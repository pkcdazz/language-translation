<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l&#39;orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
        <span class="n">list_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">list_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
        <span class="n">list_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">list_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">list_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.1.0
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>c:\users\praveen.chaudhary\appdata\local\conda\conda\envs\tensorflow1\lib\site-packages\ipykernel_launcher.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
  from ipykernel import kernelapp as app
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">])</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,(</span><span class="kc">None</span><span class="p">,),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;target_sequence_length&#39;</span><span class="p">)</span>
    <span class="n">keep_probability</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    <span class="n">max_target_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,(</span><span class="kc">None</span><span class="p">,),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;source_sequence_length&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_length</span><span class="p">,</span> <span class="n">source_sequence_len</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">x</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">)</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="n">source_vocab_size</span><span class="p">,</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">encoding_embedding_size</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">):</span>
        <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">enc_cell</span>

    
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    <span class="n">output</span><span class="p">,</span><span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span><span class="n">embed</span><span class="p">,</span><span class="n">sequence_length</span><span class="o">=</span><span class="n">source_sequence_length</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">final_state</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;Placeholder:0&#34;, shape=(64, 22), dtype=int32)
Tensor(&#34;rnn/transpose:0&#34;, shape=(64, 22, 512), dtype=float32)
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
 
    <span class="c1">#dec_cell = dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])</span>
    <span class="n">training_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                    <span class="n">sequence_length</span><span class="o">=</span><span class="n">target_sequence_length</span><span class="p">,</span>
                                                    <span class="n">time_major</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">training_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span><span class="n">training_helper</span><span class="p">,</span><span class="n">encoder_state</span><span class="p">,</span><span class="n">output_layer</span><span class="p">)</span> 
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">training_decoder</span><span class="p">,</span>
                                                                       <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                       <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">training_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;start_tokens&#39;</span><span class="p">)</span>

    <span class="c1"># Helper for the inference process.</span>
    <span class="n">inference_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span><span class="n">start_tokens</span><span class="p">,</span><span class="n">end_of_sequence_id</span><span class="p">)</span>

    <span class="c1"># Basic decoder</span>
    <span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                    <span class="n">inference_helper</span><span class="p">,</span>
                                                    <span class="n">encoder_state</span><span class="p">,</span>
                                                    <span class="n">output_layer</span><span class="p">)</span>

    <span class="c1"># Perform dynamic decoding using the decoder</span>
    <span class="n">inference_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">inference_decoder</span><span class="p">,</span>
                                                        <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                        <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">inference_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="c1"># 2. Construct the decoder cell</span>
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">):</span>
        <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">dec_cell</span>

    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
     
    <span class="c1"># 3. Dense layer to translate the decoder&#39;s output at each time </span>
    <span class="c1"># step into a choice from the target vocabulary</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


    <span class="c1"># 4. Set up a training decoder and an inference decoder</span>
    <span class="c1"># Training Decoder</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">):</span>

        <span class="c1"># Helper for the training process. Used by BasicDecoder to read inputs.</span>
        <span class="n">training_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                            <span class="n">sequence_length</span><span class="o">=</span><span class="n">target_sequence_length</span><span class="p">,</span>
                                                            <span class="n">time_major</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="c1"># Basic decoder</span>
        <span class="n">training_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                           <span class="n">training_helper</span><span class="p">,</span>
                                                           <span class="n">encoder_state</span><span class="p">,</span>
                                                           <span class="n">output_layer</span><span class="p">)</span> 
        
        <span class="c1"># Perform dynamic decoding using the decoder</span>
        <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">training_decoder</span><span class="p">,</span>
                                                                       <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                       <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    <span class="c1"># 5. Inference Decoder</span>
    <span class="c1"># Reuses the same parameters trained by the training process</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;start_tokens&#39;</span><span class="p">)</span>

        <span class="c1"># Helper for the inference process.</span>
        <span class="n">inference_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span>
                                                                <span class="n">start_tokens</span><span class="p">,</span>
                                                                <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>

        <span class="c1"># Basic decoder</span>
        <span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                        <span class="n">inference_helper</span><span class="p">,</span>
                                                        <span class="n">encoder_state</span><span class="p">,</span>
                                                        <span class="n">output_layer</span><span class="p">)</span>
        
        <span class="c1"># Perform dynamic decoding using the decoder</span>
        <span class="n">inference_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">inference_decoder</span><span class="p">,</span>
                                                            <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                            <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
         

    
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to the input data for the encoder.</li>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Apply embedding to the target data for the decoder.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>

                    
    <span class="n">_</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span><span class="n">rnn_size</span><span class="p">,</span><span class="n">num_layers</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">,</span><span class="n">source_sequence_length</span><span class="p">,</span><span class="n">source_vocab_size</span><span class="p">,</span><span class="n">enc_embedding_size</span><span class="p">)</span>
    
    
    <span class="c1"># Prepare the target sequences we&#39;ll feed to the decoder in training mode</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="c1"># Pass encoder state and decoder inputs to the decoders</span>
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span><span class="n">enc_state</span><span class="p">,</span><span class="n">target_sequence_length</span><span class="p">,</span><span class="n">max_target_sentence_length</span><span class="p">,</span>
                                                                      <span class="n">rnn_size</span><span class="p">,</span><span class="n">num_layers</span><span class="p">,</span><span class="n">target_vocab_to_int</span><span class="p">,</span><span class="n">target_vocab_size</span><span class="p">,</span>
                                                                      <span class="n">batch_size</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">,</span><span class="n">dec_embedding_size</span><span class="p">)</span>

    
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;Placeholder_6:0&#34;, shape=(64, 22), dtype=int32)
Tensor(&#34;rnn/transpose:0&#34;, shape=(64, 22, 512), dtype=float32)
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;ReverseV2:0&#34;, shape=(?, ?), dtype=int32)
Tensor(&#34;rnn/transpose:0&#34;, shape=(?, ?, 50), dtype=float32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch   20/1077 - Train Accuracy: 0.2316, Validation Accuracy: 0.3050, Loss: 4.8685
Epoch   0 Batch   40/1077 - Train Accuracy: 0.2316, Validation Accuracy: 0.3050, Loss: 3.8388
Epoch   0 Batch   60/1077 - Train Accuracy: 0.2932, Validation Accuracy: 0.3349, Loss: 3.4794
Epoch   0 Batch   80/1077 - Train Accuracy: 0.2699, Validation Accuracy: 0.3356, Loss: 3.4603
Epoch   0 Batch  100/1077 - Train Accuracy: 0.2605, Validation Accuracy: 0.3363, Loss: 3.4039
Epoch   0 Batch  120/1077 - Train Accuracy: 0.2703, Validation Accuracy: 0.3363, Loss: 3.2936
Epoch   0 Batch  140/1077 - Train Accuracy: 0.2438, Validation Accuracy: 0.3487, Loss: 3.3492
Epoch   0 Batch  160/1077 - Train Accuracy: 0.2863, Validation Accuracy: 0.3501, Loss: 3.0902
Epoch   0 Batch  180/1077 - Train Accuracy: 0.2895, Validation Accuracy: 0.3501, Loss: 3.0399
Epoch   0 Batch  200/1077 - Train Accuracy: 0.3340, Validation Accuracy: 0.3867, Loss: 2.9634
Epoch   0 Batch  220/1077 - Train Accuracy: 0.3121, Validation Accuracy: 0.3906, Loss: 2.9843
Epoch   0 Batch  240/1077 - Train Accuracy: 0.3563, Validation Accuracy: 0.3970, Loss: 2.7860
Epoch   0 Batch  260/1077 - Train Accuracy: 0.3676, Validation Accuracy: 0.4023, Loss: 2.6998
Epoch   0 Batch  280/1077 - Train Accuracy: 0.3496, Validation Accuracy: 0.4016, Loss: 2.7433
Epoch   0 Batch  300/1077 - Train Accuracy: 0.3211, Validation Accuracy: 0.4094, Loss: 2.8407
Epoch   0 Batch  320/1077 - Train Accuracy: 0.3570, Validation Accuracy: 0.4059, Loss: 2.7064
Epoch   0 Batch  340/1077 - Train Accuracy: 0.3170, Validation Accuracy: 0.4102, Loss: 2.7739
Epoch   0 Batch  360/1077 - Train Accuracy: 0.3629, Validation Accuracy: 0.4212, Loss: 2.6184
Epoch   0 Batch  380/1077 - Train Accuracy: 0.3777, Validation Accuracy: 0.4244, Loss: 2.5375
Epoch   0 Batch  400/1077 - Train Accuracy: 0.3758, Validation Accuracy: 0.4393, Loss: 2.5689
Epoch   0 Batch  420/1077 - Train Accuracy: 0.3766, Validation Accuracy: 0.4450, Loss: 2.5217
Epoch   0 Batch  440/1077 - Train Accuracy: 0.4176, Validation Accuracy: 0.4620, Loss: 2.4473
Epoch   0 Batch  460/1077 - Train Accuracy: 0.3914, Validation Accuracy: 0.4524, Loss: 2.4601
Epoch   0 Batch  480/1077 - Train Accuracy: 0.4042, Validation Accuracy: 0.4688, Loss: 2.4334
Epoch   0 Batch  500/1077 - Train Accuracy: 0.4379, Validation Accuracy: 0.4684, Loss: 2.3186
Epoch   0 Batch  520/1077 - Train Accuracy: 0.4513, Validation Accuracy: 0.4730, Loss: 2.1948
Epoch   0 Batch  540/1077 - Train Accuracy: 0.4375, Validation Accuracy: 0.4688, Loss: 2.1820
Epoch   0 Batch  560/1077 - Train Accuracy: 0.4398, Validation Accuracy: 0.4822, Loss: 2.1880
Epoch   0 Batch  580/1077 - Train Accuracy: 0.4609, Validation Accuracy: 0.4805, Loss: 2.1006
Epoch   0 Batch  600/1077 - Train Accuracy: 0.4691, Validation Accuracy: 0.4833, Loss: 2.0518
Epoch   0 Batch  620/1077 - Train Accuracy: 0.4348, Validation Accuracy: 0.4833, Loss: 2.1368
Epoch   0 Batch  640/1077 - Train Accuracy: 0.4535, Validation Accuracy: 0.4833, Loss: 2.0551
Epoch   0 Batch  660/1077 - Train Accuracy: 0.4379, Validation Accuracy: 0.4904, Loss: 2.1203
Epoch   0 Batch  680/1077 - Train Accuracy: 0.4591, Validation Accuracy: 0.4943, Loss: 2.0116
Epoch   0 Batch  700/1077 - Train Accuracy: 0.4473, Validation Accuracy: 0.4911, Loss: 1.9979
Epoch   0 Batch  720/1077 - Train Accuracy: 0.4379, Validation Accuracy: 0.4972, Loss: 2.1155
Epoch   0 Batch  740/1077 - Train Accuracy: 0.4535, Validation Accuracy: 0.4847, Loss: 1.9308
Epoch   0 Batch  760/1077 - Train Accuracy: 0.4488, Validation Accuracy: 0.4883, Loss: 1.9194
Epoch   0 Batch  780/1077 - Train Accuracy: 0.4535, Validation Accuracy: 0.4982, Loss: 1.8779
Epoch   0 Batch  800/1077 - Train Accuracy: 0.4363, Validation Accuracy: 0.5121, Loss: 1.8870
Epoch   0 Batch  820/1077 - Train Accuracy: 0.4633, Validation Accuracy: 0.5153, Loss: 1.8518
Epoch   0 Batch  840/1077 - Train Accuracy: 0.4723, Validation Accuracy: 0.5160, Loss: 1.7191
Epoch   0 Batch  860/1077 - Train Accuracy: 0.4918, Validation Accuracy: 0.5114, Loss: 1.6074
Epoch   0 Batch  880/1077 - Train Accuracy: 0.4742, Validation Accuracy: 0.4844, Loss: 1.5597
Epoch   0 Batch  900/1077 - Train Accuracy: 0.4426, Validation Accuracy: 0.4808, Loss: 1.6062
Epoch   0 Batch  920/1077 - Train Accuracy: 0.3934, Validation Accuracy: 0.4439, Loss: 1.5326
Epoch   0 Batch  940/1077 - Train Accuracy: 0.3555, Validation Accuracy: 0.3981, Loss: 1.5203
Epoch   0 Batch  960/1077 - Train Accuracy: 0.4070, Validation Accuracy: 0.4105, Loss: 1.3628
Epoch   0 Batch  980/1077 - Train Accuracy: 0.3781, Validation Accuracy: 0.4073, Loss: 1.3710
Epoch   0 Batch 1000/1077 - Train Accuracy: 0.4022, Validation Accuracy: 0.4112, Loss: 1.3008
Epoch   0 Batch 1020/1077 - Train Accuracy: 0.3641, Validation Accuracy: 0.4087, Loss: 1.3257
Epoch   0 Batch 1040/1077 - Train Accuracy: 0.3524, Validation Accuracy: 0.4094, Loss: 1.3662
Epoch   0 Batch 1060/1077 - Train Accuracy: 0.3738, Validation Accuracy: 0.3775, Loss: 1.2739
Epoch   1 Batch   20/1077 - Train Accuracy: 0.3676, Validation Accuracy: 0.4116, Loss: 1.2038
Epoch   1 Batch   40/1077 - Train Accuracy: 0.3586, Validation Accuracy: 0.4293, Loss: 1.2256
Epoch   1 Batch   60/1077 - Train Accuracy: 0.3858, Validation Accuracy: 0.4283, Loss: 1.1829
Epoch   1 Batch   80/1077 - Train Accuracy: 0.3285, Validation Accuracy: 0.4162, Loss: 1.2005
Epoch   1 Batch  100/1077 - Train Accuracy: 0.3680, Validation Accuracy: 0.4237, Loss: 1.1914
Epoch   1 Batch  120/1077 - Train Accuracy: 0.3957, Validation Accuracy: 0.4311, Loss: 1.1781
Epoch   1 Batch  140/1077 - Train Accuracy: 0.3766, Validation Accuracy: 0.4464, Loss: 1.2219
Epoch   1 Batch  160/1077 - Train Accuracy: 0.3785, Validation Accuracy: 0.4293, Loss: 1.1154
Epoch   1 Batch  180/1077 - Train Accuracy: 0.3867, Validation Accuracy: 0.4247, Loss: 1.1169
Epoch   1 Batch  200/1077 - Train Accuracy: 0.4012, Validation Accuracy: 0.4226, Loss: 1.1198
Epoch   1 Batch  220/1077 - Train Accuracy: 0.3828, Validation Accuracy: 0.4311, Loss: 1.1294
Epoch   1 Batch  240/1077 - Train Accuracy: 0.3605, Validation Accuracy: 0.4194, Loss: 1.0628
Epoch   1 Batch  260/1077 - Train Accuracy: 0.3765, Validation Accuracy: 0.4251, Loss: 1.0248
Epoch   1 Batch  280/1077 - Train Accuracy: 0.3652, Validation Accuracy: 0.4169, Loss: 1.0927
Epoch   1 Batch  300/1077 - Train Accuracy: 0.3561, Validation Accuracy: 0.4300, Loss: 1.1085
Epoch   1 Batch  320/1077 - Train Accuracy: 0.3859, Validation Accuracy: 0.4297, Loss: 1.0624
Epoch   1 Batch  340/1077 - Train Accuracy: 0.3701, Validation Accuracy: 0.4407, Loss: 1.0535
Epoch   1 Batch  360/1077 - Train Accuracy: 0.3953, Validation Accuracy: 0.4478, Loss: 1.0269
Epoch   1 Batch  380/1077 - Train Accuracy: 0.4355, Validation Accuracy: 0.4460, Loss: 0.9863
Epoch   1 Batch  400/1077 - Train Accuracy: 0.4164, Validation Accuracy: 0.4485, Loss: 1.0188
Epoch   1 Batch  420/1077 - Train Accuracy: 0.4270, Validation Accuracy: 0.4499, Loss: 0.9991
Epoch   1 Batch  440/1077 - Train Accuracy: 0.4348, Validation Accuracy: 0.4503, Loss: 1.0172
Epoch   1 Batch  460/1077 - Train Accuracy: 0.3836, Validation Accuracy: 0.4421, Loss: 0.9950
Epoch   1 Batch  480/1077 - Train Accuracy: 0.4050, Validation Accuracy: 0.4577, Loss: 1.0004
Epoch   1 Batch  500/1077 - Train Accuracy: 0.4277, Validation Accuracy: 0.4553, Loss: 0.9493
Epoch   1 Batch  520/1077 - Train Accuracy: 0.4587, Validation Accuracy: 0.4538, Loss: 0.8929
Epoch   1 Batch  540/1077 - Train Accuracy: 0.4313, Validation Accuracy: 0.4624, Loss: 0.8935
Epoch   1 Batch  560/1077 - Train Accuracy: 0.4594, Validation Accuracy: 0.4616, Loss: 0.9078
Epoch   1 Batch  580/1077 - Train Accuracy: 0.4680, Validation Accuracy: 0.4641, Loss: 0.8626
Epoch   1 Batch  600/1077 - Train Accuracy: 0.4643, Validation Accuracy: 0.4599, Loss: 0.8688
Epoch   1 Batch  620/1077 - Train Accuracy: 0.4918, Validation Accuracy: 0.5000, Loss: 0.8932
Epoch   1 Batch  640/1077 - Train Accuracy: 0.5063, Validation Accuracy: 0.4979, Loss: 0.8623
Epoch   1 Batch  660/1077 - Train Accuracy: 0.4816, Validation Accuracy: 0.4925, Loss: 0.9061
Epoch   1 Batch  680/1077 - Train Accuracy: 0.5149, Validation Accuracy: 0.5337, Loss: 0.8446
Epoch   1 Batch  700/1077 - Train Accuracy: 0.4977, Validation Accuracy: 0.5160, Loss: 0.8395
Epoch   1 Batch  720/1077 - Train Accuracy: 0.5354, Validation Accuracy: 0.5433, Loss: 0.9208
Epoch   1 Batch  740/1077 - Train Accuracy: 0.5250, Validation Accuracy: 0.5217, Loss: 0.8358
Epoch   1 Batch  760/1077 - Train Accuracy: 0.5074, Validation Accuracy: 0.5472, Loss: 0.8511
Epoch   1 Batch  780/1077 - Train Accuracy: 0.5270, Validation Accuracy: 0.5426, Loss: 0.8640
Epoch   1 Batch  800/1077 - Train Accuracy: 0.5285, Validation Accuracy: 0.5291, Loss: 0.8359
Epoch   1 Batch  820/1077 - Train Accuracy: 0.5008, Validation Accuracy: 0.5391, Loss: 0.8371
Epoch   1 Batch  840/1077 - Train Accuracy: 0.5500, Validation Accuracy: 0.5518, Loss: 0.7904
Epoch   1 Batch  860/1077 - Train Accuracy: 0.5547, Validation Accuracy: 0.5458, Loss: 0.7780
Epoch   1 Batch  880/1077 - Train Accuracy: 0.5492, Validation Accuracy: 0.5352, Loss: 0.7826
Epoch   1 Batch  900/1077 - Train Accuracy: 0.5434, Validation Accuracy: 0.5451, Loss: 0.8061
Epoch   1 Batch  920/1077 - Train Accuracy: 0.5250, Validation Accuracy: 0.5430, Loss: 0.7976
Epoch   1 Batch  940/1077 - Train Accuracy: 0.5379, Validation Accuracy: 0.5394, Loss: 0.7864
Epoch   1 Batch  960/1077 - Train Accuracy: 0.5714, Validation Accuracy: 0.5692, Loss: 0.7413
Epoch   1 Batch  980/1077 - Train Accuracy: 0.5320, Validation Accuracy: 0.5309, Loss: 0.7569
Epoch   1 Batch 1000/1077 - Train Accuracy: 0.5852, Validation Accuracy: 0.5657, Loss: 0.7130
Epoch   1 Batch 1020/1077 - Train Accuracy: 0.5715, Validation Accuracy: 0.5657, Loss: 0.7288
Epoch   1 Batch 1040/1077 - Train Accuracy: 0.5378, Validation Accuracy: 0.5501, Loss: 0.7879
Epoch   1 Batch 1060/1077 - Train Accuracy: 0.5738, Validation Accuracy: 0.5199, Loss: 0.7236
Epoch   2 Batch   20/1077 - Train Accuracy: 0.5340, Validation Accuracy: 0.5586, Loss: 0.7021
Epoch   2 Batch   40/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.5490, Loss: 0.7230
Epoch   2 Batch   60/1077 - Train Accuracy: 0.5822, Validation Accuracy: 0.5859, Loss: 0.6933
Epoch   2 Batch   80/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.5696, Loss: 0.7179
Epoch   2 Batch  100/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.5884, Loss: 0.7184
Epoch   2 Batch  120/1077 - Train Accuracy: 0.5664, Validation Accuracy: 0.5870, Loss: 0.7084
Epoch   2 Batch  140/1077 - Train Accuracy: 0.5387, Validation Accuracy: 0.5898, Loss: 0.7315
Epoch   2 Batch  160/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.5515, Loss: 0.6820
Epoch   2 Batch  180/1077 - Train Accuracy: 0.5949, Validation Accuracy: 0.5866, Loss: 0.6743
Epoch   2 Batch  200/1077 - Train Accuracy: 0.5887, Validation Accuracy: 0.5707, Loss: 0.6939
Epoch   2 Batch  220/1077 - Train Accuracy: 0.5678, Validation Accuracy: 0.5962, Loss: 0.6956
Epoch   2 Batch  240/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.5959, Loss: 0.6551
Epoch   2 Batch  260/1077 - Train Accuracy: 0.6045, Validation Accuracy: 0.5909, Loss: 0.6245
Epoch   2 Batch  280/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.5962, Loss: 0.6894
Epoch   2 Batch  300/1077 - Train Accuracy: 0.6184, Validation Accuracy: 0.5980, Loss: 0.6836
Epoch   2 Batch  320/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6030, Loss: 0.6718
Epoch   2 Batch  340/1077 - Train Accuracy: 0.5444, Validation Accuracy: 0.5948, Loss: 0.6615
Epoch   2 Batch  360/1077 - Train Accuracy: 0.5980, Validation Accuracy: 0.5881, Loss: 0.6488
Epoch   2 Batch  380/1077 - Train Accuracy: 0.6207, Validation Accuracy: 0.6019, Loss: 0.6288
Epoch   2 Batch  400/1077 - Train Accuracy: 0.5746, Validation Accuracy: 0.6080, Loss: 0.6496
Epoch   2 Batch  420/1077 - Train Accuracy: 0.6074, Validation Accuracy: 0.5980, Loss: 0.6155
Epoch   2 Batch  440/1077 - Train Accuracy: 0.6113, Validation Accuracy: 0.5913, Loss: 0.6465
Epoch   2 Batch  460/1077 - Train Accuracy: 0.6078, Validation Accuracy: 0.5987, Loss: 0.6484
Epoch   2 Batch  480/1077 - Train Accuracy: 0.5847, Validation Accuracy: 0.6019, Loss: 0.6476
Epoch   2 Batch  500/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6136, Loss: 0.6185
Epoch   2 Batch  520/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6179, Loss: 0.5803
Epoch   2 Batch  540/1077 - Train Accuracy: 0.5887, Validation Accuracy: 0.5941, Loss: 0.5734
Epoch   2 Batch  560/1077 - Train Accuracy: 0.6082, Validation Accuracy: 0.5952, Loss: 0.6001
Epoch   2 Batch  580/1077 - Train Accuracy: 0.6403, Validation Accuracy: 0.6044, Loss: 0.5685
Epoch   2 Batch  600/1077 - Train Accuracy: 0.6079, Validation Accuracy: 0.5938, Loss: 0.5778
Epoch   2 Batch  620/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6143, Loss: 0.5873
Epoch   2 Batch  640/1077 - Train Accuracy: 0.6462, Validation Accuracy: 0.6197, Loss: 0.5818
Epoch   2 Batch  660/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.5991, Loss: 0.6109
Epoch   2 Batch  680/1077 - Train Accuracy: 0.6306, Validation Accuracy: 0.6200, Loss: 0.5728
Epoch   2 Batch  700/1077 - Train Accuracy: 0.5961, Validation Accuracy: 0.6083, Loss: 0.5785
Epoch   2 Batch  720/1077 - Train Accuracy: 0.5966, Validation Accuracy: 0.6143, Loss: 0.6257
Epoch   2 Batch  740/1077 - Train Accuracy: 0.6117, Validation Accuracy: 0.5969, Loss: 0.5800
Epoch   2 Batch  760/1077 - Train Accuracy: 0.6215, Validation Accuracy: 0.5948, Loss: 0.5882
Epoch   2 Batch  780/1077 - Train Accuracy: 0.5957, Validation Accuracy: 0.6271, Loss: 0.5992
Epoch   2 Batch  800/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6190, Loss: 0.5804
Epoch   2 Batch  820/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6168, Loss: 0.5843
Epoch   2 Batch  840/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.6218, Loss: 0.5549
Epoch   2 Batch  860/1077 - Train Accuracy: 0.6224, Validation Accuracy: 0.6083, Loss: 0.5430
Epoch   2 Batch  880/1077 - Train Accuracy: 0.6477, Validation Accuracy: 0.6072, Loss: 0.5482
Epoch   2 Batch  900/1077 - Train Accuracy: 0.6238, Validation Accuracy: 0.6161, Loss: 0.5724
Epoch   2 Batch  920/1077 - Train Accuracy: 0.6285, Validation Accuracy: 0.6232, Loss: 0.5717
Epoch   2 Batch  940/1077 - Train Accuracy: 0.6566, Validation Accuracy: 0.6239, Loss: 0.5469
Epoch   2 Batch  960/1077 - Train Accuracy: 0.6466, Validation Accuracy: 0.6222, Loss: 0.5275
Epoch   2 Batch  980/1077 - Train Accuracy: 0.6004, Validation Accuracy: 0.6154, Loss: 0.5429
Epoch   2 Batch 1000/1077 - Train Accuracy: 0.6708, Validation Accuracy: 0.6236, Loss: 0.5001
Epoch   2 Batch 1020/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6129, Loss: 0.5123
Epoch   2 Batch 1040/1077 - Train Accuracy: 0.6184, Validation Accuracy: 0.6243, Loss: 0.5657
Epoch   2 Batch 1060/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6200, Loss: 0.5159
Epoch   3 Batch   20/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.6428, Loss: 0.5003
Epoch   3 Batch   40/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6467, Loss: 0.5131
Epoch   3 Batch   60/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6403, Loss: 0.4988
Epoch   3 Batch   80/1077 - Train Accuracy: 0.6203, Validation Accuracy: 0.6435, Loss: 0.5125
Epoch   3 Batch  100/1077 - Train Accuracy: 0.6375, Validation Accuracy: 0.6413, Loss: 0.5245
Epoch   3 Batch  120/1077 - Train Accuracy: 0.6543, Validation Accuracy: 0.6271, Loss: 0.5201
Epoch   3 Batch  140/1077 - Train Accuracy: 0.6423, Validation Accuracy: 0.6332, Loss: 0.5288
Epoch   3 Batch  160/1077 - Train Accuracy: 0.6762, Validation Accuracy: 0.6474, Loss: 0.4999
Epoch   3 Batch  180/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6467, Loss: 0.4902
Epoch   3 Batch  200/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6435, Loss: 0.5089
Epoch   3 Batch  220/1077 - Train Accuracy: 0.6303, Validation Accuracy: 0.6335, Loss: 0.5052
Epoch   3 Batch  240/1077 - Train Accuracy: 0.6539, Validation Accuracy: 0.6413, Loss: 0.4718
Epoch   3 Batch  260/1077 - Train Accuracy: 0.6741, Validation Accuracy: 0.6392, Loss: 0.4512
Epoch   3 Batch  280/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6282, Loss: 0.4989
Epoch   3 Batch  300/1077 - Train Accuracy: 0.6579, Validation Accuracy: 0.6449, Loss: 0.4961
Epoch   3 Batch  320/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6417, Loss: 0.4954
Epoch   3 Batch  340/1077 - Train Accuracy: 0.6377, Validation Accuracy: 0.6310, Loss: 0.4889
Epoch   3 Batch  360/1077 - Train Accuracy: 0.6387, Validation Accuracy: 0.6488, Loss: 0.4705
Epoch   3 Batch  380/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6399, Loss: 0.4644
Epoch   3 Batch  400/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6495, Loss: 0.4788
Epoch   3 Batch  420/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6371, Loss: 0.4477
Epoch   3 Batch  440/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6445, Loss: 0.4742
Epoch   3 Batch  460/1077 - Train Accuracy: 0.6559, Validation Accuracy: 0.6349, Loss: 0.4785
Epoch   3 Batch  480/1077 - Train Accuracy: 0.6558, Validation Accuracy: 0.6509, Loss: 0.4690
Epoch   3 Batch  500/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6371, Loss: 0.4447
Epoch   3 Batch  520/1077 - Train Accuracy: 0.7083, Validation Accuracy: 0.6513, Loss: 0.4172
Epoch   3 Batch  540/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6559, Loss: 0.4200
Epoch   3 Batch  560/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6580, Loss: 0.4376
Epoch   3 Batch  580/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6463, Loss: 0.4209
Epoch   3 Batch  600/1077 - Train Accuracy: 0.6704, Validation Accuracy: 0.6438, Loss: 0.4275
Epoch   3 Batch  620/1077 - Train Accuracy: 0.6500, Validation Accuracy: 0.6552, Loss: 0.4345
Epoch   3 Batch  640/1077 - Train Accuracy: 0.6856, Validation Accuracy: 0.6598, Loss: 0.4299
Epoch   3 Batch  660/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.6587, Loss: 0.4475
Epoch   3 Batch  680/1077 - Train Accuracy: 0.6771, Validation Accuracy: 0.6538, Loss: 0.4332
Epoch   3 Batch  700/1077 - Train Accuracy: 0.6570, Validation Accuracy: 0.6452, Loss: 0.4289
Epoch   3 Batch  720/1077 - Train Accuracy: 0.6587, Validation Accuracy: 0.6424, Loss: 0.4659
Epoch   3 Batch  740/1077 - Train Accuracy: 0.6449, Validation Accuracy: 0.6491, Loss: 0.4321
Epoch   3 Batch  760/1077 - Train Accuracy: 0.6375, Validation Accuracy: 0.6499, Loss: 0.4391
Epoch   3 Batch  780/1077 - Train Accuracy: 0.6520, Validation Accuracy: 0.6520, Loss: 0.4470
Epoch   3 Batch  800/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6516, Loss: 0.4279
Epoch   3 Batch  820/1077 - Train Accuracy: 0.6273, Validation Accuracy: 0.6467, Loss: 0.4336
Epoch   3 Batch  840/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.6641, Loss: 0.4116
Epoch   3 Batch  860/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.6559, Loss: 0.4037
Epoch   3 Batch  880/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.6605, Loss: 0.4006
Epoch   3 Batch  900/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.6552, Loss: 0.4353
Epoch   3 Batch  920/1077 - Train Accuracy: 0.6539, Validation Accuracy: 0.6527, Loss: 0.4301
Epoch   3 Batch  940/1077 - Train Accuracy: 0.6902, Validation Accuracy: 0.6630, Loss: 0.4127
Epoch   3 Batch  960/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.6541, Loss: 0.3875
Epoch   3 Batch  980/1077 - Train Accuracy: 0.6703, Validation Accuracy: 0.6470, Loss: 0.4067
Epoch   3 Batch 1000/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6623, Loss: 0.3693
Epoch   3 Batch 1020/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.6655, Loss: 0.3828
Epoch   3 Batch 1040/1077 - Train Accuracy: 0.6624, Validation Accuracy: 0.6559, Loss: 0.4297
Epoch   3 Batch 1060/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6328, Loss: 0.3965
Epoch   4 Batch   20/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.6548, Loss: 0.3689
Epoch   4 Batch   40/1077 - Train Accuracy: 0.7074, Validation Accuracy: 0.6804, Loss: 0.3841
Epoch   4 Batch   60/1077 - Train Accuracy: 0.6853, Validation Accuracy: 0.6676, Loss: 0.3672
Epoch   4 Batch   80/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.6683, Loss: 0.3855
Epoch   4 Batch  100/1077 - Train Accuracy: 0.6937, Validation Accuracy: 0.6651, Loss: 0.3951
Epoch   4 Batch  120/1077 - Train Accuracy: 0.7105, Validation Accuracy: 0.6488, Loss: 0.3950
Epoch   4 Batch  140/1077 - Train Accuracy: 0.6933, Validation Accuracy: 0.6562, Loss: 0.3972
Epoch   4 Batch  160/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.6662, Loss: 0.3772
Epoch   4 Batch  180/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6637, Loss: 0.3665
Epoch   4 Batch  200/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.6612, Loss: 0.3871
Epoch   4 Batch  220/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6893, Loss: 0.3836
Epoch   4 Batch  240/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.6740, Loss: 0.3556
Epoch   4 Batch  260/1077 - Train Accuracy: 0.7173, Validation Accuracy: 0.6765, Loss: 0.3413
Epoch   4 Batch  280/1077 - Train Accuracy: 0.6852, Validation Accuracy: 0.6697, Loss: 0.3808
Epoch   4 Batch  300/1077 - Train Accuracy: 0.7216, Validation Accuracy: 0.6630, Loss: 0.3803
Epoch   4 Batch  320/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.6680, Loss: 0.3817
Epoch   4 Batch  340/1077 - Train Accuracy: 0.6534, Validation Accuracy: 0.6804, Loss: 0.3682
Epoch   4 Batch  360/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6843, Loss: 0.3590
Epoch   4 Batch  380/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6850, Loss: 0.3565
Epoch   4 Batch  400/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.6793, Loss: 0.3750
Epoch   4 Batch  420/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.6843, Loss: 0.3372
Epoch   4 Batch  440/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.6882, Loss: 0.3613
Epoch   4 Batch  460/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.6744, Loss: 0.3679
Epoch   4 Batch  480/1077 - Train Accuracy: 0.7134, Validation Accuracy: 0.6797, Loss: 0.3538
Epoch   4 Batch  500/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.6825, Loss: 0.3341
Epoch   4 Batch  520/1077 - Train Accuracy: 0.7567, Validation Accuracy: 0.6793, Loss: 0.3202
Epoch   4 Batch  540/1077 - Train Accuracy: 0.7250, Validation Accuracy: 0.6871, Loss: 0.3113
Epoch   4 Batch  560/1077 - Train Accuracy: 0.6922, Validation Accuracy: 0.6847, Loss: 0.3314
Epoch   4 Batch  580/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.7013, Loss: 0.3132
Epoch   4 Batch  600/1077 - Train Accuracy: 0.7318, Validation Accuracy: 0.6882, Loss: 0.3248
Epoch   4 Batch  620/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6996, Loss: 0.3339
Epoch   4 Batch  640/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.6882, Loss: 0.3292
Epoch   4 Batch  660/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.6783, Loss: 0.3370
Epoch   4 Batch  680/1077 - Train Accuracy: 0.7072, Validation Accuracy: 0.6950, Loss: 0.3203
Epoch   4 Batch  700/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6911, Loss: 0.3248
Epoch   4 Batch  720/1077 - Train Accuracy: 0.7208, Validation Accuracy: 0.6946, Loss: 0.3563
Epoch   4 Batch  740/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6879, Loss: 0.3280
Epoch   4 Batch  760/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6996, Loss: 0.3423
Epoch   4 Batch  780/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7031, Loss: 0.3394
Epoch   4 Batch  800/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7053, Loss: 0.3263
Epoch   4 Batch  820/1077 - Train Accuracy: 0.6895, Validation Accuracy: 0.7173, Loss: 0.3317
Epoch   4 Batch  840/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7010, Loss: 0.3135
Epoch   4 Batch  860/1077 - Train Accuracy: 0.7132, Validation Accuracy: 0.7003, Loss: 0.3099
Epoch   4 Batch  880/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.6978, Loss: 0.2992
Epoch   4 Batch  900/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7035, Loss: 0.3358
Epoch   4 Batch  920/1077 - Train Accuracy: 0.7312, Validation Accuracy: 0.7099, Loss: 0.3282
Epoch   4 Batch  940/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7099, Loss: 0.3078
Epoch   4 Batch  960/1077 - Train Accuracy: 0.7437, Validation Accuracy: 0.6911, Loss: 0.2910
Epoch   4 Batch  980/1077 - Train Accuracy: 0.7125, Validation Accuracy: 0.7138, Loss: 0.3088
Epoch   4 Batch 1000/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.6982, Loss: 0.2800
Epoch   4 Batch 1020/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7006, Loss: 0.2869
Epoch   4 Batch 1040/1077 - Train Accuracy: 0.7282, Validation Accuracy: 0.6903, Loss: 0.3263
Epoch   4 Batch 1060/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.6815, Loss: 0.3238
Epoch   5 Batch   20/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.7134, Loss: 0.2767
Epoch   5 Batch   40/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.6974, Loss: 0.2979
Epoch   5 Batch   60/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7205, Loss: 0.2766
Epoch   5 Batch   80/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.6942, Loss: 0.2892
Epoch   5 Batch  100/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7152, Loss: 0.2955
Epoch   5 Batch  120/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.6921, Loss: 0.3069
Epoch   5 Batch  140/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7017, Loss: 0.3044
Epoch   5 Batch  160/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7124, Loss: 0.2848
Epoch   5 Batch  180/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7095, Loss: 0.2752
Epoch   5 Batch  200/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7188, Loss: 0.2954
Epoch   5 Batch  220/1077 - Train Accuracy: 0.7179, Validation Accuracy: 0.7312, Loss: 0.2898
Epoch   5 Batch  240/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7173, Loss: 0.2713
Epoch   5 Batch  260/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7202, Loss: 0.2573
Epoch   5 Batch  280/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7113, Loss: 0.2832
Epoch   5 Batch  300/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7266, Loss: 0.2892
Epoch   5 Batch  320/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7159, Loss: 0.2916
Epoch   5 Batch  340/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7145, Loss: 0.2744
Epoch   5 Batch  360/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7266, Loss: 0.2744
Epoch   5 Batch  380/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7227, Loss: 0.2612
Epoch   5 Batch  400/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7209, Loss: 0.2957
Epoch   5 Batch  420/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7088, Loss: 0.2494
Epoch   5 Batch  440/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7124, Loss: 0.2746
Epoch   5 Batch  460/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7280, Loss: 0.2834
Epoch   5 Batch  480/1077 - Train Accuracy: 0.7545, Validation Accuracy: 0.7230, Loss: 0.2690
Epoch   5 Batch  500/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7205, Loss: 0.2546
Epoch   5 Batch  520/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7337, Loss: 0.2420
Epoch   5 Batch  540/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7337, Loss: 0.2300
Epoch   5 Batch  560/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7255, Loss: 0.2470
Epoch   5 Batch  580/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7422, Loss: 0.2387
Epoch   5 Batch  600/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7205, Loss: 0.2506
Epoch   5 Batch  620/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7401, Loss: 0.2516
Epoch   5 Batch  640/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7092, Loss: 0.2485
Epoch   5 Batch  660/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7393, Loss: 0.2616
Epoch   5 Batch  680/1077 - Train Accuracy: 0.7593, Validation Accuracy: 0.7397, Loss: 0.2420
Epoch   5 Batch  700/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7063, Loss: 0.2438
Epoch   5 Batch  720/1077 - Train Accuracy: 0.7525, Validation Accuracy: 0.7472, Loss: 0.2740
Epoch   5 Batch  740/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7269, Loss: 0.2449
Epoch   5 Batch  760/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7347, Loss: 0.2739
Epoch   5 Batch  780/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7429, Loss: 0.2665
Epoch   5 Batch  800/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7390, Loss: 0.2501
Epoch   5 Batch  820/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.7401, Loss: 0.2585
Epoch   5 Batch  840/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7599, Loss: 0.2406
Epoch   5 Batch  860/1077 - Train Accuracy: 0.7325, Validation Accuracy: 0.7422, Loss: 0.2500
Epoch   5 Batch  880/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7461, Loss: 0.2305
Epoch   5 Batch  900/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7170, Loss: 0.2699
Epoch   5 Batch  920/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7290, Loss: 0.2493
Epoch   5 Batch  940/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7347, Loss: 0.2332
Epoch   5 Batch  960/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7319, Loss: 0.2260
Epoch   5 Batch  980/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7603, Loss: 0.2408
Epoch   5 Batch 1000/1077 - Train Accuracy: 0.8099, Validation Accuracy: 0.7585, Loss: 0.2130
Epoch   5 Batch 1020/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7525, Loss: 0.2195
Epoch   5 Batch 1040/1077 - Train Accuracy: 0.7755, Validation Accuracy: 0.7333, Loss: 0.2489
Epoch   5 Batch 1060/1077 - Train Accuracy: 0.7289, Validation Accuracy: 0.6971, Loss: 0.2665
Epoch   6 Batch   20/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7518, Loss: 0.2126
Epoch   6 Batch   40/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7489, Loss: 0.2246
Epoch   6 Batch   60/1077 - Train Accuracy: 0.7615, Validation Accuracy: 0.7678, Loss: 0.2146
Epoch   6 Batch   80/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7401, Loss: 0.2188
Epoch   6 Batch  100/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7798, Loss: 0.2239
Epoch   6 Batch  120/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7553, Loss: 0.2412
Epoch   6 Batch  140/1077 - Train Accuracy: 0.7673, Validation Accuracy: 0.7493, Loss: 0.2295
Epoch   6 Batch  160/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7756, Loss: 0.2187
Epoch   6 Batch  180/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7617, Loss: 0.2034
Epoch   6 Batch  200/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7923, Loss: 0.2265
Epoch   6 Batch  220/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7855, Loss: 0.2232
Epoch   6 Batch  240/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7724, Loss: 0.2090
Epoch   6 Batch  260/1077 - Train Accuracy: 0.8110, Validation Accuracy: 0.7560, Loss: 0.1982
Epoch   6 Batch  280/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7617, Loss: 0.2182
Epoch   6 Batch  300/1077 - Train Accuracy: 0.7882, Validation Accuracy: 0.7720, Loss: 0.2186
Epoch   6 Batch  320/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7802, Loss: 0.2237
Epoch   6 Batch  340/1077 - Train Accuracy: 0.8183, Validation Accuracy: 0.7816, Loss: 0.2093
Epoch   6 Batch  360/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7962, Loss: 0.2067
Epoch   6 Batch  380/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.8004, Loss: 0.1926
Epoch   6 Batch  400/1077 - Train Accuracy: 0.8016, Validation Accuracy: 0.7830, Loss: 0.2242
Epoch   6 Batch  420/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7979, Loss: 0.1924
Epoch   6 Batch  440/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7844, Loss: 0.2133
Epoch   6 Batch  460/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7834, Loss: 0.2199
Epoch   6 Batch  480/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7795, Loss: 0.2057
Epoch   6 Batch  500/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.8011, Loss: 0.1874
Epoch   6 Batch  520/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.7763, Loss: 0.1877
Epoch   6 Batch  540/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7823, Loss: 0.1737
Epoch   6 Batch  560/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7912, Loss: 0.1897
Epoch   6 Batch  580/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7930, Loss: 0.1856
Epoch   6 Batch  600/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7717, Loss: 0.1975
Epoch   6 Batch  620/1077 - Train Accuracy: 0.8148, Validation Accuracy: 0.7752, Loss: 0.1930
Epoch   6 Batch  640/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.8058, Loss: 0.1957
Epoch   6 Batch  660/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.8047, Loss: 0.2008
Epoch   6 Batch  680/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.8004, Loss: 0.1838
Epoch   6 Batch  700/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7624, Loss: 0.1810
Epoch   6 Batch  720/1077 - Train Accuracy: 0.7714, Validation Accuracy: 0.7741, Loss: 0.2202
Epoch   6 Batch  740/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7962, Loss: 0.1890
Epoch   6 Batch  760/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.8047, Loss: 0.2172
Epoch   6 Batch  780/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.8072, Loss: 0.2109
Epoch   6 Batch  800/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.8072, Loss: 0.1915
Epoch   6 Batch  820/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.8022, Loss: 0.2030
Epoch   6 Batch  840/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.7983, Loss: 0.1825
Epoch   6 Batch  860/1077 - Train Accuracy: 0.7630, Validation Accuracy: 0.7894, Loss: 0.1878
Epoch   6 Batch  880/1077 - Train Accuracy: 0.8305, Validation Accuracy: 0.8274, Loss: 0.1790
Epoch   6 Batch  900/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7773, Loss: 0.2211
Epoch   6 Batch  920/1077 - Train Accuracy: 0.8016, Validation Accuracy: 0.7933, Loss: 0.1914
Epoch   6 Batch  940/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7944, Loss: 0.1791
Epoch   6 Batch  960/1077 - Train Accuracy: 0.8058, Validation Accuracy: 0.7962, Loss: 0.1730
Epoch   6 Batch  980/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.8200, Loss: 0.1889
Epoch   6 Batch 1000/1077 - Train Accuracy: 0.8389, Validation Accuracy: 0.8288, Loss: 0.1666
Epoch   6 Batch 1020/1077 - Train Accuracy: 0.8148, Validation Accuracy: 0.7979, Loss: 0.1671
Epoch   6 Batch 1040/1077 - Train Accuracy: 0.8100, Validation Accuracy: 0.7844, Loss: 0.1885
Epoch   6 Batch 1060/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7610, Loss: 0.2052
Epoch   7 Batch   20/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7990, Loss: 0.1613
Epoch   7 Batch   40/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.7926, Loss: 0.1714
Epoch   7 Batch   60/1077 - Train Accuracy: 0.8225, Validation Accuracy: 0.8065, Loss: 0.1723
Epoch   7 Batch   80/1077 - Train Accuracy: 0.8195, Validation Accuracy: 0.8093, Loss: 0.1697
Epoch   7 Batch  100/1077 - Train Accuracy: 0.8242, Validation Accuracy: 0.8171, Loss: 0.1728
Epoch   7 Batch  120/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.8192, Loss: 0.1873
Epoch   7 Batch  140/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.8079, Loss: 0.1782
Epoch   7 Batch  160/1077 - Train Accuracy: 0.8246, Validation Accuracy: 0.8278, Loss: 0.1702
Epoch   7 Batch  180/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8246, Loss: 0.1548
Epoch   7 Batch  200/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.8185, Loss: 0.1729
Epoch   7 Batch  220/1077 - Train Accuracy: 0.8244, Validation Accuracy: 0.8157, Loss: 0.1707
Epoch   7 Batch  240/1077 - Train Accuracy: 0.8465, Validation Accuracy: 0.8093, Loss: 0.1587
Epoch   7 Batch  260/1077 - Train Accuracy: 0.8423, Validation Accuracy: 0.8058, Loss: 0.1539
Epoch   7 Batch  280/1077 - Train Accuracy: 0.8172, Validation Accuracy: 0.8022, Loss: 0.1701
Epoch   7 Batch  300/1077 - Train Accuracy: 0.8183, Validation Accuracy: 0.8196, Loss: 0.1655
Epoch   7 Batch  320/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8121, Loss: 0.1777
Epoch   7 Batch  340/1077 - Train Accuracy: 0.8569, Validation Accuracy: 0.8139, Loss: 0.1642
Epoch   7 Batch  360/1077 - Train Accuracy: 0.8465, Validation Accuracy: 0.8320, Loss: 0.1522
Epoch   7 Batch  380/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.8338, Loss: 0.1462
Epoch   7 Batch  400/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8505, Loss: 0.1755
Epoch   7 Batch  420/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.8388, Loss: 0.1469
Epoch   7 Batch  440/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.8306, Loss: 0.1686
Epoch   7 Batch  460/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.8398, Loss: 0.1737
Epoch   7 Batch  480/1077 - Train Accuracy: 0.8425, Validation Accuracy: 0.8182, Loss: 0.1632
Epoch   7 Batch  500/1077 - Train Accuracy: 0.8375, Validation Accuracy: 0.8381, Loss: 0.1446
Epoch   7 Batch  520/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8221, Loss: 0.1413
Epoch   7 Batch  540/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8196, Loss: 0.1266
Epoch   7 Batch  560/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.8448, Loss: 0.1445
Epoch   7 Batch  580/1077 - Train Accuracy: 0.8493, Validation Accuracy: 0.8288, Loss: 0.1441
Epoch   7 Batch  600/1077 - Train Accuracy: 0.8326, Validation Accuracy: 0.8168, Loss: 0.1548
Epoch   7 Batch  620/1077 - Train Accuracy: 0.8477, Validation Accuracy: 0.8327, Loss: 0.1497
Epoch   7 Batch  640/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.8274, Loss: 0.1517
Epoch   7 Batch  660/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.8398, Loss: 0.1562
Epoch   7 Batch  680/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.8150, Loss: 0.1459
Epoch   7 Batch  700/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8040, Loss: 0.1388
Epoch   7 Batch  720/1077 - Train Accuracy: 0.7858, Validation Accuracy: 0.7955, Loss: 0.1837
Epoch   7 Batch  740/1077 - Train Accuracy: 0.8402, Validation Accuracy: 0.8327, Loss: 0.1478
Epoch   7 Batch  760/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.8342, Loss: 0.1696
Epoch   7 Batch  780/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.8342, Loss: 0.1697
Epoch   7 Batch  800/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.8178, Loss: 0.1563
Epoch   7 Batch  820/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.8281, Loss: 0.1554
Epoch   7 Batch  840/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8381, Loss: 0.1414
Epoch   7 Batch  860/1077 - Train Accuracy: 0.8140, Validation Accuracy: 0.8406, Loss: 0.1486
Epoch   7 Batch  880/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8455, Loss: 0.1421
Epoch   7 Batch  900/1077 - Train Accuracy: 0.8414, Validation Accuracy: 0.8093, Loss: 0.1682
Epoch   7 Batch  920/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8409, Loss: 0.1536
Epoch   7 Batch  940/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8285, Loss: 0.1393
Epoch   7 Batch  960/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8292, Loss: 0.1322
Epoch   7 Batch  980/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.8565, Loss: 0.1572
Epoch   7 Batch 1000/1077 - Train Accuracy: 0.8575, Validation Accuracy: 0.8640, Loss: 0.1321
Epoch   7 Batch 1020/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8537, Loss: 0.1281
Epoch   7 Batch 1040/1077 - Train Accuracy: 0.8454, Validation Accuracy: 0.8214, Loss: 0.1475
Epoch   7 Batch 1060/1077 - Train Accuracy: 0.8215, Validation Accuracy: 0.7965, Loss: 0.1628
Epoch   8 Batch   20/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8118, Loss: 0.1258
Epoch   8 Batch   40/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8523, Loss: 0.1304
Epoch   8 Batch   60/1077 - Train Accuracy: 0.8612, Validation Accuracy: 0.8459, Loss: 0.1298
Epoch   8 Batch   80/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8395, Loss: 0.1351
Epoch   8 Batch  100/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8622, Loss: 0.1325
Epoch   8 Batch  120/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8612, Loss: 0.1449
Epoch   8 Batch  140/1077 - Train Accuracy: 0.8220, Validation Accuracy: 0.8576, Loss: 0.1366
Epoch   8 Batch  160/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8665, Loss: 0.1349
Epoch   8 Batch  180/1077 - Train Accuracy: 0.8633, Validation Accuracy: 0.8427, Loss: 0.1214
Epoch   8 Batch  200/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.8562, Loss: 0.1383
Epoch   8 Batch  220/1077 - Train Accuracy: 0.8536, Validation Accuracy: 0.8430, Loss: 0.1332
Epoch   8 Batch  240/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8370, Loss: 0.1231
Epoch   8 Batch  260/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8338, Loss: 0.1199
Epoch   8 Batch  280/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.8413, Loss: 0.1317
Epoch   8 Batch  300/1077 - Train Accuracy: 0.8894, Validation Accuracy: 0.8484, Loss: 0.1228
Epoch   8 Batch  320/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8459, Loss: 0.1412
Epoch   8 Batch  340/1077 - Train Accuracy: 0.8845, Validation Accuracy: 0.8636, Loss: 0.1259
Epoch   8 Batch  360/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8654, Loss: 0.1166
Epoch   8 Batch  380/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8622, Loss: 0.1137
Epoch   8 Batch  400/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8679, Loss: 0.1368
Epoch   8 Batch  420/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8718, Loss: 0.1127
Epoch   8 Batch  440/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.8370, Loss: 0.1383
Epoch   8 Batch  460/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8551, Loss: 0.1378
Epoch   8 Batch  480/1077 - Train Accuracy: 0.8964, Validation Accuracy: 0.8548, Loss: 0.1252
Epoch   8 Batch  500/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8462, Loss: 0.1133
Epoch   8 Batch  520/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8420, Loss: 0.1112
Epoch   8 Batch  540/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8491, Loss: 0.1003
Epoch   8 Batch  560/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8725, Loss: 0.1136
Epoch   8 Batch  580/1077 - Train Accuracy: 0.8757, Validation Accuracy: 0.8438, Loss: 0.1088
Epoch   8 Batch  600/1077 - Train Accuracy: 0.8821, Validation Accuracy: 0.8558, Loss: 0.1218
Epoch   8 Batch  620/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8707, Loss: 0.1186
Epoch   8 Batch  640/1077 - Train Accuracy: 0.8698, Validation Accuracy: 0.8455, Loss: 0.1187
Epoch   8 Batch  660/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8672, Loss: 0.1223
Epoch   8 Batch  680/1077 - Train Accuracy: 0.8456, Validation Accuracy: 0.8491, Loss: 0.1186
Epoch   8 Batch  700/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8533, Loss: 0.1073
Epoch   8 Batch  720/1077 - Train Accuracy: 0.8162, Validation Accuracy: 0.8395, Loss: 0.1472
Epoch   8 Batch  740/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8473, Loss: 0.1128
Epoch   8 Batch  760/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8622, Loss: 0.1331
Epoch   8 Batch  780/1077 - Train Accuracy: 0.8152, Validation Accuracy: 0.8775, Loss: 0.1390
Epoch   8 Batch  800/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8640, Loss: 0.1269
Epoch   8 Batch  820/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8576, Loss: 0.1230
Epoch   8 Batch  840/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8690, Loss: 0.1107
Epoch   8 Batch  860/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8555, Loss: 0.1205
Epoch   8 Batch  880/1077 - Train Accuracy: 0.9039, Validation Accuracy: 0.8839, Loss: 0.1142
Epoch   8 Batch  900/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.7969, Loss: 0.1421
Epoch   8 Batch  920/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8477, Loss: 0.1262
Epoch   8 Batch  940/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8395, Loss: 0.1167
Epoch   8 Batch  960/1077 - Train Accuracy: 0.8531, Validation Accuracy: 0.8359, Loss: 0.1095
Epoch   8 Batch  980/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8832, Loss: 0.1265
Epoch   8 Batch 1000/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8928, Loss: 0.1094
Epoch   8 Batch 1020/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8778, Loss: 0.1003
Epoch   8 Batch 1040/1077 - Train Accuracy: 0.8643, Validation Accuracy: 0.8430, Loss: 0.1179
Epoch   8 Batch 1060/1077 - Train Accuracy: 0.8461, Validation Accuracy: 0.8260, Loss: 0.1167
Epoch   9 Batch   20/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8711, Loss: 0.0957
Epoch   9 Batch   40/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8732, Loss: 0.1022
Epoch   9 Batch   60/1077 - Train Accuracy: 0.9003, Validation Accuracy: 0.8796, Loss: 0.1006
Epoch   9 Batch   80/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8665, Loss: 0.1083
Epoch   9 Batch  100/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8903, Loss: 0.1043
Epoch   9 Batch  120/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8810, Loss: 0.1191
Epoch   9 Batch  140/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8885, Loss: 0.1029
Epoch   9 Batch  160/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8977, Loss: 0.1070
Epoch   9 Batch  180/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8707, Loss: 0.0967
Epoch   9 Batch  200/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.9013, Loss: 0.1101
Epoch   9 Batch  220/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8924, Loss: 0.1047
Epoch   9 Batch  240/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8846, Loss: 0.0975
Epoch   9 Batch  260/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8580, Loss: 0.0948
Epoch   9 Batch  280/1077 - Train Accuracy: 0.8520, Validation Accuracy: 0.8693, Loss: 0.1061
Epoch   9 Batch  300/1077 - Train Accuracy: 0.9350, Validation Accuracy: 0.8739, Loss: 0.0930
Epoch   9 Batch  320/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8594, Loss: 0.1129
Epoch   9 Batch  340/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8896, Loss: 0.0980
Epoch   9 Batch  360/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8920, Loss: 0.0885
Epoch   9 Batch  380/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8928, Loss: 0.0854
Epoch   9 Batch  400/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8857, Loss: 0.1066
Epoch   9 Batch  420/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8999, Loss: 0.0869
Epoch   9 Batch  440/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8746, Loss: 0.1117
Epoch   9 Batch  460/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8793, Loss: 0.1078
Epoch   9 Batch  480/1077 - Train Accuracy: 0.9058, Validation Accuracy: 0.8853, Loss: 0.0934
Epoch   9 Batch  500/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8871, Loss: 0.0870
Epoch   9 Batch  520/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8960, Loss: 0.0871
Epoch   9 Batch  540/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8956, Loss: 0.0758
Epoch   9 Batch  560/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.9009, Loss: 0.0883
Epoch   9 Batch  580/1077 - Train Accuracy: 0.9036, Validation Accuracy: 0.8807, Loss: 0.0859
Epoch   9 Batch  600/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8725, Loss: 0.0978
Epoch   9 Batch  620/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8917, Loss: 0.0908
Epoch   9 Batch  640/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8949, Loss: 0.0927
Epoch   9 Batch  660/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8928, Loss: 0.0917
Epoch   9 Batch  680/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8924, Loss: 0.0981
Epoch   9 Batch  700/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8746, Loss: 0.0850
Epoch   9 Batch  720/1077 - Train Accuracy: 0.8372, Validation Accuracy: 0.8668, Loss: 0.1193
Epoch   9 Batch  740/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8849, Loss: 0.0880
Epoch   9 Batch  760/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8899, Loss: 0.1058
Epoch   9 Batch  780/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8991, Loss: 0.1140
Epoch   9 Batch  800/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8967, Loss: 0.0933
Epoch   9 Batch  820/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8810, Loss: 0.0962
Epoch   9 Batch  840/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8853, Loss: 0.0877
Epoch   9 Batch  860/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8920, Loss: 0.0965
Epoch   9 Batch  880/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9013, Loss: 0.0915
Epoch   9 Batch  900/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8420, Loss: 0.1106
Epoch   9 Batch  920/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8995, Loss: 0.0959
Epoch   9 Batch  940/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8693, Loss: 0.0871
Epoch   9 Batch  960/1077 - Train Accuracy: 0.8679, Validation Accuracy: 0.8754, Loss: 0.0813
Epoch   9 Batch  980/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.9031, Loss: 0.0994
Epoch   9 Batch 1000/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8984, Loss: 0.0881
Epoch   9 Batch 1020/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.8853, Loss: 0.0771
Epoch   9 Batch 1040/1077 - Train Accuracy: 0.8869, Validation Accuracy: 0.8803, Loss: 0.0909
Epoch   9 Batch 1060/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8565, Loss: 0.0972
Epoch  10 Batch   20/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8949, Loss: 0.0751
Epoch  10 Batch   40/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9016, Loss: 0.0790
Epoch  10 Batch   60/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8899, Loss: 0.0789
Epoch  10 Batch   80/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8924, Loss: 0.0839
Epoch  10 Batch  100/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8963, Loss: 0.0823
Epoch  10 Batch  120/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8810, Loss: 0.0938
Epoch  10 Batch  140/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8974, Loss: 0.0803
Epoch  10 Batch  160/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9112, Loss: 0.0842
Epoch  10 Batch  180/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8860, Loss: 0.0761
Epoch  10 Batch  200/1077 - Train Accuracy: 0.8617, Validation Accuracy: 0.9066, Loss: 0.0876
Epoch  10 Batch  220/1077 - Train Accuracy: 0.9091, Validation Accuracy: 0.8903, Loss: 0.0824
Epoch  10 Batch  240/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.9045, Loss: 0.0760
Epoch  10 Batch  260/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8832, Loss: 0.0720
Epoch  10 Batch  280/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8800, Loss: 0.0844
Epoch  10 Batch  300/1077 - Train Accuracy: 0.9433, Validation Accuracy: 0.8839, Loss: 0.0730
Epoch  10 Batch  320/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8686, Loss: 0.0911
Epoch  10 Batch  340/1077 - Train Accuracy: 0.9116, Validation Accuracy: 0.8970, Loss: 0.0769
Epoch  10 Batch  360/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9031, Loss: 0.0695
Epoch  10 Batch  380/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9073, Loss: 0.0666
Epoch  10 Batch  400/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8999, Loss: 0.0857
Epoch  10 Batch  420/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9205, Loss: 0.0677
Epoch  10 Batch  440/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.9002, Loss: 0.0914
Epoch  10 Batch  460/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8974, Loss: 0.0871
Epoch  10 Batch  480/1077 - Train Accuracy: 0.9305, Validation Accuracy: 0.9034, Loss: 0.0754
Epoch  10 Batch  500/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.9031, Loss: 0.0690
Epoch  10 Batch  520/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.8970, Loss: 0.0691
Epoch  10 Batch  540/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9016, Loss: 0.0585
Epoch  10 Batch  560/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.9183, Loss: 0.0719
Epoch  10 Batch  580/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8977, Loss: 0.0687
Epoch  10 Batch  600/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9034, Loss: 0.0825
Epoch  10 Batch  620/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9109, Loss: 0.0722
Epoch  10 Batch  640/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.9119, Loss: 0.0736
Epoch  10 Batch  660/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8999, Loss: 0.0727
Epoch  10 Batch  680/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8945, Loss: 0.0806
Epoch  10 Batch  700/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8846, Loss: 0.0679
Epoch  10 Batch  720/1077 - Train Accuracy: 0.8647, Validation Accuracy: 0.8796, Loss: 0.1044
Epoch  10 Batch  740/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.9002, Loss: 0.0725
Epoch  10 Batch  760/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.9023, Loss: 0.0863
Epoch  10 Batch  780/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.9109, Loss: 0.0975
Epoch  10 Batch  800/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.9151, Loss: 0.0739
Epoch  10 Batch  820/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.9023, Loss: 0.0761
Epoch  10 Batch  840/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.9038, Loss: 0.0716
Epoch  10 Batch  860/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8981, Loss: 0.0809
Epoch  10 Batch  880/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.9141, Loss: 0.0768
Epoch  10 Batch  900/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8590, Loss: 0.0904
Epoch  10 Batch  920/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.9070, Loss: 0.0781
Epoch  10 Batch  940/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8991, Loss: 0.0709
Epoch  10 Batch  960/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8999, Loss: 0.0675
Epoch  10 Batch  980/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.9158, Loss: 0.0828
Epoch  10 Batch 1000/1077 - Train Accuracy: 0.9185, Validation Accuracy: 0.9364, Loss: 0.0731
Epoch  10 Batch 1020/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9077, Loss: 0.0616
Epoch  10 Batch 1040/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8977, Loss: 0.0731
Epoch  10 Batch 1060/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8938, Loss: 0.0790
Epoch  11 Batch   20/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.9041, Loss: 0.0615
Epoch  11 Batch   40/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.9112, Loss: 0.0628
Epoch  11 Batch   60/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.9141, Loss: 0.0630
Epoch  11 Batch   80/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.9119, Loss: 0.0688
Epoch  11 Batch  100/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.9116, Loss: 0.0695
Epoch  11 Batch  120/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.9244, Loss: 0.0775
Epoch  11 Batch  140/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.9244, Loss: 0.0655
Epoch  11 Batch  160/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.9279, Loss: 0.0690
Epoch  11 Batch  180/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8977, Loss: 0.0640
Epoch  11 Batch  200/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.9112, Loss: 0.0736
Epoch  11 Batch  220/1077 - Train Accuracy: 0.9186, Validation Accuracy: 0.9247, Loss: 0.0694
Epoch  11 Batch  240/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.9141, Loss: 0.0624
Epoch  11 Batch  260/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.9137, Loss: 0.0590
Epoch  11 Batch  280/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8903, Loss: 0.0734
Epoch  11 Batch  300/1077 - Train Accuracy: 0.9433, Validation Accuracy: 0.9066, Loss: 0.0600
Epoch  11 Batch  320/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.8899, Loss: 0.0791
Epoch  11 Batch  340/1077 - Train Accuracy: 0.9153, Validation Accuracy: 0.8949, Loss: 0.0644
Epoch  11 Batch  360/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9162, Loss: 0.0571
Epoch  11 Batch  380/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9197, Loss: 0.0550
Epoch  11 Batch  400/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9066, Loss: 0.0754
Epoch  11 Batch  420/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9208, Loss: 0.0564
Epoch  11 Batch  440/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.9052, Loss: 0.0778
Epoch  11 Batch  460/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9045, Loss: 0.0744
Epoch  11 Batch  480/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9109, Loss: 0.0617
Epoch  11 Batch  500/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9002, Loss: 0.0562
Epoch  11 Batch  520/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9119, Loss: 0.0570
Epoch  11 Batch  540/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9080, Loss: 0.0491
Epoch  11 Batch  560/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.9290, Loss: 0.0612
Epoch  11 Batch  580/1077 - Train Accuracy: 0.9278, Validation Accuracy: 0.9066, Loss: 0.0566
Epoch  11 Batch  600/1077 - Train Accuracy: 0.9200, Validation Accuracy: 0.9126, Loss: 0.0683
Epoch  11 Batch  620/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.9109, Loss: 0.0611
Epoch  11 Batch  640/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.9052, Loss: 0.0583
Epoch  11 Batch  660/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.9073, Loss: 0.0627
Epoch  11 Batch  680/1077 - Train Accuracy: 0.8757, Validation Accuracy: 0.9073, Loss: 0.0680
Epoch  11 Batch  700/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8991, Loss: 0.0614
Epoch  11 Batch  720/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8906, Loss: 0.0973
Epoch  11 Batch  740/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9173, Loss: 0.0658
Epoch  11 Batch  760/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9070, Loss: 0.0741
Epoch  11 Batch  780/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.9126, Loss: 0.0870
Epoch  11 Batch  800/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.9212, Loss: 0.0658
Epoch  11 Batch  820/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.9137, Loss: 0.0648
Epoch  11 Batch  840/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.9212, Loss: 0.0577
Epoch  11 Batch  860/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.9055, Loss: 0.0685
Epoch  11 Batch  880/1077 - Train Accuracy: 0.9246, Validation Accuracy: 0.9297, Loss: 0.0679
Epoch  11 Batch  900/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.8867, Loss: 0.0747
Epoch  11 Batch  920/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9048, Loss: 0.0707
Epoch  11 Batch  940/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.9169, Loss: 0.0634
Epoch  11 Batch  960/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.9098, Loss: 0.0593
Epoch  11 Batch  980/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.9158, Loss: 0.0723
Epoch  11 Batch 1000/1077 - Train Accuracy: 0.9282, Validation Accuracy: 0.9371, Loss: 0.0631
Epoch  11 Batch 1020/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9059, Loss: 0.0525
Epoch  11 Batch 1040/1077 - Train Accuracy: 0.9206, Validation Accuracy: 0.9158, Loss: 0.0625
Epoch  11 Batch 1060/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.9094, Loss: 0.0581
Epoch  12 Batch   20/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.9031, Loss: 0.0541
Epoch  12 Batch   40/1077 - Train Accuracy: 0.9305, Validation Accuracy: 0.9173, Loss: 0.0521
Epoch  12 Batch   60/1077 - Train Accuracy: 0.9263, Validation Accuracy: 0.9041, Loss: 0.0519
Epoch  12 Batch   80/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9197, Loss: 0.0584
Epoch  12 Batch  100/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.9308, Loss: 0.0598
Epoch  12 Batch  120/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9237, Loss: 0.0669
Epoch  12 Batch  140/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.9070, Loss: 0.0581
Epoch  12 Batch  160/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.9226, Loss: 0.0586
Epoch  12 Batch  180/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9084, Loss: 0.0548
Epoch  12 Batch  200/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.9098, Loss: 0.0634
Epoch  12 Batch  220/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9393, Loss: 0.0604
Epoch  12 Batch  240/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9169, Loss: 0.0519
Epoch  12 Batch  260/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.9173, Loss: 0.0503
Epoch  12 Batch  280/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.9197, Loss: 0.0635
Epoch  12 Batch  300/1077 - Train Accuracy: 0.9346, Validation Accuracy: 0.9219, Loss: 0.0542
Epoch  12 Batch  320/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9052, Loss: 0.0699
Epoch  12 Batch  340/1077 - Train Accuracy: 0.9256, Validation Accuracy: 0.9006, Loss: 0.0540
Epoch  12 Batch  360/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9105, Loss: 0.0491
Epoch  12 Batch  380/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9251, Loss: 0.0471
Epoch  12 Batch  400/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.9276, Loss: 0.0674
Epoch  12 Batch  420/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9134, Loss: 0.0477
Epoch  12 Batch  440/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.9141, Loss: 0.0670
Epoch  12 Batch  460/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8984, Loss: 0.0690
Epoch  12 Batch  480/1077 - Train Accuracy: 0.9428, Validation Accuracy: 0.9116, Loss: 0.0520
Epoch  12 Batch  500/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9066, Loss: 0.0475
Epoch  12 Batch  520/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9162, Loss: 0.0507
Epoch  12 Batch  540/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9244, Loss: 0.0432
Epoch  12 Batch  560/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.9315, Loss: 0.0544
Epoch  12 Batch  580/1077 - Train Accuracy: 0.9353, Validation Accuracy: 0.9329, Loss: 0.0469
Epoch  12 Batch  600/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9116, Loss: 0.0593
Epoch  12 Batch  620/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.9158, Loss: 0.0514
Epoch  12 Batch  640/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.9308, Loss: 0.0497
Epoch  12 Batch  660/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9173, Loss: 0.0496
Epoch  12 Batch  680/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.9080, Loss: 0.0599
Epoch  12 Batch  700/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9279, Loss: 0.0545
Epoch  12 Batch  720/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8867, Loss: 0.0923
Epoch  12 Batch  740/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.9215, Loss: 0.0579
Epoch  12 Batch  760/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9094, Loss: 0.0641
Epoch  12 Batch  780/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.9155, Loss: 0.0775
Epoch  12 Batch  800/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.9233, Loss: 0.0583
Epoch  12 Batch  820/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.9162, Loss: 0.0569
Epoch  12 Batch  840/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.9148, Loss: 0.0492
Epoch  12 Batch  860/1077 - Train Accuracy: 0.9282, Validation Accuracy: 0.9215, Loss: 0.0617
Epoch  12 Batch  880/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9279, Loss: 0.0614
Epoch  12 Batch  900/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9336, Loss: 0.0654
Epoch  12 Batch  920/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.9134, Loss: 0.0596
Epoch  12 Batch  940/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.9141, Loss: 0.0561
Epoch  12 Batch  960/1077 - Train Accuracy: 0.9103, Validation Accuracy: 0.9013, Loss: 0.0526
Epoch  12 Batch  980/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.9212, Loss: 0.0640
Epoch  12 Batch 1000/1077 - Train Accuracy: 0.9267, Validation Accuracy: 0.9347, Loss: 0.0552
Epoch  12 Batch 1020/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9229, Loss: 0.0450
Epoch  12 Batch 1040/1077 - Train Accuracy: 0.9317, Validation Accuracy: 0.9212, Loss: 0.0536
Epoch  12 Batch 1060/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.9123, Loss: 0.0521
Epoch  13 Batch   20/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.9165, Loss: 0.0481
Epoch  13 Batch   40/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9254, Loss: 0.0463
Epoch  13 Batch   60/1077 - Train Accuracy: 0.9308, Validation Accuracy: 0.9027, Loss: 0.0451
Epoch  13 Batch   80/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.9116, Loss: 0.0505
Epoch  13 Batch  100/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9254, Loss: 0.0537
Epoch  13 Batch  120/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9290, Loss: 0.0582
Epoch  13 Batch  140/1077 - Train Accuracy: 0.9350, Validation Accuracy: 0.9144, Loss: 0.0503
Epoch  13 Batch  160/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.9244, Loss: 0.0500
Epoch  13 Batch  180/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.9215, Loss: 0.0506
Epoch  13 Batch  200/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9084, Loss: 0.0565
Epoch  13 Batch  220/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.9290, Loss: 0.0553
Epoch  13 Batch  240/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9180, Loss: 0.0443
Epoch  13 Batch  260/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9247, Loss: 0.0435
Epoch  13 Batch  280/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.9268, Loss: 0.0569
Epoch  13 Batch  300/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9165, Loss: 0.0472
Epoch  13 Batch  320/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9187, Loss: 0.0627
Epoch  13 Batch  340/1077 - Train Accuracy: 0.9428, Validation Accuracy: 0.9094, Loss: 0.0517
Epoch  13 Batch  360/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9208, Loss: 0.0424
Epoch  13 Batch  380/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9205, Loss: 0.0415
Epoch  13 Batch  400/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.9343, Loss: 0.0622
Epoch  13 Batch  420/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9084, Loss: 0.0407
Epoch  13 Batch  440/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.9219, Loss: 0.0596
Epoch  13 Batch  460/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8928, Loss: 0.0577
Epoch  13 Batch  480/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9180, Loss: 0.0450
Epoch  13 Batch  500/1077 - Train Accuracy: 0.9336, Validation Accuracy: 0.9002, Loss: 0.0415
Epoch  13 Batch  520/1077 - Train Accuracy: 0.9475, Validation Accuracy: 0.9265, Loss: 0.0463
Epoch  13 Batch  540/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9162, Loss: 0.0378
Epoch  13 Batch  560/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9268, Loss: 0.0479
Epoch  13 Batch  580/1077 - Train Accuracy: 0.9390, Validation Accuracy: 0.9297, Loss: 0.0406
Epoch  13 Batch  600/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9158, Loss: 0.0540
Epoch  13 Batch  620/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9212, Loss: 0.0459
Epoch  13 Batch  640/1077 - Train Accuracy: 0.9241, Validation Accuracy: 0.9229, Loss: 0.0447
Epoch  13 Batch  660/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9134, Loss: 0.0445
Epoch  13 Batch  680/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9215, Loss: 0.0536
Epoch  13 Batch  700/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9339, Loss: 0.0449
Epoch  13 Batch  720/1077 - Train Accuracy: 0.9157, Validation Accuracy: 0.9041, Loss: 0.0845
Epoch  13 Batch  740/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9268, Loss: 0.0505
Epoch  13 Batch  760/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9144, Loss: 0.0572
Epoch  13 Batch  780/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.9258, Loss: 0.0687
Epoch  13 Batch  800/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9293, Loss: 0.0501
Epoch  13 Batch  820/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.9112, Loss: 0.0497
Epoch  13 Batch  840/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9119, Loss: 0.0432
Epoch  13 Batch  860/1077 - Train Accuracy: 0.9271, Validation Accuracy: 0.9233, Loss: 0.0547
Epoch  13 Batch  880/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9251, Loss: 0.0552
Epoch  13 Batch  900/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9205, Loss: 0.0586
Epoch  13 Batch  920/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9158, Loss: 0.0535
Epoch  13 Batch  940/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.9031, Loss: 0.0524
Epoch  13 Batch  960/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.9123, Loss: 0.0472
Epoch  13 Batch  980/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.9201, Loss: 0.0569
Epoch  13 Batch 1000/1077 - Train Accuracy: 0.9356, Validation Accuracy: 0.9279, Loss: 0.0489
Epoch  13 Batch 1020/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9237, Loss: 0.0401
Epoch  13 Batch 1040/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9268, Loss: 0.0481
Epoch  13 Batch 1060/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.9045, Loss: 0.0465
Epoch  14 Batch   20/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.9205, Loss: 0.0419
Epoch  14 Batch   40/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9205, Loss: 0.0408
Epoch  14 Batch   60/1077 - Train Accuracy: 0.9267, Validation Accuracy: 0.9038, Loss: 0.0402
Epoch  14 Batch   80/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.9197, Loss: 0.0447
Epoch  14 Batch  100/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.9254, Loss: 0.0488
Epoch  14 Batch  120/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.9336, Loss: 0.0529
Epoch  14 Batch  140/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9109, Loss: 0.0458
Epoch  14 Batch  160/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.9293, Loss: 0.0439
Epoch  14 Batch  180/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.9332, Loss: 0.0472
Epoch  14 Batch  200/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.9251, Loss: 0.0499
Epoch  14 Batch  220/1077 - Train Accuracy: 0.9478, Validation Accuracy: 0.9208, Loss: 0.0477
Epoch  14 Batch  240/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9197, Loss: 0.0395
Epoch  14 Batch  260/1077 - Train Accuracy: 0.9286, Validation Accuracy: 0.9233, Loss: 0.0390
Epoch  14 Batch  280/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.9251, Loss: 0.0521
Epoch  14 Batch  300/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9165, Loss: 0.0433
Epoch  14 Batch  320/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9244, Loss: 0.0569
Epoch  14 Batch  340/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9183, Loss: 0.0454
Epoch  14 Batch  360/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9205, Loss: 0.0370
Epoch  14 Batch  380/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9148, Loss: 0.0373
Epoch  14 Batch  400/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.9368, Loss: 0.0543
Epoch  14 Batch  420/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9205, Loss: 0.0382
Epoch  14 Batch  440/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9180, Loss: 0.0534
Epoch  14 Batch  460/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9048, Loss: 0.0538
Epoch  14 Batch  480/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9251, Loss: 0.0407
Epoch  14 Batch  500/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9148, Loss: 0.0362
Epoch  14 Batch  520/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9205, Loss: 0.0425
Epoch  14 Batch  540/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9339, Loss: 0.0350
Epoch  14 Batch  560/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9272, Loss: 0.0442
Epoch  14 Batch  580/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9222, Loss: 0.0360
Epoch  14 Batch  600/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9190, Loss: 0.0483
Epoch  14 Batch  620/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9258, Loss: 0.0408
Epoch  14 Batch  640/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9265, Loss: 0.0402
Epoch  14 Batch  660/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9151, Loss: 0.0395
Epoch  14 Batch  680/1077 - Train Accuracy: 0.9200, Validation Accuracy: 0.9237, Loss: 0.0491
Epoch  14 Batch  700/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9279, Loss: 0.0399
Epoch  14 Batch  720/1077 - Train Accuracy: 0.8882, Validation Accuracy: 0.9176, Loss: 0.0621
Epoch  14 Batch  740/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9094, Loss: 0.0521
Epoch  14 Batch  760/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9098, Loss: 0.0522
Epoch  14 Batch  780/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.9318, Loss: 0.0637
Epoch  14 Batch  800/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9297, Loss: 0.0442
Epoch  14 Batch  820/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.9283, Loss: 0.0449
Epoch  14 Batch  840/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9311, Loss: 0.0382
Epoch  14 Batch  860/1077 - Train Accuracy: 0.9394, Validation Accuracy: 0.9290, Loss: 0.0496
Epoch  14 Batch  880/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9311, Loss: 0.0517
Epoch  14 Batch  900/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9105, Loss: 0.0526
Epoch  14 Batch  920/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9226, Loss: 0.0495
Epoch  14 Batch  940/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9148, Loss: 0.0493
Epoch  14 Batch  960/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.9134, Loss: 0.0416
Epoch  14 Batch  980/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.9304, Loss: 0.0500
Epoch  14 Batch 1000/1077 - Train Accuracy: 0.9390, Validation Accuracy: 0.9237, Loss: 0.0444
Epoch  14 Batch 1020/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9290, Loss: 0.0362
Epoch  14 Batch 1040/1077 - Train Accuracy: 0.9433, Validation Accuracy: 0.9332, Loss: 0.0450
Epoch  14 Batch 1060/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.9180, Loss: 0.0426
Epoch  15 Batch   20/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.9176, Loss: 0.0376
Epoch  15 Batch   40/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9354, Loss: 0.0364
Epoch  15 Batch   60/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.9091, Loss: 0.0355
Epoch  15 Batch   80/1077 - Train Accuracy: 0.9277, Validation Accuracy: 0.9315, Loss: 0.0414
Epoch  15 Batch  100/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.9233, Loss: 0.0456
Epoch  15 Batch  120/1077 - Train Accuracy: 0.9277, Validation Accuracy: 0.9332, Loss: 0.0486
Epoch  15 Batch  140/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9119, Loss: 0.0409
Epoch  15 Batch  160/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9290, Loss: 0.0411
Epoch  15 Batch  180/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.9371, Loss: 0.0428
Epoch  15 Batch  200/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9279, Loss: 0.0431
Epoch  15 Batch  220/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9293, Loss: 0.0427
Epoch  15 Batch  240/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9229, Loss: 0.0351
Epoch  15 Batch  260/1077 - Train Accuracy: 0.9286, Validation Accuracy: 0.9308, Loss: 0.0349
Epoch  15 Batch  280/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.9254, Loss: 0.0489
Epoch  15 Batch  300/1077 - Train Accuracy: 0.9400, Validation Accuracy: 0.9318, Loss: 0.0394
Epoch  15 Batch  320/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9215, Loss: 0.0530
Epoch  15 Batch  340/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9173, Loss: 0.0393
Epoch  15 Batch  360/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9215, Loss: 0.0341
Epoch  15 Batch  380/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9244, Loss: 0.0340
Epoch  15 Batch  400/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9212, Loss: 0.0476
Epoch  15 Batch  420/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9176, Loss: 0.0331
Epoch  15 Batch  440/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.9148, Loss: 0.0482
Epoch  15 Batch  460/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.9013, Loss: 0.0510
Epoch  15 Batch  480/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9347, Loss: 0.0356
Epoch  15 Batch  500/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9077, Loss: 0.0327
Epoch  15 Batch  520/1077 - Train Accuracy: 0.9561, Validation Accuracy: 0.9286, Loss: 0.0422
Epoch  15 Batch  540/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9126, Loss: 0.0312
Epoch  15 Batch  560/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9318, Loss: 0.0413
Epoch  15 Batch  580/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9222, Loss: 0.0331
Epoch  15 Batch  600/1077 - Train Accuracy: 0.9554, Validation Accuracy: 0.9183, Loss: 0.0443
Epoch  15 Batch  620/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9272, Loss: 0.0373
Epoch  15 Batch  640/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.9300, Loss: 0.0370
Epoch  15 Batch  660/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9038, Loss: 0.0339
Epoch  15 Batch  680/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9247, Loss: 0.0444
Epoch  15 Batch  700/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9354, Loss: 0.0362
Epoch  15 Batch  720/1077 - Train Accuracy: 0.9095, Validation Accuracy: 0.9318, Loss: 0.0513
Epoch  15 Batch  740/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9158, Loss: 0.0439
Epoch  15 Batch  760/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9194, Loss: 0.0468
Epoch  15 Batch  780/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.9244, Loss: 0.0575
Epoch  15 Batch  800/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9499, Loss: 0.0391
Epoch  15 Batch  820/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.9329, Loss: 0.0413
Epoch  15 Batch  840/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9332, Loss: 0.0348
Epoch  15 Batch  860/1077 - Train Accuracy: 0.9345, Validation Accuracy: 0.9247, Loss: 0.0462
Epoch  15 Batch  880/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9329, Loss: 0.0485
Epoch  15 Batch  900/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9102, Loss: 0.0476
Epoch  15 Batch  920/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9325, Loss: 0.0454
Epoch  15 Batch  940/1077 - Train Accuracy: 0.9320, Validation Accuracy: 0.9208, Loss: 0.0446
Epoch  15 Batch  960/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9247, Loss: 0.0386
Epoch  15 Batch  980/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.9350, Loss: 0.0466
Epoch  15 Batch 1000/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9265, Loss: 0.0409
Epoch  15 Batch 1020/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9109, Loss: 0.0324
Epoch  15 Batch 1040/1077 - Train Accuracy: 0.9626, Validation Accuracy: 0.9283, Loss: 0.0413
Epoch  15 Batch 1060/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9254, Loss: 0.0479
Epoch  16 Batch   20/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9151, Loss: 0.0367
Epoch  16 Batch   40/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9411, Loss: 0.0330
Epoch  16 Batch   60/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.8956, Loss: 0.0322
Epoch  16 Batch   80/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9258, Loss: 0.0355
Epoch  16 Batch  100/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9219, Loss: 0.0427
Epoch  16 Batch  120/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9272, Loss: 0.0432
Epoch  16 Batch  140/1077 - Train Accuracy: 0.9206, Validation Accuracy: 0.9041, Loss: 0.0385
Epoch  16 Batch  160/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9205, Loss: 0.0360
Epoch  16 Batch  180/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9375, Loss: 0.0391
Epoch  16 Batch  200/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9300, Loss: 0.0381
Epoch  16 Batch  220/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9411, Loss: 0.0387
Epoch  16 Batch  240/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9251, Loss: 0.0308
Epoch  16 Batch  260/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9290, Loss: 0.0314
Epoch  16 Batch  280/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.9286, Loss: 0.0461
Epoch  16 Batch  300/1077 - Train Accuracy: 0.9482, Validation Accuracy: 0.9474, Loss: 0.0360
Epoch  16 Batch  320/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9240, Loss: 0.0508
Epoch  16 Batch  340/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9304, Loss: 0.0365
Epoch  16 Batch  360/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9297, Loss: 0.0313
Epoch  16 Batch  380/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9272, Loss: 0.0316
Epoch  16 Batch  400/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.9215, Loss: 0.0436
Epoch  16 Batch  420/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9208, Loss: 0.0315
Epoch  16 Batch  440/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.9165, Loss: 0.0445
Epoch  16 Batch  460/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.9002, Loss: 0.0468
Epoch  16 Batch  480/1077 - Train Accuracy: 0.9626, Validation Accuracy: 0.9173, Loss: 0.0337
Epoch  16 Batch  500/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9155, Loss: 0.0321
Epoch  16 Batch  520/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9254, Loss: 0.0366
Epoch  16 Batch  540/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9332, Loss: 0.0282
Epoch  16 Batch  560/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9350, Loss: 0.0391
Epoch  16 Batch  580/1077 - Train Accuracy: 0.9490, Validation Accuracy: 0.9233, Loss: 0.0304
Epoch  16 Batch  600/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9375, Loss: 0.0403
Epoch  16 Batch  620/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9208, Loss: 0.0351
Epoch  16 Batch  640/1077 - Train Accuracy: 0.9386, Validation Accuracy: 0.9265, Loss: 0.0349
Epoch  16 Batch  660/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9148, Loss: 0.0309
Epoch  16 Batch  680/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9361, Loss: 0.0401
Epoch  16 Batch  700/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9411, Loss: 0.0335
Epoch  16 Batch  720/1077 - Train Accuracy: 0.9030, Validation Accuracy: 0.9393, Loss: 0.0464
Epoch  16 Batch  740/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9144, Loss: 0.0376
Epoch  16 Batch  760/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9261, Loss: 0.0409
Epoch  16 Batch  780/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9283, Loss: 0.0535
Epoch  16 Batch  800/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9496, Loss: 0.0353
Epoch  16 Batch  820/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9336, Loss: 0.0377
Epoch  16 Batch  840/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9329, Loss: 0.0317
Epoch  16 Batch  860/1077 - Train Accuracy: 0.9606, Validation Accuracy: 0.9432, Loss: 0.0428
Epoch  16 Batch  880/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9219, Loss: 0.0453
Epoch  16 Batch  900/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9219, Loss: 0.0482
Epoch  16 Batch  920/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9247, Loss: 0.0420
Epoch  16 Batch  940/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9130, Loss: 0.0415
Epoch  16 Batch  960/1077 - Train Accuracy: 0.9487, Validation Accuracy: 0.9219, Loss: 0.0359
Epoch  16 Batch  980/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.9350, Loss: 0.0445
Epoch  16 Batch 1000/1077 - Train Accuracy: 0.9405, Validation Accuracy: 0.9368, Loss: 0.0384
Epoch  16 Batch 1020/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9265, Loss: 0.0308
Epoch  16 Batch 1040/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9400, Loss: 0.0410
Epoch  16 Batch 1060/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9371, Loss: 0.0346
Epoch  17 Batch   20/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.9219, Loss: 0.0333
Epoch  17 Batch   40/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9382, Loss: 0.0294
Epoch  17 Batch   60/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9190, Loss: 0.0302
Epoch  17 Batch   80/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9293, Loss: 0.0313
Epoch  17 Batch  100/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.9368, Loss: 0.0377
Epoch  17 Batch  120/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9425, Loss: 0.0393
Epoch  17 Batch  140/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.9169, Loss: 0.0346
Epoch  17 Batch  160/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9304, Loss: 0.0324
Epoch  17 Batch  180/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9368, Loss: 0.0359
Epoch  17 Batch  200/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9474, Loss: 0.0354
Epoch  17 Batch  220/1077 - Train Accuracy: 0.9642, Validation Accuracy: 0.9300, Loss: 0.0360
Epoch  17 Batch  240/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9233, Loss: 0.0286
Epoch  17 Batch  260/1077 - Train Accuracy: 0.9334, Validation Accuracy: 0.9279, Loss: 0.0291
Epoch  17 Batch  280/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.9322, Loss: 0.0431
Epoch  17 Batch  300/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9389, Loss: 0.0328
Epoch  17 Batch  320/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9318, Loss: 0.0486
Epoch  17 Batch  340/1077 - Train Accuracy: 0.9581, Validation Accuracy: 0.9276, Loss: 0.0334
Epoch  17 Batch  360/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9336, Loss: 0.0280
Epoch  17 Batch  380/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9286, Loss: 0.0284
Epoch  17 Batch  400/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9400, Loss: 0.0407
Epoch  17 Batch  420/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9158, Loss: 0.0294
Epoch  17 Batch  440/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9265, Loss: 0.0397
Epoch  17 Batch  460/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9190, Loss: 0.0438
Epoch  17 Batch  480/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9300, Loss: 0.0317
Epoch  17 Batch  500/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9240, Loss: 0.0300
Epoch  17 Batch  520/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9308, Loss: 0.0333
Epoch  17 Batch  540/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9283, Loss: 0.0255
Epoch  17 Batch  560/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9325, Loss: 0.0360
Epoch  17 Batch  580/1077 - Train Accuracy: 0.9487, Validation Accuracy: 0.9272, Loss: 0.0271
Epoch  17 Batch  600/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9521, Loss: 0.0374
Epoch  17 Batch  620/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9290, Loss: 0.0330
Epoch  17 Batch  640/1077 - Train Accuracy: 0.9405, Validation Accuracy: 0.9176, Loss: 0.0327
Epoch  17 Batch  660/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9180, Loss: 0.0289
Epoch  17 Batch  680/1077 - Train Accuracy: 0.9174, Validation Accuracy: 0.9343, Loss: 0.0374
Epoch  17 Batch  700/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9368, Loss: 0.0316
Epoch  17 Batch  720/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9421, Loss: 0.0414
Epoch  17 Batch  740/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9215, Loss: 0.0369
Epoch  17 Batch  760/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9265, Loss: 0.0389
Epoch  17 Batch  780/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.9180, Loss: 0.0487
Epoch  17 Batch  800/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9485, Loss: 0.0327
Epoch  17 Batch  820/1077 - Train Accuracy: 0.9320, Validation Accuracy: 0.9371, Loss: 0.0359
Epoch  17 Batch  840/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9471, Loss: 0.0311
Epoch  17 Batch  860/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9425, Loss: 0.0403
Epoch  17 Batch  880/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9279, Loss: 0.0416
Epoch  17 Batch  900/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9258, Loss: 0.0422
Epoch  17 Batch  920/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9329, Loss: 0.0384
Epoch  17 Batch  940/1077 - Train Accuracy: 0.9246, Validation Accuracy: 0.9119, Loss: 0.0397
Epoch  17 Batch  960/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9350, Loss: 0.0331
Epoch  17 Batch  980/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.9403, Loss: 0.0413
Epoch  17 Batch 1000/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9446, Loss: 0.0358
Epoch  17 Batch 1020/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9272, Loss: 0.0274
Epoch  17 Batch 1040/1077 - Train Accuracy: 0.9626, Validation Accuracy: 0.9407, Loss: 0.0371
Epoch  17 Batch 1060/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9229, Loss: 0.0318
Epoch  18 Batch   20/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9226, Loss: 0.0307
Epoch  18 Batch   40/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9361, Loss: 0.0271
Epoch  18 Batch   60/1077 - Train Accuracy: 0.9356, Validation Accuracy: 0.9173, Loss: 0.0284
Epoch  18 Batch   80/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9318, Loss: 0.0288
Epoch  18 Batch  100/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.9524, Loss: 0.0339
Epoch  18 Batch  120/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9354, Loss: 0.0361
Epoch  18 Batch  140/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.9222, Loss: 0.0325
Epoch  18 Batch  160/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9435, Loss: 0.0302
Epoch  18 Batch  180/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9382, Loss: 0.0323
Epoch  18 Batch  200/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9386, Loss: 0.0324
Epoch  18 Batch  220/1077 - Train Accuracy: 0.9634, Validation Accuracy: 0.9308, Loss: 0.0342
Epoch  18 Batch  240/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9286, Loss: 0.0270
Epoch  18 Batch  260/1077 - Train Accuracy: 0.9397, Validation Accuracy: 0.9343, Loss: 0.0270
Epoch  18 Batch  280/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9439, Loss: 0.0402
Epoch  18 Batch  300/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9538, Loss: 0.0308
Epoch  18 Batch  320/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9293, Loss: 0.0470
Epoch  18 Batch  340/1077 - Train Accuracy: 0.9622, Validation Accuracy: 0.9279, Loss: 0.0322
Epoch  18 Batch  360/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9375, Loss: 0.0350
Epoch  18 Batch  380/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9400, Loss: 0.0277
Epoch  18 Batch  400/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9428, Loss: 0.0385
Epoch  18 Batch  420/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9297, Loss: 0.0280
Epoch  18 Batch  440/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9432, Loss: 0.0366
Epoch  18 Batch  460/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9272, Loss: 0.0390
Epoch  18 Batch  480/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9379, Loss: 0.0267
Epoch  18 Batch  500/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9212, Loss: 0.0279
Epoch  18 Batch  520/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9265, Loss: 0.0306
Epoch  18 Batch  540/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9290, Loss: 0.0246
Epoch  18 Batch  560/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9442, Loss: 0.0343
Epoch  18 Batch  580/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9329, Loss: 0.0247
Epoch  18 Batch  600/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9439, Loss: 0.0346
Epoch  18 Batch  620/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9371, Loss: 0.0319
Epoch  18 Batch  640/1077 - Train Accuracy: 0.9360, Validation Accuracy: 0.9222, Loss: 0.0290
Epoch  18 Batch  660/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9208, Loss: 0.0264
Epoch  18 Batch  680/1077 - Train Accuracy: 0.9397, Validation Accuracy: 0.9396, Loss: 0.0341
Epoch  18 Batch  700/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9350, Loss: 0.0285
Epoch  18 Batch  720/1077 - Train Accuracy: 0.9079, Validation Accuracy: 0.9279, Loss: 0.0382
Epoch  18 Batch  740/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9116, Loss: 0.0347
Epoch  18 Batch  760/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9176, Loss: 0.0355
Epoch  18 Batch  780/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9400, Loss: 0.0481
Epoch  18 Batch  800/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9521, Loss: 0.0301
Epoch  18 Batch  820/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9421, Loss: 0.0323
Epoch  18 Batch  840/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9510, Loss: 0.0293
Epoch  18 Batch  860/1077 - Train Accuracy: 0.9580, Validation Accuracy: 0.9411, Loss: 0.0371
Epoch  18 Batch  880/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9411, Loss: 0.0400
Epoch  18 Batch  900/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9322, Loss: 0.0381
Epoch  18 Batch  920/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9389, Loss: 0.0358
Epoch  18 Batch  940/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9126, Loss: 0.0372
Epoch  18 Batch  960/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.9453, Loss: 0.0302
Epoch  18 Batch  980/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.9379, Loss: 0.0388
Epoch  18 Batch 1000/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9478, Loss: 0.0335
Epoch  18 Batch 1020/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9315, Loss: 0.0258
Epoch  18 Batch 1040/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9343, Loss: 0.0344
Epoch  18 Batch 1060/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9272, Loss: 0.0323
Epoch  19 Batch   20/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9325, Loss: 0.0322
Epoch  19 Batch   40/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9492, Loss: 0.0253
Epoch  19 Batch   60/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9187, Loss: 0.0262
Epoch  19 Batch   80/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9329, Loss: 0.0273
Epoch  19 Batch  100/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.9517, Loss: 0.0314
Epoch  19 Batch  120/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9361, Loss: 0.0332
Epoch  19 Batch  140/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9190, Loss: 0.0300
Epoch  19 Batch  160/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9485, Loss: 0.0280
Epoch  19 Batch  180/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9382, Loss: 0.0294
Epoch  19 Batch  200/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9332, Loss: 0.0308
Epoch  19 Batch  220/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9343, Loss: 0.0320
Epoch  19 Batch  240/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9251, Loss: 0.0248
Epoch  19 Batch  260/1077 - Train Accuracy: 0.9386, Validation Accuracy: 0.9325, Loss: 0.0252
Epoch  19 Batch  280/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.9464, Loss: 0.0372
Epoch  19 Batch  300/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9496, Loss: 0.0285
Epoch  19 Batch  320/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9286, Loss: 0.0438
Epoch  19 Batch  340/1077 - Train Accuracy: 0.9733, Validation Accuracy: 0.9428, Loss: 0.0302
Epoch  19 Batch  360/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9442, Loss: 0.0246
Epoch  19 Batch  380/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9403, Loss: 0.0254
Epoch  19 Batch  400/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9414, Loss: 0.0356
Epoch  19 Batch  420/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9258, Loss: 0.0242
Epoch  19 Batch  440/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.9439, Loss: 0.0357
Epoch  19 Batch  460/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9375, Loss: 0.0387
Epoch  19 Batch  480/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9382, Loss: 0.0250
Epoch  19 Batch  500/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9187, Loss: 0.0268
Epoch  19 Batch  520/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9371, Loss: 0.0284
Epoch  19 Batch  540/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9382, Loss: 0.0221
Epoch  19 Batch  560/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9407, Loss: 0.0330
Epoch  19 Batch  580/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9322, Loss: 0.0241
Epoch  19 Batch  600/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9467, Loss: 0.0313
Epoch  19 Batch  620/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9368, Loss: 0.0295
Epoch  19 Batch  640/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9361, Loss: 0.0270
Epoch  19 Batch  660/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9084, Loss: 0.0262
Epoch  19 Batch  680/1077 - Train Accuracy: 0.9382, Validation Accuracy: 0.9471, Loss: 0.0325
Epoch  19 Batch  700/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9425, Loss: 0.0268
Epoch  19 Batch  720/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.9453, Loss: 0.0346
Epoch  19 Batch  740/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9304, Loss: 0.0317
Epoch  19 Batch  760/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9325, Loss: 0.0344
Epoch  19 Batch  780/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9137, Loss: 0.0479
Epoch  19 Batch  800/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9595, Loss: 0.0288
Epoch  19 Batch  820/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9368, Loss: 0.0311
Epoch  19 Batch  840/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9510, Loss: 0.0298
Epoch  19 Batch  860/1077 - Train Accuracy: 0.9561, Validation Accuracy: 0.9510, Loss: 0.0368
Epoch  19 Batch  880/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9325, Loss: 0.0377
Epoch  19 Batch  900/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9279, Loss: 0.0384
Epoch  19 Batch  920/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9332, Loss: 0.0322
Epoch  19 Batch  940/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9151, Loss: 0.0356
Epoch  19 Batch  960/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9563, Loss: 0.0269
Epoch  19 Batch  980/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.9442, Loss: 0.0351
Epoch  19 Batch 1000/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9521, Loss: 0.0306
Epoch  19 Batch 1020/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9418, Loss: 0.0235
Epoch  19 Batch 1040/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9457, Loss: 0.0301
Epoch  19 Batch 1060/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9315, Loss: 0.0287
Epoch  20 Batch   20/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9407, Loss: 0.0284
Epoch  20 Batch   40/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9460, Loss: 0.0226
Epoch  20 Batch   60/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9233, Loss: 0.0247
Epoch  20 Batch   80/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9347, Loss: 0.0251
Epoch  20 Batch  100/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9549, Loss: 0.0267
Epoch  20 Batch  120/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9435, Loss: 0.0319
Epoch  20 Batch  140/1077 - Train Accuracy: 0.9490, Validation Accuracy: 0.9183, Loss: 0.0270
Epoch  20 Batch  160/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9506, Loss: 0.0266
Epoch  20 Batch  180/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9400, Loss: 0.0268
Epoch  20 Batch  200/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9411, Loss: 0.0269
Epoch  20 Batch  220/1077 - Train Accuracy: 0.9638, Validation Accuracy: 0.9464, Loss: 0.0300
Epoch  20 Batch  240/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9382, Loss: 0.0228
Epoch  20 Batch  260/1077 - Train Accuracy: 0.9386, Validation Accuracy: 0.9482, Loss: 0.0242
Epoch  20 Batch  280/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.9485, Loss: 0.0357
Epoch  20 Batch  300/1077 - Train Accuracy: 0.9581, Validation Accuracy: 0.9577, Loss: 0.0269
Epoch  20 Batch  320/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9450, Loss: 0.0402
Epoch  20 Batch  340/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9538, Loss: 0.0284
Epoch  20 Batch  360/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9439, Loss: 0.0223
Epoch  20 Batch  380/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9506, Loss: 0.0238
Epoch  20 Batch  400/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9464, Loss: 0.0335
Epoch  20 Batch  420/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9272, Loss: 0.0215
Epoch  20 Batch  440/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9396, Loss: 0.0323
Epoch  20 Batch  460/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9450, Loss: 0.0354
Epoch  20 Batch  480/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9411, Loss: 0.0234
Epoch  20 Batch  500/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9464, Loss: 0.0250
Epoch  20 Batch  520/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9308, Loss: 0.0244
Epoch  20 Batch  540/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9425, Loss: 0.0201
Epoch  20 Batch  560/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9457, Loss: 0.0308
Epoch  20 Batch  580/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9503, Loss: 0.0222
Epoch  20 Batch  600/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9474, Loss: 0.0299
Epoch  20 Batch  620/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9460, Loss: 0.0277
Epoch  20 Batch  640/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9325, Loss: 0.0256
Epoch  20 Batch  660/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9190, Loss: 0.0243
Epoch  20 Batch  680/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.9460, Loss: 0.0309
Epoch  20 Batch  700/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9450, Loss: 0.0255
Epoch  20 Batch  720/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.9442, Loss: 0.0375
Epoch  20 Batch  740/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9368, Loss: 0.0297
Epoch  20 Batch  760/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9357, Loss: 0.0306
Epoch  20 Batch  780/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.9222, Loss: 0.0418
Epoch  20 Batch  800/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9542, Loss: 0.0276
Epoch  20 Batch  820/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9371, Loss: 0.0293
Epoch  20 Batch  840/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9460, Loss: 0.0280
Epoch  20 Batch  860/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9538, Loss: 0.0352
Epoch  20 Batch  880/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9311, Loss: 0.0352
Epoch  20 Batch  900/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9442, Loss: 0.0345
Epoch  20 Batch  920/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9382, Loss: 0.0305
Epoch  20 Batch  940/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9208, Loss: 0.0319
Epoch  20 Batch  960/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9421, Loss: 0.0251
Epoch  20 Batch  980/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9467, Loss: 0.0324
Epoch  20 Batch 1000/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9482, Loss: 0.0292
Epoch  20 Batch 1020/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9510, Loss: 0.0217
Epoch  20 Batch 1040/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9407, Loss: 0.0302
Epoch  20 Batch 1060/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9428, Loss: 0.0322
Epoch  21 Batch   20/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9425, Loss: 0.0272
Epoch  21 Batch   40/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9528, Loss: 0.0225
Epoch  21 Batch   60/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9332, Loss: 0.0220
Epoch  21 Batch   80/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9318, Loss: 0.0243
Epoch  21 Batch  100/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9549, Loss: 0.0254
Epoch  21 Batch  120/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9364, Loss: 0.0316
Epoch  21 Batch  140/1077 - Train Accuracy: 0.9548, Validation Accuracy: 0.9222, Loss: 0.0267
Epoch  21 Batch  160/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9489, Loss: 0.0250
Epoch  21 Batch  180/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9446, Loss: 0.0245
Epoch  21 Batch  200/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9336, Loss: 0.0257
Epoch  21 Batch  220/1077 - Train Accuracy: 0.9638, Validation Accuracy: 0.9513, Loss: 0.0285
Epoch  21 Batch  240/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9386, Loss: 0.0212
Epoch  21 Batch  260/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9524, Loss: 0.0228
Epoch  21 Batch  280/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.9606, Loss: 0.0323
Epoch  21 Batch  300/1077 - Train Accuracy: 0.9642, Validation Accuracy: 0.9439, Loss: 0.0254
Epoch  21 Batch  320/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9382, Loss: 0.0391
Epoch  21 Batch  340/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9492, Loss: 0.0261
Epoch  21 Batch  360/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9453, Loss: 0.0214
Epoch  21 Batch  380/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9411, Loss: 0.0250
Epoch  21 Batch  400/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9485, Loss: 0.0313
Epoch  21 Batch  420/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9375, Loss: 0.0211
Epoch  21 Batch  440/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9400, Loss: 0.0331
Epoch  21 Batch  460/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9453, Loss: 0.0327
Epoch  21 Batch  480/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9386, Loss: 0.0211
Epoch  21 Batch  500/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9460, Loss: 0.0247
Epoch  21 Batch  520/1077 - Train Accuracy: 0.9591, Validation Accuracy: 0.9421, Loss: 0.0229
Epoch  21 Batch  540/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9474, Loss: 0.0188
Epoch  21 Batch  560/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9517, Loss: 0.0311
Epoch  21 Batch  580/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9439, Loss: 0.0211
Epoch  21 Batch  600/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9567, Loss: 0.0273
Epoch  21 Batch  620/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9425, Loss: 0.0248
Epoch  21 Batch  640/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9308, Loss: 0.0255
Epoch  21 Batch  660/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9134, Loss: 0.0231
Epoch  21 Batch  680/1077 - Train Accuracy: 0.9323, Validation Accuracy: 0.9531, Loss: 0.0292
Epoch  21 Batch  700/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9457, Loss: 0.0235
Epoch  21 Batch  720/1077 - Train Accuracy: 0.9544, Validation Accuracy: 0.9418, Loss: 0.0333
Epoch  21 Batch  740/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9467, Loss: 0.0246
Epoch  21 Batch  760/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9393, Loss: 0.0283
Epoch  21 Batch  780/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9379, Loss: 0.0397
Epoch  21 Batch  800/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9620, Loss: 0.0251
Epoch  21 Batch  820/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9467, Loss: 0.0270
Epoch  21 Batch  840/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9478, Loss: 0.0271
Epoch  21 Batch  860/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9648, Loss: 0.0304
Epoch  21 Batch  880/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9439, Loss: 0.0361
Epoch  21 Batch  900/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9489, Loss: 0.0312
Epoch  21 Batch  920/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9460, Loss: 0.0283
Epoch  21 Batch  940/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9080, Loss: 0.0290
Epoch  21 Batch  960/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9471, Loss: 0.0232
Epoch  21 Batch  980/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.9542, Loss: 0.0303
Epoch  21 Batch 1000/1077 - Train Accuracy: 0.9546, Validation Accuracy: 0.9453, Loss: 0.0265
Epoch  21 Batch 1020/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9460, Loss: 0.0195
Epoch  21 Batch 1040/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9542, Loss: 0.0260
Epoch  21 Batch 1060/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9535, Loss: 0.0295
Epoch  22 Batch   20/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9567, Loss: 0.0279
Epoch  22 Batch   40/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9531, Loss: 0.0198
Epoch  22 Batch   60/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9290, Loss: 0.0221
Epoch  22 Batch   80/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9304, Loss: 0.0238
Epoch  22 Batch  100/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9517, Loss: 0.0252
Epoch  22 Batch  120/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9585, Loss: 0.0303
Epoch  22 Batch  140/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9283, Loss: 0.0234
Epoch  22 Batch  160/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9492, Loss: 0.0231
Epoch  22 Batch  180/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9489, Loss: 0.0235
Epoch  22 Batch  200/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9460, Loss: 0.0261
Epoch  22 Batch  220/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9482, Loss: 0.0273
Epoch  22 Batch  240/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9400, Loss: 0.0214
Epoch  22 Batch  260/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9560, Loss: 0.0219
Epoch  22 Batch  280/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9556, Loss: 0.0305
Epoch  22 Batch  300/1077 - Train Accuracy: 0.9544, Validation Accuracy: 0.9592, Loss: 0.0252
Epoch  22 Batch  320/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9400, Loss: 0.0370
Epoch  22 Batch  340/1077 - Train Accuracy: 0.9811, Validation Accuracy: 0.9428, Loss: 0.0269
Epoch  22 Batch  360/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9528, Loss: 0.0201
Epoch  22 Batch  380/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9450, Loss: 0.0216
Epoch  22 Batch  400/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9485, Loss: 0.0299
Epoch  22 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9478, Loss: 0.0193
Epoch  22 Batch  440/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9553, Loss: 0.0279
Epoch  22 Batch  460/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9521, Loss: 0.0292
Epoch  22 Batch  480/1077 - Train Accuracy: 0.9708, Validation Accuracy: 0.9506, Loss: 0.0232
Epoch  22 Batch  500/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9478, Loss: 0.0246
Epoch  22 Batch  520/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9482, Loss: 0.0217
Epoch  22 Batch  540/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9471, Loss: 0.0181
Epoch  22 Batch  560/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9513, Loss: 0.0274
Epoch  22 Batch  580/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9659, Loss: 0.0207
Epoch  22 Batch  600/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9403, Loss: 0.0263
Epoch  22 Batch  620/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9453, Loss: 0.0263
Epoch  22 Batch  640/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9453, Loss: 0.0233
Epoch  22 Batch  660/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9134, Loss: 0.0201
Epoch  22 Batch  680/1077 - Train Accuracy: 0.9405, Validation Accuracy: 0.9471, Loss: 0.0265
Epoch  22 Batch  700/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9517, Loss: 0.0224
Epoch  22 Batch  720/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9460, Loss: 0.0280
Epoch  22 Batch  740/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9482, Loss: 0.0234
Epoch  22 Batch  760/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9393, Loss: 0.0256
Epoch  22 Batch  780/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9219, Loss: 0.0384
Epoch  22 Batch  800/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9702, Loss: 0.0222
Epoch  22 Batch  820/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9460, Loss: 0.0250
Epoch  22 Batch  840/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9489, Loss: 0.0262
Epoch  22 Batch  860/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9663, Loss: 0.0276
Epoch  22 Batch  880/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9421, Loss: 0.0344
Epoch  22 Batch  900/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9414, Loss: 0.0276
Epoch  22 Batch  920/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9482, Loss: 0.0259
Epoch  22 Batch  940/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9197, Loss: 0.0270
Epoch  22 Batch  960/1077 - Train Accuracy: 0.9587, Validation Accuracy: 0.9499, Loss: 0.0215
Epoch  22 Batch  980/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9517, Loss: 0.0283
Epoch  22 Batch 1000/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9428, Loss: 0.0258
Epoch  22 Batch 1020/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9499, Loss: 0.0180
Epoch  22 Batch 1040/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9467, Loss: 0.0238
Epoch  22 Batch 1060/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9531, Loss: 0.0632
Epoch  23 Batch   20/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9350, Loss: 0.0261
Epoch  23 Batch   40/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9609, Loss: 0.0193
Epoch  23 Batch   60/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9371, Loss: 0.0195
Epoch  23 Batch   80/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9453, Loss: 0.0223
Epoch  23 Batch  100/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9574, Loss: 0.0234
Epoch  23 Batch  120/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9513, Loss: 0.0290
Epoch  23 Batch  140/1077 - Train Accuracy: 0.9683, Validation Accuracy: 0.9435, Loss: 0.0236
Epoch  23 Batch  160/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9528, Loss: 0.0218
Epoch  23 Batch  180/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9492, Loss: 0.0215
Epoch  23 Batch  200/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9382, Loss: 0.0227
Epoch  23 Batch  220/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9560, Loss: 0.0253
Epoch  23 Batch  240/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9339, Loss: 0.0188
Epoch  23 Batch  260/1077 - Train Accuracy: 0.9401, Validation Accuracy: 0.9432, Loss: 0.0214
Epoch  23 Batch  280/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9517, Loss: 0.0290
Epoch  23 Batch  300/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9563, Loss: 0.0238
Epoch  23 Batch  320/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9535, Loss: 0.0358
Epoch  23 Batch  340/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9442, Loss: 0.0232
Epoch  23 Batch  360/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9517, Loss: 0.0181
Epoch  23 Batch  380/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9513, Loss: 0.0203
Epoch  23 Batch  400/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9492, Loss: 0.0284
Epoch  23 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9549, Loss: 0.0175
Epoch  23 Batch  440/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9574, Loss: 0.0270
Epoch  23 Batch  460/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9574, Loss: 0.0266
Epoch  23 Batch  480/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9354, Loss: 0.0175
Epoch  23 Batch  500/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9478, Loss: 0.0240
Epoch  23 Batch  520/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9411, Loss: 0.0197
Epoch  23 Batch  540/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9496, Loss: 0.0164
Epoch  23 Batch  560/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9560, Loss: 0.0267
Epoch  23 Batch  580/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9627, Loss: 0.0196
Epoch  23 Batch  600/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9478, Loss: 0.0243
Epoch  23 Batch  620/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9467, Loss: 0.0235
Epoch  23 Batch  640/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9556, Loss: 0.0217
Epoch  23 Batch  660/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9428, Loss: 0.0187
Epoch  23 Batch  680/1077 - Train Accuracy: 0.9360, Validation Accuracy: 0.9588, Loss: 0.0237
Epoch  23 Batch  700/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9457, Loss: 0.0217
Epoch  23 Batch  720/1077 - Train Accuracy: 0.9634, Validation Accuracy: 0.9542, Loss: 0.0250
Epoch  23 Batch  740/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9531, Loss: 0.0221
Epoch  23 Batch  760/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9442, Loss: 0.0268
Epoch  23 Batch  780/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9364, Loss: 0.0363
Epoch  23 Batch  800/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9673, Loss: 0.0219
Epoch  23 Batch  820/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9631, Loss: 0.0242
Epoch  23 Batch  840/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9528, Loss: 0.0254
Epoch  23 Batch  860/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9641, Loss: 0.0247
Epoch  23 Batch  880/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9464, Loss: 0.0317
Epoch  23 Batch  900/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9432, Loss: 0.0280
Epoch  23 Batch  920/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9432, Loss: 0.0238
Epoch  23 Batch  940/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9308, Loss: 0.0255
Epoch  23 Batch  960/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9577, Loss: 0.0208
Epoch  23 Batch  980/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9492, Loss: 0.0266
Epoch  23 Batch 1000/1077 - Train Accuracy: 0.9624, Validation Accuracy: 0.9574, Loss: 0.0249
Epoch  23 Batch 1020/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9545, Loss: 0.0166
Epoch  23 Batch 1040/1077 - Train Accuracy: 0.9626, Validation Accuracy: 0.9538, Loss: 0.0210
Epoch  23 Batch 1060/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9648, Loss: 0.0281
Epoch  24 Batch   20/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9506, Loss: 0.0230
Epoch  24 Batch   40/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9577, Loss: 0.0186
Epoch  24 Batch   60/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9442, Loss: 0.0172
Epoch  24 Batch   80/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9428, Loss: 0.0206
Epoch  24 Batch  100/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9631, Loss: 0.0202
Epoch  24 Batch  120/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9577, Loss: 0.0261
Epoch  24 Batch  140/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9492, Loss: 0.0206
Epoch  24 Batch  160/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9528, Loss: 0.0208
Epoch  24 Batch  180/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9521, Loss: 0.0210
Epoch  24 Batch  200/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9471, Loss: 0.0215
Epoch  24 Batch  220/1077 - Train Accuracy: 0.9630, Validation Accuracy: 0.9563, Loss: 0.0251
Epoch  24 Batch  240/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9503, Loss: 0.0169
Epoch  24 Batch  260/1077 - Train Accuracy: 0.9401, Validation Accuracy: 0.9474, Loss: 0.0201
Epoch  24 Batch  280/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9560, Loss: 0.0279
Epoch  24 Batch  300/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9673, Loss: 0.0215
Epoch  24 Batch  320/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9450, Loss: 0.0345
Epoch  24 Batch  340/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9464, Loss: 0.0220
Epoch  24 Batch  360/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9492, Loss: 0.0193
Epoch  24 Batch  380/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9510, Loss: 0.0201
Epoch  24 Batch  400/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9435, Loss: 0.0262
Epoch  24 Batch  420/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9496, Loss: 0.0171
Epoch  24 Batch  440/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9563, Loss: 0.0265
Epoch  24 Batch  460/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9581, Loss: 0.0254
Epoch  24 Batch  480/1077 - Train Accuracy: 0.9811, Validation Accuracy: 0.9379, Loss: 0.0164
Epoch  24 Batch  500/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9638, Loss: 0.0233
Epoch  24 Batch  520/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9460, Loss: 0.0179
Epoch  24 Batch  540/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9570, Loss: 0.0153
Epoch  24 Batch  560/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9581, Loss: 0.0252
Epoch  24 Batch  580/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9595, Loss: 0.0196
Epoch  24 Batch  600/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9531, Loss: 0.0233
Epoch  24 Batch  620/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9389, Loss: 0.0208
Epoch  24 Batch  640/1077 - Train Accuracy: 0.9736, Validation Accuracy: 0.9563, Loss: 0.0198
Epoch  24 Batch  660/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9247, Loss: 0.0191
Epoch  24 Batch  680/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.9492, Loss: 0.0241
Epoch  24 Batch  700/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9538, Loss: 0.0213
Epoch  24 Batch  720/1077 - Train Accuracy: 0.9729, Validation Accuracy: 0.9602, Loss: 0.0345
Epoch  24 Batch  740/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9542, Loss: 0.0281
Epoch  24 Batch  760/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9432, Loss: 0.0245
Epoch  24 Batch  780/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9421, Loss: 0.0450
Epoch  24 Batch  800/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9680, Loss: 0.0230
Epoch  24 Batch  820/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9492, Loss: 0.0247
Epoch  24 Batch  840/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9464, Loss: 0.0253
Epoch  24 Batch  860/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9695, Loss: 0.0249
Epoch  24 Batch  880/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9567, Loss: 0.0327
Epoch  24 Batch  900/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9545, Loss: 0.0247
Epoch  24 Batch  920/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9421, Loss: 0.0238
Epoch  24 Batch  940/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9521, Loss: 0.0230
Epoch  24 Batch  960/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9517, Loss: 0.0200
Epoch  24 Batch  980/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9478, Loss: 0.0248
Epoch  24 Batch 1000/1077 - Train Accuracy: 0.9580, Validation Accuracy: 0.9503, Loss: 0.0237
Epoch  24 Batch 1020/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9538, Loss: 0.0166
Epoch  24 Batch 1040/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9634, Loss: 0.0206
Epoch  24 Batch 1060/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9641, Loss: 0.0250
Epoch  25 Batch   20/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9482, Loss: 0.0187
Epoch  25 Batch   40/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9549, Loss: 0.0173
Epoch  25 Batch   60/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9411, Loss: 0.0166
Epoch  25 Batch   80/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9467, Loss: 0.0223
Epoch  25 Batch  100/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9538, Loss: 0.0208
Epoch  25 Batch  120/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9577, Loss: 0.0256
Epoch  25 Batch  140/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9460, Loss: 0.0184
Epoch  25 Batch  160/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9581, Loss: 0.0206
Epoch  25 Batch  180/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9510, Loss: 0.0193
Epoch  25 Batch  200/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9471, Loss: 0.0202
Epoch  25 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9631, Loss: 0.0241
Epoch  25 Batch  240/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9613, Loss: 0.0160
Epoch  25 Batch  260/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9624, Loss: 0.0182
Epoch  25 Batch  280/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9428, Loss: 0.0270
Epoch  25 Batch  300/1077 - Train Accuracy: 0.9683, Validation Accuracy: 0.9631, Loss: 0.0213
Epoch  25 Batch  320/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9535, Loss: 0.0327
Epoch  25 Batch  340/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9474, Loss: 0.0234
Epoch  25 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9624, Loss: 0.0178
Epoch  25 Batch  380/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9474, Loss: 0.0191
Epoch  25 Batch  400/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9496, Loss: 0.0248
Epoch  25 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9641, Loss: 0.0162
Epoch  25 Batch  440/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9624, Loss: 0.0243
Epoch  25 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9602, Loss: 0.0242
Epoch  25 Batch  480/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9492, Loss: 0.0155
Epoch  25 Batch  500/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9588, Loss: 0.0239
Epoch  25 Batch  520/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9482, Loss: 0.0165
Epoch  25 Batch  540/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9616, Loss: 0.0146
Epoch  25 Batch  560/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9599, Loss: 0.0242
Epoch  25 Batch  580/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9620, Loss: 0.0185
Epoch  25 Batch  600/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9545, Loss: 0.0219
Epoch  25 Batch  620/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9471, Loss: 0.0198
Epoch  25 Batch  640/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9602, Loss: 0.0181
Epoch  25 Batch  660/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9311, Loss: 0.0177
Epoch  25 Batch  680/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9560, Loss: 0.0222
Epoch  25 Batch  700/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9592, Loss: 0.0215
Epoch  25 Batch  720/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9563, Loss: 0.0230
Epoch  25 Batch  740/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9513, Loss: 0.0207
Epoch  25 Batch  760/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9368, Loss: 0.0230
Epoch  25 Batch  780/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9453, Loss: 0.0335
Epoch  25 Batch  800/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9719, Loss: 0.0223
Epoch  25 Batch  820/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9638, Loss: 0.0216
Epoch  25 Batch  840/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9656, Loss: 0.0250
Epoch  25 Batch  860/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9634, Loss: 0.0223
Epoch  25 Batch  880/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9620, Loss: 0.0299
Epoch  25 Batch  900/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9602, Loss: 0.0239
Epoch  25 Batch  920/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9556, Loss: 0.0211
Epoch  25 Batch  940/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9521, Loss: 0.0209
Epoch  25 Batch  960/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9471, Loss: 0.0189
Epoch  25 Batch  980/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9645, Loss: 0.0239
Epoch  25 Batch 1000/1077 - Train Accuracy: 0.9580, Validation Accuracy: 0.9567, Loss: 0.0240
Epoch  25 Batch 1020/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9485, Loss: 0.0146
Epoch  25 Batch 1040/1077 - Train Accuracy: 0.9630, Validation Accuracy: 0.9588, Loss: 0.0199
Epoch  25 Batch 1060/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9659, Loss: 0.0207
Epoch  26 Batch   20/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9549, Loss: 0.0190
Epoch  26 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9620, Loss: 0.0171
Epoch  26 Batch   60/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9460, Loss: 0.0154
Epoch  26 Batch   80/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9478, Loss: 0.0207
Epoch  26 Batch  100/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9599, Loss: 0.0190
Epoch  26 Batch  120/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9563, Loss: 0.0235
Epoch  26 Batch  140/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9471, Loss: 0.0190
Epoch  26 Batch  160/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9599, Loss: 0.0209
Epoch  26 Batch  180/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9567, Loss: 0.0168
Epoch  26 Batch  200/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9663, Loss: 0.0189
Epoch  26 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9609, Loss: 0.0232
Epoch  26 Batch  240/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9613, Loss: 0.0157
Epoch  26 Batch  260/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9624, Loss: 0.0173
Epoch  26 Batch  280/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9513, Loss: 0.0252
Epoch  26 Batch  300/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9528, Loss: 0.0205
Epoch  26 Batch  320/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9570, Loss: 0.0327
Epoch  26 Batch  340/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9407, Loss: 0.0204
Epoch  26 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9471, Loss: 0.0166
Epoch  26 Batch  380/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9581, Loss: 0.0161
Epoch  26 Batch  400/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9489, Loss: 0.0240
Epoch  26 Batch  420/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9599, Loss: 0.0168
Epoch  26 Batch  440/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9471, Loss: 0.0237
Epoch  26 Batch  460/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9574, Loss: 0.0229
Epoch  26 Batch  480/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9446, Loss: 0.0142
Epoch  26 Batch  500/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9549, Loss: 0.0246
Epoch  26 Batch  520/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9513, Loss: 0.0166
Epoch  26 Batch  540/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9588, Loss: 0.0140
Epoch  26 Batch  560/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9528, Loss: 0.0218
Epoch  26 Batch  580/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9624, Loss: 0.0184
Epoch  26 Batch  600/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9556, Loss: 0.0204
Epoch  26 Batch  620/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9393, Loss: 0.0195
Epoch  26 Batch  640/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9695, Loss: 0.0182
Epoch  26 Batch  660/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9329, Loss: 0.0170
Epoch  26 Batch  680/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9521, Loss: 0.0213
Epoch  26 Batch  700/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9563, Loss: 0.0203
Epoch  26 Batch  720/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9620, Loss: 0.0234
Epoch  26 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9524, Loss: 0.0199
Epoch  26 Batch  760/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9414, Loss: 0.0231
Epoch  26 Batch  780/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9375, Loss: 0.0338
Epoch  26 Batch  800/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9741, Loss: 0.0209
Epoch  26 Batch  820/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9638, Loss: 0.0212
Epoch  26 Batch  840/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9563, Loss: 0.0245
Epoch  26 Batch  860/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9641, Loss: 0.0215
Epoch  26 Batch  880/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9567, Loss: 0.0286
Epoch  26 Batch  900/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9599, Loss: 0.0241
Epoch  26 Batch  920/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9670, Loss: 0.0200
Epoch  26 Batch  940/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9435, Loss: 0.0207
Epoch  26 Batch  960/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9585, Loss: 0.0180
Epoch  26 Batch  980/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9482, Loss: 0.0221
Epoch  26 Batch 1000/1077 - Train Accuracy: 0.9635, Validation Accuracy: 0.9563, Loss: 0.0227
Epoch  26 Batch 1020/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9542, Loss: 0.0135
Epoch  26 Batch 1040/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9606, Loss: 0.0175
Epoch  26 Batch 1060/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9613, Loss: 0.0176
Epoch  27 Batch   20/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9460, Loss: 0.0163
Epoch  27 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9627, Loss: 0.0157
Epoch  27 Batch   60/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9382, Loss: 0.0149
Epoch  27 Batch   80/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9553, Loss: 0.0189
Epoch  27 Batch  100/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9478, Loss: 0.0189
Epoch  27 Batch  120/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9634, Loss: 0.0216
Epoch  27 Batch  140/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9535, Loss: 0.0183
Epoch  27 Batch  160/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9641, Loss: 0.0193
Epoch  27 Batch  180/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9407, Loss: 0.0159
Epoch  27 Batch  200/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9624, Loss: 0.0170
Epoch  27 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9563, Loss: 0.0233
Epoch  27 Batch  240/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9652, Loss: 0.0156
Epoch  27 Batch  260/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9620, Loss: 0.0171
Epoch  27 Batch  280/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9542, Loss: 0.0264
Epoch  27 Batch  300/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9684, Loss: 0.0201
Epoch  27 Batch  320/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9592, Loss: 0.0312
Epoch  27 Batch  340/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9492, Loss: 0.0186
Epoch  27 Batch  360/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9581, Loss: 0.0165
Epoch  27 Batch  380/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9457, Loss: 0.0172
Epoch  27 Batch  400/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9620, Loss: 0.0243
Epoch  27 Batch  420/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9599, Loss: 0.0157
Epoch  27 Batch  440/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9506, Loss: 0.0223
Epoch  27 Batch  460/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9599, Loss: 0.0226
Epoch  27 Batch  480/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9545, Loss: 0.0138
Epoch  27 Batch  500/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9585, Loss: 0.0209
Epoch  27 Batch  520/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9464, Loss: 0.0154
Epoch  27 Batch  540/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9588, Loss: 0.0125
Epoch  27 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9528, Loss: 0.0229
Epoch  27 Batch  580/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9624, Loss: 0.0186
Epoch  27 Batch  600/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9581, Loss: 0.0191
Epoch  27 Batch  620/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9460, Loss: 0.0201
Epoch  27 Batch  640/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9695, Loss: 0.0179
Epoch  27 Batch  660/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9485, Loss: 0.0178
Epoch  27 Batch  680/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9634, Loss: 0.0203
Epoch  27 Batch  700/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9553, Loss: 0.0200
Epoch  27 Batch  720/1077 - Train Accuracy: 0.9659, Validation Accuracy: 0.9599, Loss: 0.0211
Epoch  27 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9538, Loss: 0.0189
Epoch  27 Batch  760/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9542, Loss: 0.0248
Epoch  27 Batch  780/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9418, Loss: 0.0323
Epoch  27 Batch  800/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9748, Loss: 0.0204
Epoch  27 Batch  820/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9663, Loss: 0.0207
Epoch  27 Batch  840/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9673, Loss: 0.0236
Epoch  27 Batch  860/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9627, Loss: 0.0203
Epoch  27 Batch  880/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9677, Loss: 0.0269
Epoch  27 Batch  900/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9588, Loss: 0.0212
Epoch  27 Batch  920/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9549, Loss: 0.0203
Epoch  27 Batch  940/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9549, Loss: 0.0192
Epoch  27 Batch  960/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9599, Loss: 0.0177
Epoch  27 Batch  980/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9535, Loss: 0.0211
Epoch  27 Batch 1000/1077 - Train Accuracy: 0.9635, Validation Accuracy: 0.9570, Loss: 0.0224
Epoch  27 Batch 1020/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9570, Loss: 0.0131
Epoch  27 Batch 1040/1077 - Train Accuracy: 0.9729, Validation Accuracy: 0.9585, Loss: 0.0174
Epoch  27 Batch 1060/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9570, Loss: 0.0168
Epoch  28 Batch   20/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9379, Loss: 0.0149
Epoch  28 Batch   40/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9585, Loss: 0.0151
Epoch  28 Batch   60/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9389, Loss: 0.0150
Epoch  28 Batch   80/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9588, Loss: 0.0177
Epoch  28 Batch  100/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9570, Loss: 0.0164
Epoch  28 Batch  120/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9513, Loss: 0.0226
Epoch  28 Batch  140/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9673, Loss: 0.0180
Epoch  28 Batch  160/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9631, Loss: 0.0188
Epoch  28 Batch  180/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9581, Loss: 0.0149
Epoch  28 Batch  200/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9581, Loss: 0.0156
Epoch  28 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9585, Loss: 0.0228
Epoch  28 Batch  240/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9620, Loss: 0.0136
Epoch  28 Batch  260/1077 - Train Accuracy: 0.9542, Validation Accuracy: 0.9641, Loss: 0.0162
Epoch  28 Batch  280/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9521, Loss: 0.0238
Epoch  28 Batch  300/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9677, Loss: 0.0189
Epoch  28 Batch  320/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9581, Loss: 0.0300
Epoch  28 Batch  340/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9531, Loss: 0.0165
Epoch  28 Batch  360/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9563, Loss: 0.0175
Epoch  28 Batch  380/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9517, Loss: 0.0211
Epoch  28 Batch  400/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9542, Loss: 0.0284
Epoch  28 Batch  420/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9560, Loss: 0.0205
Epoch  28 Batch  440/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9467, Loss: 0.0212
Epoch  28 Batch  460/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9585, Loss: 0.0212
Epoch  28 Batch  480/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9450, Loss: 0.0140
Epoch  28 Batch  500/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9624, Loss: 0.0195
Epoch  28 Batch  520/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9563, Loss: 0.0149
Epoch  28 Batch  540/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9570, Loss: 0.0127
Epoch  28 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9528, Loss: 0.0192
Epoch  28 Batch  580/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9609, Loss: 0.0164
Epoch  28 Batch  600/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9538, Loss: 0.0187
Epoch  28 Batch  620/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9375, Loss: 0.0181
Epoch  28 Batch  640/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9531, Loss: 0.0216
Epoch  28 Batch  660/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9521, Loss: 0.0148
Epoch  28 Batch  680/1077 - Train Accuracy: 0.9442, Validation Accuracy: 0.9656, Loss: 0.0189
Epoch  28 Batch  700/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9528, Loss: 0.0188
Epoch  28 Batch  720/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9538, Loss: 0.0207
Epoch  28 Batch  740/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9634, Loss: 0.0191
Epoch  28 Batch  760/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9421, Loss: 0.0218
Epoch  28 Batch  780/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9602, Loss: 0.0301
Epoch  28 Batch  800/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9812, Loss: 0.0200
Epoch  28 Batch  820/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9663, Loss: 0.0184
Epoch  28 Batch  840/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9663, Loss: 0.0225
Epoch  28 Batch  860/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.9727, Loss: 0.0189
Epoch  28 Batch  880/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9570, Loss: 0.0254
Epoch  28 Batch  900/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9581, Loss: 0.0207
Epoch  28 Batch  920/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9606, Loss: 0.0214
Epoch  28 Batch  940/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9521, Loss: 0.0209
Epoch  28 Batch  960/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9624, Loss: 0.0167
Epoch  28 Batch  980/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9613, Loss: 0.0197
Epoch  28 Batch 1000/1077 - Train Accuracy: 0.9654, Validation Accuracy: 0.9666, Loss: 0.0211
Epoch  28 Batch 1020/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9496, Loss: 0.0125
Epoch  28 Batch 1040/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9553, Loss: 0.0157
Epoch  28 Batch 1060/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9624, Loss: 0.0227
Epoch  29 Batch   20/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9680, Loss: 0.0152
Epoch  29 Batch   40/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9542, Loss: 0.0143
Epoch  29 Batch   60/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9581, Loss: 0.0140
Epoch  29 Batch   80/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9638, Loss: 0.0173
Epoch  29 Batch  100/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9474, Loss: 0.0153
Epoch  29 Batch  120/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9574, Loss: 0.0206
Epoch  29 Batch  140/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9716, Loss: 0.0169
Epoch  29 Batch  160/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9556, Loss: 0.0186
Epoch  29 Batch  180/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9588, Loss: 0.0134
Epoch  29 Batch  200/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9577, Loss: 0.0143
Epoch  29 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9592, Loss: 0.0232
Epoch  29 Batch  240/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9602, Loss: 0.0126
Epoch  29 Batch  260/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9670, Loss: 0.0161
Epoch  29 Batch  280/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9599, Loss: 0.0224
Epoch  29 Batch  300/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9624, Loss: 0.0189
Epoch  29 Batch  320/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9517, Loss: 0.0292
Epoch  29 Batch  340/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9528, Loss: 0.0155
Epoch  29 Batch  360/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9599, Loss: 0.0147
Epoch  29 Batch  380/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9574, Loss: 0.0147
Epoch  29 Batch  400/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9634, Loss: 0.0230
Epoch  29 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9602, Loss: 0.0146
Epoch  29 Batch  440/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9474, Loss: 0.0207
Epoch  29 Batch  460/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9549, Loss: 0.0191
Epoch  29 Batch  480/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9549, Loss: 0.0130
Epoch  29 Batch  500/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9592, Loss: 0.0191
Epoch  29 Batch  520/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9513, Loss: 0.0141
Epoch  29 Batch  540/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9513, Loss: 0.0119
Epoch  29 Batch  560/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9631, Loss: 0.0192
Epoch  29 Batch  580/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9606, Loss: 0.0155
Epoch  29 Batch  600/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9510, Loss: 0.0173
Epoch  29 Batch  620/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9542, Loss: 0.0168
Epoch  29 Batch  640/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9588, Loss: 0.0164
Epoch  29 Batch  660/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9517, Loss: 0.0144
Epoch  29 Batch  680/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9609, Loss: 0.0214
Epoch  29 Batch  700/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9560, Loss: 0.0185
Epoch  29 Batch  720/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9545, Loss: 0.0196
Epoch  29 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9506, Loss: 0.0180
Epoch  29 Batch  760/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9531, Loss: 0.0218
Epoch  29 Batch  780/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9560, Loss: 0.0294
Epoch  29 Batch  800/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9776, Loss: 0.0173
Epoch  29 Batch  820/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9620, Loss: 0.0195
Epoch  29 Batch  840/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9666, Loss: 0.0223
Epoch  29 Batch  860/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9790, Loss: 0.0190
Epoch  29 Batch  880/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9648, Loss: 0.0250
Epoch  29 Batch  900/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9680, Loss: 0.0207
Epoch  29 Batch  920/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9648, Loss: 0.0165
Epoch  29 Batch  940/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9556, Loss: 0.0164
Epoch  29 Batch  960/1077 - Train Accuracy: 0.9635, Validation Accuracy: 0.9585, Loss: 0.0162
Epoch  29 Batch  980/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9641, Loss: 0.0197
Epoch  29 Batch 1000/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9616, Loss: 0.0203
Epoch  29 Batch 1020/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9545, Loss: 0.0121
Epoch  29 Batch 1040/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9595, Loss: 0.0155
Epoch  29 Batch 1060/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9471, Loss: 0.0172
Epoch  30 Batch   20/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9627, Loss: 0.0154
Epoch  30 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9577, Loss: 0.0136
Epoch  30 Batch   60/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9446, Loss: 0.0148
Epoch  30 Batch   80/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9496, Loss: 0.0164
Epoch  30 Batch  100/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9474, Loss: 0.0152
Epoch  30 Batch  120/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9588, Loss: 0.0214
Epoch  30 Batch  140/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9641, Loss: 0.0178
Epoch  30 Batch  160/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9613, Loss: 0.0187
Epoch  30 Batch  180/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9684, Loss: 0.0131
Epoch  30 Batch  200/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9560, Loss: 0.0138
Epoch  30 Batch  220/1077 - Train Accuracy: 0.9675, Validation Accuracy: 0.9634, Loss: 0.0290
Epoch  30 Batch  240/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9634, Loss: 0.0134
Epoch  30 Batch  260/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9702, Loss: 0.0153
Epoch  30 Batch  280/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9688, Loss: 0.0205
Epoch  30 Batch  300/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9698, Loss: 0.0185
Epoch  30 Batch  320/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9549, Loss: 0.0289
Epoch  30 Batch  340/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9517, Loss: 0.0137
Epoch  30 Batch  360/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9677, Loss: 0.0140
Epoch  30 Batch  380/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9489, Loss: 0.0140
Epoch  30 Batch  400/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9620, Loss: 0.0218
Epoch  30 Batch  420/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9652, Loss: 0.0155
Epoch  30 Batch  440/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9471, Loss: 0.0201
Epoch  30 Batch  460/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9528, Loss: 0.0188
Epoch  30 Batch  480/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9375, Loss: 0.0130
Epoch  30 Batch  500/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9545, Loss: 0.0174
Epoch  30 Batch  520/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9521, Loss: 0.0126
Epoch  30 Batch  540/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9545, Loss: 0.0114
Epoch  30 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9577, Loss: 0.0171
Epoch  30 Batch  580/1077 - Train Accuracy: 0.9732, Validation Accuracy: 0.9613, Loss: 0.0139
Epoch  30 Batch  600/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9581, Loss: 0.0160
Epoch  30 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9553, Loss: 0.0176
Epoch  30 Batch  640/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9677, Loss: 0.0140
Epoch  30 Batch  660/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9609, Loss: 0.0135
Epoch  30 Batch  680/1077 - Train Accuracy: 0.9442, Validation Accuracy: 0.9602, Loss: 0.0182
Epoch  30 Batch  700/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9510, Loss: 0.0176
Epoch  30 Batch  720/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9535, Loss: 0.0215
Epoch  30 Batch  740/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9599, Loss: 0.0174
Epoch  30 Batch  760/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9485, Loss: 0.0191
Epoch  30 Batch  780/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9677, Loss: 0.0273
Epoch  30 Batch  800/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9783, Loss: 0.0182
Epoch  30 Batch  820/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9609, Loss: 0.0181
Epoch  30 Batch  840/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9773, Loss: 0.0214
Epoch  30 Batch  860/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9592, Loss: 0.0178
Epoch  30 Batch  880/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9631, Loss: 0.0227
Epoch  30 Batch  900/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9521, Loss: 0.0214
Epoch  30 Batch  920/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9645, Loss: 0.0206
Epoch  30 Batch  940/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9535, Loss: 0.0174
Epoch  30 Batch  960/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9638, Loss: 0.0155
Epoch  30 Batch  980/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9677, Loss: 0.0183
Epoch  30 Batch 1000/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9670, Loss: 0.0203
Epoch  30 Batch 1020/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9538, Loss: 0.0103
Epoch  30 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9553, Loss: 0.0141
Epoch  30 Batch 1060/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9506, Loss: 0.0227
Epoch  31 Batch   20/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9695, Loss: 0.0142
Epoch  31 Batch   40/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9602, Loss: 0.0130
Epoch  31 Batch   60/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9538, Loss: 0.0134
Epoch  31 Batch   80/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9670, Loss: 0.0151
Epoch  31 Batch  100/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9528, Loss: 0.0150
Epoch  31 Batch  120/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9510, Loss: 0.0182
Epoch  31 Batch  140/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9716, Loss: 0.0152
Epoch  31 Batch  160/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9553, Loss: 0.0176
Epoch  31 Batch  180/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9638, Loss: 0.0124
Epoch  31 Batch  200/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9602, Loss: 0.0125
Epoch  31 Batch  220/1077 - Train Accuracy: 0.9675, Validation Accuracy: 0.9638, Loss: 0.0223
Epoch  31 Batch  240/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9695, Loss: 0.0117
Epoch  31 Batch  260/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9705, Loss: 0.0153
Epoch  31 Batch  280/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9656, Loss: 0.0202
Epoch  31 Batch  300/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9727, Loss: 0.0166
Epoch  31 Batch  320/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9574, Loss: 0.0267
Epoch  31 Batch  340/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9652, Loss: 0.0126
Epoch  31 Batch  360/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9677, Loss: 0.0128
Epoch  31 Batch  380/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9531, Loss: 0.0133
Epoch  31 Batch  400/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9556, Loss: 0.0208
Epoch  31 Batch  420/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9606, Loss: 0.0140
Epoch  31 Batch  440/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9435, Loss: 0.0189
Epoch  31 Batch  460/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9517, Loss: 0.0176
Epoch  31 Batch  480/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9389, Loss: 0.0122
Epoch  31 Batch  500/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9545, Loss: 0.0180
Epoch  31 Batch  520/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9563, Loss: 0.0123
Epoch  31 Batch  540/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9574, Loss: 0.0123
Epoch  31 Batch  560/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9602, Loss: 0.0164
Epoch  31 Batch  580/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9613, Loss: 0.0141
Epoch  31 Batch  600/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9624, Loss: 0.0152
Epoch  31 Batch  620/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9513, Loss: 0.0170
Epoch  31 Batch  640/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9631, Loss: 0.0128
Epoch  31 Batch  660/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9616, Loss: 0.0125
Epoch  31 Batch  680/1077 - Train Accuracy: 0.9487, Validation Accuracy: 0.9645, Loss: 0.0174
Epoch  31 Batch  700/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9702, Loss: 0.0169
Epoch  31 Batch  720/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9730, Loss: 0.0199
Epoch  31 Batch  740/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9560, Loss: 0.0153
Epoch  31 Batch  760/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9698, Loss: 0.0173
Epoch  31 Batch  780/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9606, Loss: 0.0298
Epoch  31 Batch  800/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9705, Loss: 0.0168
Epoch  31 Batch  820/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9627, Loss: 0.0170
Epoch  31 Batch  840/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9698, Loss: 0.0196
Epoch  31 Batch  860/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9563, Loss: 0.0177
Epoch  31 Batch  880/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9606, Loss: 0.0216
Epoch  31 Batch  900/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9595, Loss: 0.0209
Epoch  31 Batch  920/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9613, Loss: 0.0154
Epoch  31 Batch  940/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9478, Loss: 0.0138
Epoch  31 Batch  960/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9677, Loss: 0.0151
Epoch  31 Batch  980/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9705, Loss: 0.0184
Epoch  31 Batch 1000/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9627, Loss: 0.0188
Epoch  31 Batch 1020/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9506, Loss: 0.0109
Epoch  31 Batch 1040/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9549, Loss: 0.0167
Epoch  31 Batch 1060/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9499, Loss: 0.0221
Epoch  32 Batch   20/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9648, Loss: 0.0135
Epoch  32 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9577, Loss: 0.0145
Epoch  32 Batch   60/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9432, Loss: 0.0128
Epoch  32 Batch   80/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9663, Loss: 0.0140
Epoch  32 Batch  100/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9645, Loss: 0.0139
Epoch  32 Batch  120/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9389, Loss: 0.0184
Epoch  32 Batch  140/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9613, Loss: 0.0148
Epoch  32 Batch  160/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9595, Loss: 0.0162
Epoch  32 Batch  180/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9567, Loss: 0.0120
Epoch  32 Batch  200/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9624, Loss: 0.0131
Epoch  32 Batch  220/1077 - Train Accuracy: 0.9729, Validation Accuracy: 0.9652, Loss: 0.0234
Epoch  32 Batch  240/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9606, Loss: 0.0126
Epoch  32 Batch  260/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9691, Loss: 0.0145
Epoch  32 Batch  280/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9670, Loss: 0.0197
Epoch  32 Batch  300/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9698, Loss: 0.0171
Epoch  32 Batch  320/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9471, Loss: 0.0261
Epoch  32 Batch  340/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9595, Loss: 0.0125
Epoch  32 Batch  360/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9680, Loss: 0.0125
Epoch  32 Batch  380/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9531, Loss: 0.0131
Epoch  32 Batch  400/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9645, Loss: 0.0204
Epoch  32 Batch  420/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9620, Loss: 0.0124
Epoch  32 Batch  440/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9474, Loss: 0.0192
Epoch  32 Batch  460/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9542, Loss: 0.0173
Epoch  32 Batch  480/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9467, Loss: 0.0122
Epoch  32 Batch  500/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9620, Loss: 0.0158
Epoch  32 Batch  520/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9563, Loss: 0.0120
Epoch  32 Batch  540/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9506, Loss: 0.0111
Epoch  32 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9652, Loss: 0.0151
Epoch  32 Batch  580/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9634, Loss: 0.0127
Epoch  32 Batch  600/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9719, Loss: 0.0143
Epoch  32 Batch  620/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9560, Loss: 0.0164
Epoch  32 Batch  640/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9595, Loss: 0.0125
Epoch  32 Batch  660/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9585, Loss: 0.0139
Epoch  32 Batch  680/1077 - Train Accuracy: 0.9490, Validation Accuracy: 0.9645, Loss: 0.0160
Epoch  32 Batch  700/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9613, Loss: 0.0164
Epoch  32 Batch  720/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9538, Loss: 0.0176
Epoch  32 Batch  740/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9670, Loss: 0.0156
Epoch  32 Batch  760/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9517, Loss: 0.0166
Epoch  32 Batch  780/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9670, Loss: 0.0257
Epoch  32 Batch  800/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9709, Loss: 0.0181
Epoch  32 Batch  820/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9677, Loss: 0.0166
Epoch  32 Batch  840/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9698, Loss: 0.0194
Epoch  32 Batch  860/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9567, Loss: 0.0166
Epoch  32 Batch  880/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9680, Loss: 0.0221
Epoch  32 Batch  900/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9627, Loss: 0.0181
Epoch  32 Batch  920/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9521, Loss: 0.0142
Epoch  32 Batch  940/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9691, Loss: 0.0132
Epoch  32 Batch  960/1077 - Train Accuracy: 0.9654, Validation Accuracy: 0.9663, Loss: 0.0140
Epoch  32 Batch  980/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9723, Loss: 0.0175
Epoch  32 Batch 1000/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9609, Loss: 0.0173
Epoch  32 Batch 1020/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9492, Loss: 0.0101
Epoch  32 Batch 1040/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9553, Loss: 0.0152
Epoch  32 Batch 1060/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9531, Loss: 0.0139
Epoch  33 Batch   20/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9808, Loss: 0.0135
Epoch  33 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9588, Loss: 0.0119
Epoch  33 Batch   60/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9531, Loss: 0.0121
Epoch  33 Batch   80/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9680, Loss: 0.0145
Epoch  33 Batch  100/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9595, Loss: 0.0130
Epoch  33 Batch  120/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9513, Loss: 0.0159
Epoch  33 Batch  140/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9727, Loss: 0.0151
Epoch  33 Batch  160/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9691, Loss: 0.0150
Epoch  33 Batch  180/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9698, Loss: 0.0112
Epoch  33 Batch  200/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9585, Loss: 0.0124
Epoch  33 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9673, Loss: 0.0211
Epoch  33 Batch  240/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9652, Loss: 0.0123
Epoch  33 Batch  260/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9755, Loss: 0.0146
Epoch  33 Batch  280/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9734, Loss: 0.0194
Epoch  33 Batch  300/1077 - Train Accuracy: 0.9708, Validation Accuracy: 0.9581, Loss: 0.0162
Epoch  33 Batch  320/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9673, Loss: 0.0266
Epoch  33 Batch  340/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9549, Loss: 0.0119
Epoch  33 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9616, Loss: 0.0115
Epoch  33 Batch  380/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9513, Loss: 0.0123
Epoch  33 Batch  400/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9670, Loss: 0.0192
Epoch  33 Batch  420/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9606, Loss: 0.0145
Epoch  33 Batch  440/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9435, Loss: 0.0180
Epoch  33 Batch  460/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9577, Loss: 0.0163
Epoch  33 Batch  480/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9396, Loss: 0.0109
Epoch  33 Batch  500/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9734, Loss: 0.0158
Epoch  33 Batch  520/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9560, Loss: 0.0108
Epoch  33 Batch  540/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9535, Loss: 0.0110
Epoch  33 Batch  560/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9677, Loss: 0.0159
Epoch  33 Batch  580/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9620, Loss: 0.0130
Epoch  33 Batch  600/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9719, Loss: 0.0137
Epoch  33 Batch  620/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9627, Loss: 0.0170
Epoch  33 Batch  640/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9663, Loss: 0.0122
Epoch  33 Batch  660/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9602, Loss: 0.0112
Epoch  33 Batch  680/1077 - Train Accuracy: 0.9591, Validation Accuracy: 0.9602, Loss: 0.0152
Epoch  33 Batch  700/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9645, Loss: 0.0159
Epoch  33 Batch  720/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9531, Loss: 0.0187
Epoch  33 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9609, Loss: 0.0148
Epoch  33 Batch  760/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9691, Loss: 0.0168
Epoch  33 Batch  780/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9691, Loss: 0.0261
Epoch  33 Batch  800/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9695, Loss: 0.0167
Epoch  33 Batch  820/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9666, Loss: 0.0162
Epoch  33 Batch  840/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9695, Loss: 0.0189
Epoch  33 Batch  860/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9677, Loss: 0.0158
Epoch  33 Batch  880/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9723, Loss: 0.0210
Epoch  33 Batch  900/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9574, Loss: 0.0179
Epoch  33 Batch  920/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9663, Loss: 0.0145
Epoch  33 Batch  940/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9595, Loss: 0.0132
Epoch  33 Batch  960/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9656, Loss: 0.0134
Epoch  33 Batch  980/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9723, Loss: 0.0166
Epoch  33 Batch 1000/1077 - Train Accuracy: 0.9736, Validation Accuracy: 0.9542, Loss: 0.0179
Epoch  33 Batch 1020/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9474, Loss: 0.0093
Epoch  33 Batch 1040/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9588, Loss: 0.0138
Epoch  33 Batch 1060/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9560, Loss: 0.0110
Epoch  34 Batch   20/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9808, Loss: 0.0122
Epoch  34 Batch   40/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9574, Loss: 0.0112
Epoch  34 Batch   60/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9510, Loss: 0.0114
Epoch  34 Batch   80/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9741, Loss: 0.0134
Epoch  34 Batch  100/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9659, Loss: 0.0128
Epoch  34 Batch  120/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9545, Loss: 0.0168
Epoch  34 Batch  140/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9663, Loss: 0.0140
Epoch  34 Batch  160/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9645, Loss: 0.0150
Epoch  34 Batch  180/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9602, Loss: 0.0111
Epoch  34 Batch  200/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9666, Loss: 0.0117
Epoch  34 Batch  220/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9709, Loss: 0.0190
Epoch  34 Batch  240/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9602, Loss: 0.0115
Epoch  34 Batch  260/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9673, Loss: 0.0133
Epoch  34 Batch  280/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9602, Loss: 0.0182
Epoch  34 Batch  300/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9698, Loss: 0.0152
Epoch  34 Batch  320/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9609, Loss: 0.0250
Epoch  34 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9606, Loss: 0.0113
Epoch  34 Batch  360/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9666, Loss: 0.0152
Epoch  34 Batch  380/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9581, Loss: 0.0126
Epoch  34 Batch  400/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9652, Loss: 0.0188
Epoch  34 Batch  420/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9620, Loss: 0.0129
Epoch  34 Batch  440/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9474, Loss: 0.0175
Epoch  34 Batch  460/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9595, Loss: 0.0164
Epoch  34 Batch  480/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9542, Loss: 0.0124
Epoch  34 Batch  500/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9766, Loss: 0.0147
Epoch  34 Batch  520/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9680, Loss: 0.0107
Epoch  34 Batch  540/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9599, Loss: 0.0111
Epoch  34 Batch  560/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9616, Loss: 0.0136
Epoch  34 Batch  580/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9613, Loss: 0.0126
Epoch  34 Batch  600/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9783, Loss: 0.0158
Epoch  34 Batch  620/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9531, Loss: 0.0162
Epoch  34 Batch  640/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9741, Loss: 0.0126
Epoch  34 Batch  660/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9602, Loss: 0.0107
Epoch  34 Batch  680/1077 - Train Accuracy: 0.9591, Validation Accuracy: 0.9709, Loss: 0.0158
Epoch  34 Batch  700/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9613, Loss: 0.0143
Epoch  34 Batch  720/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9624, Loss: 0.0156
Epoch  34 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9677, Loss: 0.0145
Epoch  34 Batch  760/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9585, Loss: 0.0142
Epoch  34 Batch  780/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9723, Loss: 0.0209
Epoch  34 Batch  800/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9759, Loss: 0.0175
Epoch  34 Batch  820/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9719, Loss: 0.0153
Epoch  34 Batch  840/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9741, Loss: 0.0200
Epoch  34 Batch  860/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.9556, Loss: 0.0165
Epoch  34 Batch  880/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9705, Loss: 0.0200
Epoch  34 Batch  900/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9631, Loss: 0.0160
Epoch  34 Batch  920/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9773, Loss: 0.0132
Epoch  34 Batch  940/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9545, Loss: 0.0118
Epoch  34 Batch  960/1077 - Train Accuracy: 0.9654, Validation Accuracy: 0.9659, Loss: 0.0129
Epoch  34 Batch  980/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9602, Loss: 0.0159
Epoch  34 Batch 1000/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9574, Loss: 0.0179
Epoch  34 Batch 1020/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9499, Loss: 0.0098
Epoch  34 Batch 1040/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9585, Loss: 0.0128
Epoch  34 Batch 1060/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9471, Loss: 0.0178
Epoch  35 Batch   20/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9780, Loss: 0.0142
Epoch  35 Batch   40/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9652, Loss: 0.0110
Epoch  35 Batch   60/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9439, Loss: 0.0138
Epoch  35 Batch   80/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9620, Loss: 0.0148
Epoch  35 Batch  100/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9755, Loss: 0.0123
Epoch  35 Batch  120/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9624, Loss: 0.0165
Epoch  35 Batch  140/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9787, Loss: 0.0131
Epoch  35 Batch  160/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9716, Loss: 0.0153
Epoch  35 Batch  180/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9645, Loss: 0.0106
Epoch  35 Batch  200/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9705, Loss: 0.0128
Epoch  35 Batch  220/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9698, Loss: 0.0190
Epoch  35 Batch  240/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9688, Loss: 0.0110
Epoch  35 Batch  260/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.9585, Loss: 0.0128
Epoch  35 Batch  280/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9691, Loss: 0.0178
Epoch  35 Batch  300/1077 - Train Accuracy: 0.9708, Validation Accuracy: 0.9737, Loss: 0.0158
Epoch  35 Batch  320/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9645, Loss: 0.0258
Epoch  35 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9677, Loss: 0.0104
Epoch  35 Batch  360/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9712, Loss: 0.0125
Epoch  35 Batch  380/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9663, Loss: 0.0109
Epoch  35 Batch  400/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9698, Loss: 0.0164
Epoch  35 Batch  420/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9705, Loss: 0.0116
Epoch  35 Batch  440/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9428, Loss: 0.0152
Epoch  35 Batch  460/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9645, Loss: 0.0184
Epoch  35 Batch  480/1077 - Train Accuracy: 0.9729, Validation Accuracy: 0.9570, Loss: 0.0116
Epoch  35 Batch  500/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9819, Loss: 0.0148
Epoch  35 Batch  520/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9688, Loss: 0.0088
Epoch  35 Batch  540/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9570, Loss: 0.0102
Epoch  35 Batch  560/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9705, Loss: 0.0130
Epoch  35 Batch  580/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9695, Loss: 0.0118
Epoch  35 Batch  600/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9734, Loss: 0.0143
Epoch  35 Batch  620/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9581, Loss: 0.0162
Epoch  35 Batch  640/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9684, Loss: 0.0126
Epoch  35 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9730, Loss: 0.0098
Epoch  35 Batch  680/1077 - Train Accuracy: 0.9591, Validation Accuracy: 0.9670, Loss: 0.0143
Epoch  35 Batch  700/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9666, Loss: 0.0140
Epoch  35 Batch  720/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9663, Loss: 0.0205
Epoch  35 Batch  740/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9677, Loss: 0.0131
Epoch  35 Batch  760/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9680, Loss: 0.0141
Epoch  35 Batch  780/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9751, Loss: 0.0213
Epoch  35 Batch  800/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9737, Loss: 0.0158
Epoch  35 Batch  820/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9727, Loss: 0.0141
Epoch  35 Batch  840/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9748, Loss: 0.0183
Epoch  35 Batch  860/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9627, Loss: 0.0181
Epoch  35 Batch  880/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9712, Loss: 0.0212
Epoch  35 Batch  900/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9688, Loss: 0.0151
Epoch  35 Batch  920/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9684, Loss: 0.0128
Epoch  35 Batch  940/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9531, Loss: 0.0106
Epoch  35 Batch  960/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9702, Loss: 0.0136
Epoch  35 Batch  980/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9663, Loss: 0.0167
Epoch  35 Batch 1000/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9695, Loss: 0.0174
Epoch  35 Batch 1020/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9570, Loss: 0.0102
Epoch  35 Batch 1040/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9560, Loss: 0.0144
Epoch  35 Batch 1060/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9695, Loss: 0.0115
Epoch  36 Batch   20/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9815, Loss: 0.0111
Epoch  36 Batch   40/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9684, Loss: 0.0099
Epoch  36 Batch   60/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9474, Loss: 0.0112
Epoch  36 Batch   80/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9716, Loss: 0.0126
Epoch  36 Batch  100/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9659, Loss: 0.0111
Epoch  36 Batch  120/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9613, Loss: 0.0143
Epoch  36 Batch  140/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9801, Loss: 0.0127
Epoch  36 Batch  160/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9702, Loss: 0.0146
Epoch  36 Batch  180/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9648, Loss: 0.0094
Epoch  36 Batch  200/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9631, Loss: 0.0111
Epoch  36 Batch  220/1077 - Train Accuracy: 0.9733, Validation Accuracy: 0.9670, Loss: 0.0181
Epoch  36 Batch  240/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9727, Loss: 0.0117
Epoch  36 Batch  260/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9680, Loss: 0.0120
Epoch  36 Batch  280/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9577, Loss: 0.0175
Epoch  36 Batch  300/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9698, Loss: 0.0147
Epoch  36 Batch  320/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9684, Loss: 0.0231
Epoch  36 Batch  340/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9386, Loss: 0.0119
Epoch  36 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9656, Loss: 0.0136
Epoch  36 Batch  380/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9673, Loss: 0.0130
Epoch  36 Batch  400/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9723, Loss: 0.0163
Epoch  36 Batch  420/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9684, Loss: 0.0114
Epoch  36 Batch  440/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9542, Loss: 0.0153
Epoch  36 Batch  460/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9641, Loss: 0.0157
Epoch  36 Batch  480/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9538, Loss: 0.0113
Epoch  36 Batch  500/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9741, Loss: 0.0134
Epoch  36 Batch  520/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9737, Loss: 0.0100
Epoch  36 Batch  540/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9624, Loss: 0.0105
Epoch  36 Batch  560/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9709, Loss: 0.0118
Epoch  36 Batch  580/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9709, Loss: 0.0121
Epoch  36 Batch  600/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9748, Loss: 0.0166
Epoch  36 Batch  620/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9648, Loss: 0.0158
Epoch  36 Batch  640/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9645, Loss: 0.0100
Epoch  36 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9688, Loss: 0.0084
Epoch  36 Batch  680/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9712, Loss: 0.0144
Epoch  36 Batch  700/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9616, Loss: 0.0146
Epoch  36 Batch  720/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9776, Loss: 0.0153
Epoch  36 Batch  740/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9528, Loss: 0.0147
Epoch  36 Batch  760/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9730, Loss: 0.0130
Epoch  36 Batch  780/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9673, Loss: 0.0206
Epoch  36 Batch  800/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9780, Loss: 0.0149
Epoch  36 Batch  820/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9734, Loss: 0.0137
Epoch  36 Batch  840/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9698, Loss: 0.0165
Epoch  36 Batch  860/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9581, Loss: 0.0148
Epoch  36 Batch  880/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9656, Loss: 0.0194
Epoch  36 Batch  900/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9691, Loss: 0.0156
Epoch  36 Batch  920/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9787, Loss: 0.0117
Epoch  36 Batch  940/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9588, Loss: 0.0106
Epoch  36 Batch  960/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9609, Loss: 0.0120
Epoch  36 Batch  980/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9808, Loss: 0.0162
Epoch  36 Batch 1000/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9524, Loss: 0.0165
Epoch  36 Batch 1020/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9592, Loss: 0.0085
Epoch  36 Batch 1040/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9698, Loss: 0.0123
Epoch  36 Batch 1060/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9631, Loss: 0.0112
Epoch  37 Batch   20/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9790, Loss: 0.0114
Epoch  37 Batch   40/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9680, Loss: 0.0106
Epoch  37 Batch   60/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9414, Loss: 0.0102
Epoch  37 Batch   80/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9776, Loss: 0.0125
Epoch  37 Batch  100/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9634, Loss: 0.0109
Epoch  37 Batch  120/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9691, Loss: 0.0145
Epoch  37 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9666, Loss: 0.0121
Epoch  37 Batch  160/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9769, Loss: 0.0133
Epoch  37 Batch  180/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9648, Loss: 0.0092
Epoch  37 Batch  200/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9719, Loss: 0.0105
Epoch  37 Batch  220/1077 - Train Accuracy: 0.9708, Validation Accuracy: 0.9716, Loss: 0.0162
Epoch  37 Batch  240/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9737, Loss: 0.0103
Epoch  37 Batch  260/1077 - Train Accuracy: 0.9635, Validation Accuracy: 0.9673, Loss: 0.0116
Epoch  37 Batch  280/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9737, Loss: 0.0160
Epoch  37 Batch  300/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9755, Loss: 0.0144
Epoch  37 Batch  320/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9776, Loss: 0.0224
Epoch  37 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9563, Loss: 0.0092
Epoch  37 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9659, Loss: 0.0103
Epoch  37 Batch  380/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9613, Loss: 0.0107
Epoch  37 Batch  400/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9716, Loss: 0.0157
Epoch  37 Batch  420/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9716, Loss: 0.0119
Epoch  37 Batch  440/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9545, Loss: 0.0152
Epoch  37 Batch  460/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9599, Loss: 0.0159
Epoch  37 Batch  480/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9641, Loss: 0.0103
Epoch  37 Batch  500/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9808, Loss: 0.0130
Epoch  37 Batch  520/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9702, Loss: 0.0086
Epoch  37 Batch  540/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9677, Loss: 0.0102
Epoch  37 Batch  560/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9762, Loss: 0.0123
Epoch  37 Batch  580/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9734, Loss: 0.0111
Epoch  37 Batch  600/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9645, Loss: 0.0150
Epoch  37 Batch  620/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9648, Loss: 0.0156
Epoch  37 Batch  640/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9748, Loss: 0.0106
Epoch  37 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9716, Loss: 0.0085
Epoch  37 Batch  680/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9727, Loss: 0.0140
Epoch  37 Batch  700/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9627, Loss: 0.0124
Epoch  37 Batch  720/1077 - Train Accuracy: 0.9667, Validation Accuracy: 0.9702, Loss: 0.0161
Epoch  37 Batch  740/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9606, Loss: 0.0130
Epoch  37 Batch  760/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9716, Loss: 0.0123
Epoch  37 Batch  780/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9727, Loss: 0.0202
Epoch  37 Batch  800/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9812, Loss: 0.0142
Epoch  37 Batch  820/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9833, Loss: 0.0133
Epoch  37 Batch  840/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9705, Loss: 0.0157
Epoch  37 Batch  860/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9634, Loss: 0.0151
Epoch  37 Batch  880/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9677, Loss: 0.0195
Epoch  37 Batch  900/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9691, Loss: 0.0148
Epoch  37 Batch  920/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9762, Loss: 0.0117
Epoch  37 Batch  940/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9620, Loss: 0.0099
Epoch  37 Batch  960/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9627, Loss: 0.0126
Epoch  37 Batch  980/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9741, Loss: 0.0164
Epoch  37 Batch 1000/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9560, Loss: 0.0183
Epoch  37 Batch 1020/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9599, Loss: 0.0086
Epoch  37 Batch 1040/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9716, Loss: 0.0127
Epoch  37 Batch 1060/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9627, Loss: 0.0113
Epoch  38 Batch   20/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9830, Loss: 0.0101
Epoch  38 Batch   40/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9734, Loss: 0.0107
Epoch  38 Batch   60/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9648, Loss: 0.0116
Epoch  38 Batch   80/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9755, Loss: 0.0130
Epoch  38 Batch  100/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9709, Loss: 0.0134
Epoch  38 Batch  120/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9695, Loss: 0.0161
Epoch  38 Batch  140/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9737, Loss: 0.0125
Epoch  38 Batch  160/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9688, Loss: 0.0132
Epoch  38 Batch  180/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9698, Loss: 0.0090
Epoch  38 Batch  200/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9666, Loss: 0.0103
Epoch  38 Batch  220/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9773, Loss: 0.0168
Epoch  38 Batch  240/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9688, Loss: 0.0098
Epoch  38 Batch  260/1077 - Train Accuracy: 0.9706, Validation Accuracy: 0.9620, Loss: 0.0111
Epoch  38 Batch  280/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9776, Loss: 0.0162
Epoch  38 Batch  300/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9748, Loss: 0.0142
Epoch  38 Batch  320/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9688, Loss: 0.0213
Epoch  38 Batch  340/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9659, Loss: 0.0088
Epoch  38 Batch  360/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9698, Loss: 0.0103
Epoch  38 Batch  380/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9688, Loss: 0.0099
Epoch  38 Batch  400/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9666, Loss: 0.0165
Epoch  38 Batch  420/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9723, Loss: 0.0120
Epoch  38 Batch  440/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9542, Loss: 0.0145
Epoch  38 Batch  460/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9695, Loss: 0.0135
Epoch  38 Batch  480/1077 - Train Accuracy: 0.9815, Validation Accuracy: 0.9599, Loss: 0.0109
Epoch  38 Batch  500/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9794, Loss: 0.0116
Epoch  38 Batch  520/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9634, Loss: 0.0087
Epoch  38 Batch  540/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9595, Loss: 0.0094
Epoch  38 Batch  560/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9734, Loss: 0.0128
Epoch  38 Batch  580/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9677, Loss: 0.0112
Epoch  38 Batch  600/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9719, Loss: 0.0132
Epoch  38 Batch  620/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9673, Loss: 0.0151
Epoch  38 Batch  640/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9769, Loss: 0.0089
Epoch  38 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9712, Loss: 0.0083
Epoch  38 Batch  680/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9609, Loss: 0.0146
Epoch  38 Batch  700/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9702, Loss: 0.0124
Epoch  38 Batch  720/1077 - Train Accuracy: 0.9774, Validation Accuracy: 0.9670, Loss: 0.0133
Epoch  38 Batch  740/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9695, Loss: 0.0127
Epoch  38 Batch  760/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9812, Loss: 0.0129
Epoch  38 Batch  780/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9826, Loss: 0.0187
Epoch  38 Batch  800/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9808, Loss: 0.0143
Epoch  38 Batch  820/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9762, Loss: 0.0131
Epoch  38 Batch  840/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9844, Loss: 0.0146
Epoch  38 Batch  860/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9624, Loss: 0.0154
Epoch  38 Batch  880/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9684, Loss: 0.0191
Epoch  38 Batch  900/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9730, Loss: 0.0121
Epoch  38 Batch  920/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9670, Loss: 0.0122
Epoch  38 Batch  940/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9528, Loss: 0.0100
Epoch  38 Batch  960/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9744, Loss: 0.0117
Epoch  38 Batch  980/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9766, Loss: 0.0149
Epoch  38 Batch 1000/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9652, Loss: 0.0157
Epoch  38 Batch 1020/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9613, Loss: 0.0078
Epoch  38 Batch 1040/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9663, Loss: 0.0120
Epoch  38 Batch 1060/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9521, Loss: 0.0108
Epoch  39 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9762, Loss: 0.0108
Epoch  39 Batch   40/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9744, Loss: 0.0091
Epoch  39 Batch   60/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9535, Loss: 0.0109
Epoch  39 Batch   80/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9790, Loss: 0.0116
Epoch  39 Batch  100/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9702, Loss: 0.0091
Epoch  39 Batch  120/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9737, Loss: 0.0127
Epoch  39 Batch  140/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9723, Loss: 0.0126
Epoch  39 Batch  160/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9769, Loss: 0.0134
Epoch  39 Batch  180/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9652, Loss: 0.0090
Epoch  39 Batch  200/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9652, Loss: 0.0104
Epoch  39 Batch  220/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9620, Loss: 0.0157
Epoch  39 Batch  240/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9741, Loss: 0.0096
Epoch  39 Batch  260/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9787, Loss: 0.0101
Epoch  39 Batch  280/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9730, Loss: 0.0155
Epoch  39 Batch  300/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9673, Loss: 0.0138
Epoch  39 Batch  320/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9695, Loss: 0.0212
Epoch  39 Batch  340/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9684, Loss: 0.0095
Epoch  39 Batch  360/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9698, Loss: 0.0106
Epoch  39 Batch  380/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9705, Loss: 0.0102
Epoch  39 Batch  400/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9663, Loss: 0.0153
Epoch  39 Batch  420/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9716, Loss: 0.0118
Epoch  39 Batch  440/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9624, Loss: 0.0143
Epoch  39 Batch  460/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9695, Loss: 0.0128
Epoch  39 Batch  480/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9631, Loss: 0.0108
Epoch  39 Batch  500/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9776, Loss: 0.0120
Epoch  39 Batch  520/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9698, Loss: 0.0092
Epoch  39 Batch  540/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9606, Loss: 0.0085
Epoch  39 Batch  560/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9783, Loss: 0.0110
Epoch  39 Batch  580/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9680, Loss: 0.0097
Epoch  39 Batch  600/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9833, Loss: 0.0155
Epoch  39 Batch  620/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9677, Loss: 0.0148
Epoch  39 Batch  640/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9716, Loss: 0.0092
Epoch  39 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9641, Loss: 0.0082
Epoch  39 Batch  680/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9727, Loss: 0.0147
Epoch  39 Batch  700/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9705, Loss: 0.0120
Epoch  39 Batch  720/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9684, Loss: 0.0136
Epoch  39 Batch  740/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9602, Loss: 0.0145
Epoch  39 Batch  760/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9805, Loss: 0.0167
Epoch  39 Batch  780/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9730, Loss: 0.0196
Epoch  39 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9805, Loss: 0.0131
Epoch  39 Batch  820/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9812, Loss: 0.0127
Epoch  39 Batch  840/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9851, Loss: 0.0153
Epoch  39 Batch  860/1077 - Train Accuracy: 0.9728, Validation Accuracy: 0.9680, Loss: 0.0145
Epoch  39 Batch  880/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9759, Loss: 0.0187
Epoch  39 Batch  900/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9695, Loss: 0.0136
Epoch  39 Batch  920/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9744, Loss: 0.0098
Epoch  39 Batch  940/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9553, Loss: 0.0107
Epoch  39 Batch  960/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9616, Loss: 0.0108
Epoch  39 Batch  980/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9670, Loss: 0.0146
Epoch  39 Batch 1000/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9606, Loss: 0.0150
Epoch  39 Batch 1020/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9588, Loss: 0.0083
Epoch  39 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9663, Loss: 0.0129
Epoch  39 Batch 1060/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9648, Loss: 0.0092
Epoch  40 Batch   20/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9794, Loss: 0.0102
Epoch  40 Batch   40/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9762, Loss: 0.0090
Epoch  40 Batch   60/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9467, Loss: 0.0110
Epoch  40 Batch   80/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9709, Loss: 0.0113
Epoch  40 Batch  100/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9712, Loss: 0.0091
Epoch  40 Batch  120/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9727, Loss: 0.0146
Epoch  40 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9730, Loss: 0.0114
Epoch  40 Batch  160/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9766, Loss: 0.0120
Epoch  40 Batch  180/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9755, Loss: 0.0086
Epoch  40 Batch  200/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9666, Loss: 0.0097
Epoch  40 Batch  220/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9822, Loss: 0.0147
Epoch  40 Batch  240/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9737, Loss: 0.0087
Epoch  40 Batch  260/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9695, Loss: 0.0100
Epoch  40 Batch  280/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9755, Loss: 0.0161
Epoch  40 Batch  300/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9755, Loss: 0.0137
Epoch  40 Batch  320/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9670, Loss: 0.0200
Epoch  40 Batch  340/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9702, Loss: 0.0084
Epoch  40 Batch  360/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9641, Loss: 0.0093
Epoch  40 Batch  380/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9627, Loss: 0.0096
Epoch  40 Batch  400/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9727, Loss: 0.0148
Epoch  40 Batch  420/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9727, Loss: 0.0112
Epoch  40 Batch  440/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9652, Loss: 0.0134
Epoch  40 Batch  460/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9730, Loss: 0.0122
Epoch  40 Batch  480/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9712, Loss: 0.0108
Epoch  40 Batch  500/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9737, Loss: 0.0112
Epoch  40 Batch  520/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9698, Loss: 0.0085
Epoch  40 Batch  540/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9631, Loss: 0.0083
Epoch  40 Batch  560/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9688, Loss: 0.0107
Epoch  40 Batch  580/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9684, Loss: 0.0107
Epoch  40 Batch  600/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9794, Loss: 0.0140
Epoch  40 Batch  620/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9673, Loss: 0.0129
Epoch  40 Batch  640/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9737, Loss: 0.0088
Epoch  40 Batch  660/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9663, Loss: 0.0088
Epoch  40 Batch  680/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9698, Loss: 0.0126
Epoch  40 Batch  700/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9631, Loss: 0.0118
Epoch  40 Batch  720/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9673, Loss: 0.0151
Epoch  40 Batch  740/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9641, Loss: 0.0122
Epoch  40 Batch  760/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9656, Loss: 0.0128
Epoch  40 Batch  780/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9819, Loss: 0.0213
Epoch  40 Batch  800/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9808, Loss: 0.0128
Epoch  40 Batch  820/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9762, Loss: 0.0134
Epoch  40 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9851, Loss: 0.0150
Epoch  40 Batch  860/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9513, Loss: 0.0148
Epoch  40 Batch  880/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9659, Loss: 0.0184
Epoch  40 Batch  900/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9759, Loss: 0.0133
Epoch  40 Batch  920/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9627, Loss: 0.0095
Epoch  40 Batch  940/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9656, Loss: 0.0086
Epoch  40 Batch  960/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9709, Loss: 0.0106
Epoch  40 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9719, Loss: 0.0145
Epoch  40 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9741, Loss: 0.0144
Epoch  40 Batch 1020/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9666, Loss: 0.0086
Epoch  40 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9741, Loss: 0.0119
Epoch  40 Batch 1060/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9602, Loss: 0.0118
Epoch  41 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9759, Loss: 0.0100
Epoch  41 Batch   40/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9688, Loss: 0.0101
Epoch  41 Batch   60/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9659, Loss: 0.0107
Epoch  41 Batch   80/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9762, Loss: 0.0112
Epoch  41 Batch  100/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9719, Loss: 0.0088
Epoch  41 Batch  120/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9822, Loss: 0.0117
Epoch  41 Batch  140/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9730, Loss: 0.0115
Epoch  41 Batch  160/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9794, Loss: 0.0112
Epoch  41 Batch  180/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9790, Loss: 0.0085
Epoch  41 Batch  200/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9666, Loss: 0.0084
Epoch  41 Batch  220/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9805, Loss: 0.0130
Epoch  41 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9872, Loss: 0.0085
Epoch  41 Batch  260/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9780, Loss: 0.0094
Epoch  41 Batch  280/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9737, Loss: 0.0153
Epoch  41 Batch  300/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9808, Loss: 0.0140
Epoch  41 Batch  320/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9712, Loss: 0.0182
Epoch  41 Batch  340/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9744, Loss: 0.0086
Epoch  41 Batch  360/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9691, Loss: 0.0102
Epoch  41 Batch  380/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9606, Loss: 0.0093
Epoch  41 Batch  400/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9766, Loss: 0.0157
Epoch  41 Batch  420/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9748, Loss: 0.0107
Epoch  41 Batch  440/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9616, Loss: 0.0125
Epoch  41 Batch  460/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9634, Loss: 0.0133
Epoch  41 Batch  480/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9677, Loss: 0.0103
Epoch  41 Batch  500/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9730, Loss: 0.0104
Epoch  41 Batch  520/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9631, Loss: 0.0083
Epoch  41 Batch  540/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9744, Loss: 0.0080
Epoch  41 Batch  560/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9702, Loss: 0.0129
Epoch  41 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9709, Loss: 0.0109
Epoch  41 Batch  600/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9840, Loss: 0.0131
Epoch  41 Batch  620/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9641, Loss: 0.0133
Epoch  41 Batch  640/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9730, Loss: 0.0093
Epoch  41 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9670, Loss: 0.0101
Epoch  41 Batch  680/1077 - Train Accuracy: 0.9721, Validation Accuracy: 0.9734, Loss: 0.0130
Epoch  41 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9684, Loss: 0.0119
Epoch  41 Batch  720/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9634, Loss: 0.0125
Epoch  41 Batch  740/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9790, Loss: 0.0110
Epoch  41 Batch  760/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9759, Loss: 0.0122
Epoch  41 Batch  780/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9680, Loss: 0.0195
Epoch  41 Batch  800/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9844, Loss: 0.0127
Epoch  41 Batch  820/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9808, Loss: 0.0114
Epoch  41 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9790, Loss: 0.0135
Epoch  41 Batch  860/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9592, Loss: 0.0146
Epoch  41 Batch  880/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9759, Loss: 0.0168
Epoch  41 Batch  900/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9730, Loss: 0.0126
Epoch  41 Batch  920/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9677, Loss: 0.0096
Epoch  41 Batch  940/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9709, Loss: 0.0099
Epoch  41 Batch  960/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9677, Loss: 0.0108
Epoch  41 Batch  980/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9719, Loss: 0.0132
Epoch  41 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9801, Loss: 0.0144
Epoch  41 Batch 1020/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9723, Loss: 0.0080
Epoch  41 Batch 1040/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9719, Loss: 0.0116
Epoch  41 Batch 1060/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9719, Loss: 0.0090
Epoch  42 Batch   20/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9759, Loss: 0.0096
Epoch  42 Batch   40/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9762, Loss: 0.0084
Epoch  42 Batch   60/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9496, Loss: 0.0092
Epoch  42 Batch   80/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9737, Loss: 0.0105
Epoch  42 Batch  100/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9730, Loss: 0.0099
Epoch  42 Batch  120/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9737, Loss: 0.0139
Epoch  42 Batch  140/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9698, Loss: 0.0126
Epoch  42 Batch  160/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9748, Loss: 0.0114
Epoch  42 Batch  180/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9709, Loss: 0.0084
Epoch  42 Batch  200/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9723, Loss: 0.0105
Epoch  42 Batch  220/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9719, Loss: 0.0133
Epoch  42 Batch  240/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9794, Loss: 0.0081
Epoch  42 Batch  260/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9648, Loss: 0.0092
Epoch  42 Batch  280/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9727, Loss: 0.0146
Epoch  42 Batch  300/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9776, Loss: 0.0130
Epoch  42 Batch  320/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9734, Loss: 0.0193
Epoch  42 Batch  340/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9712, Loss: 0.0067
Epoch  42 Batch  360/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9719, Loss: 0.0094
Epoch  42 Batch  380/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9656, Loss: 0.0096
Epoch  42 Batch  400/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9783, Loss: 0.0135
Epoch  42 Batch  420/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9769, Loss: 0.0112
Epoch  42 Batch  440/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9645, Loss: 0.0118
Epoch  42 Batch  460/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9624, Loss: 0.0128
Epoch  42 Batch  480/1077 - Train Accuracy: 0.9815, Validation Accuracy: 0.9570, Loss: 0.0090
Epoch  42 Batch  500/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9670, Loss: 0.0094
Epoch  42 Batch  520/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9744, Loss: 0.0086
Epoch  42 Batch  540/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9663, Loss: 0.0083
Epoch  42 Batch  560/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9709, Loss: 0.0090
Epoch  42 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9730, Loss: 0.0098
Epoch  42 Batch  600/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9858, Loss: 0.0122
Epoch  42 Batch  620/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9634, Loss: 0.0129
Epoch  42 Batch  640/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9766, Loss: 0.0079
Epoch  42 Batch  660/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9705, Loss: 0.0076
Epoch  42 Batch  680/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9691, Loss: 0.0122
Epoch  42 Batch  700/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9663, Loss: 0.0105
Epoch  42 Batch  720/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9709, Loss: 0.0112
Epoch  42 Batch  740/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9702, Loss: 0.0132
Epoch  42 Batch  760/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9716, Loss: 0.0102
Epoch  42 Batch  780/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9769, Loss: 0.0179
Epoch  42 Batch  800/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9773, Loss: 0.0115
Epoch  42 Batch  820/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9872, Loss: 0.0118
Epoch  42 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9787, Loss: 0.0135
Epoch  42 Batch  860/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9627, Loss: 0.0138
Epoch  42 Batch  880/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9719, Loss: 0.0170
Epoch  42 Batch  900/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9709, Loss: 0.0125
Epoch  42 Batch  920/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9751, Loss: 0.0091
Epoch  42 Batch  940/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9691, Loss: 0.0084
Epoch  42 Batch  960/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9620, Loss: 0.0104
Epoch  42 Batch  980/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9719, Loss: 0.0126
Epoch  42 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9787, Loss: 0.0129
Epoch  42 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9769, Loss: 0.0074
Epoch  42 Batch 1040/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9783, Loss: 0.0111
Epoch  42 Batch 1060/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9609, Loss: 0.0084
Epoch  43 Batch   20/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9812, Loss: 0.0090
Epoch  43 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9727, Loss: 0.0092
Epoch  43 Batch   60/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9528, Loss: 0.0086
Epoch  43 Batch   80/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9737, Loss: 0.0103
Epoch  43 Batch  100/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9670, Loss: 0.0103
Epoch  43 Batch  120/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9744, Loss: 0.0125
Epoch  43 Batch  140/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9734, Loss: 0.0125
Epoch  43 Batch  160/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9783, Loss: 0.0127
Epoch  43 Batch  180/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9719, Loss: 0.0079
Epoch  43 Batch  200/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9762, Loss: 0.0089
Epoch  43 Batch  220/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9751, Loss: 0.0118
Epoch  43 Batch  240/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9876, Loss: 0.0071
Epoch  43 Batch  260/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9787, Loss: 0.0085
Epoch  43 Batch  280/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9798, Loss: 0.0139
Epoch  43 Batch  300/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9783, Loss: 0.0134
Epoch  43 Batch  320/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9730, Loss: 0.0199
Epoch  43 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9734, Loss: 0.0078
Epoch  43 Batch  360/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9638, Loss: 0.0110
Epoch  43 Batch  380/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9812, Loss: 0.0095
Epoch  43 Batch  400/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9705, Loss: 0.0170
Epoch  43 Batch  420/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9798, Loss: 0.0140
Epoch  43 Batch  440/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9403, Loss: 0.0116
Epoch  43 Batch  460/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9730, Loss: 0.0138
Epoch  43 Batch  480/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9659, Loss: 0.0093
Epoch  43 Batch  500/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9695, Loss: 0.0093
Epoch  43 Batch  520/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9673, Loss: 0.0078
Epoch  43 Batch  540/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9677, Loss: 0.0075
Epoch  43 Batch  560/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9712, Loss: 0.0114
Epoch  43 Batch  580/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9705, Loss: 0.0092
Epoch  43 Batch  600/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9819, Loss: 0.0148
Epoch  43 Batch  620/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9844, Loss: 0.0135
Epoch  43 Batch  640/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9719, Loss: 0.0082
Epoch  43 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9613, Loss: 0.0064
Epoch  43 Batch  680/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9712, Loss: 0.0127
Epoch  43 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9709, Loss: 0.0101
Epoch  43 Batch  720/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9741, Loss: 0.0104
Epoch  43 Batch  740/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9830, Loss: 0.0117
Epoch  43 Batch  760/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9808, Loss: 0.0120
Epoch  43 Batch  780/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9744, Loss: 0.0172
Epoch  43 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9847, Loss: 0.0107
Epoch  43 Batch  820/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9790, Loss: 0.0111
Epoch  43 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9776, Loss: 0.0123
Epoch  43 Batch  860/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9638, Loss: 0.0134
Epoch  43 Batch  880/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9691, Loss: 0.0166
Epoch  43 Batch  900/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9844, Loss: 0.0112
Epoch  43 Batch  920/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9748, Loss: 0.0091
Epoch  43 Batch  940/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9677, Loss: 0.0082
Epoch  43 Batch  960/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9737, Loss: 0.0093
Epoch  43 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9656, Loss: 0.0132
Epoch  43 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9730, Loss: 0.0126
Epoch  43 Batch 1020/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9769, Loss: 0.0073
Epoch  43 Batch 1040/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9712, Loss: 0.0104
Epoch  43 Batch 1060/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9759, Loss: 0.0082
Epoch  44 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9698, Loss: 0.0078
Epoch  44 Batch   40/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9780, Loss: 0.0090
Epoch  44 Batch   60/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9709, Loss: 0.0111
Epoch  44 Batch   80/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9684, Loss: 0.0109
Epoch  44 Batch  100/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9648, Loss: 0.0097
Epoch  44 Batch  120/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9599, Loss: 0.0126
Epoch  44 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0105
Epoch  44 Batch  160/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9737, Loss: 0.0115
Epoch  44 Batch  180/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9787, Loss: 0.0079
Epoch  44 Batch  200/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9773, Loss: 0.0092
Epoch  44 Batch  220/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9801, Loss: 0.0125
Epoch  44 Batch  240/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9759, Loss: 0.0077
Epoch  44 Batch  260/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9762, Loss: 0.0076
Epoch  44 Batch  280/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9755, Loss: 0.0147
Epoch  44 Batch  300/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9727, Loss: 0.0126
Epoch  44 Batch  320/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9691, Loss: 0.0170
Epoch  44 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9702, Loss: 0.0093
Epoch  44 Batch  360/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9751, Loss: 0.0091
Epoch  44 Batch  380/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9727, Loss: 0.0078
Epoch  44 Batch  400/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9744, Loss: 0.0130
Epoch  44 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9762, Loss: 0.0095
Epoch  44 Batch  440/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9684, Loss: 0.0108
Epoch  44 Batch  460/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9624, Loss: 0.0132
Epoch  44 Batch  480/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9659, Loss: 0.0089
Epoch  44 Batch  500/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9730, Loss: 0.0083
Epoch  44 Batch  520/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9677, Loss: 0.0078
Epoch  44 Batch  540/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9709, Loss: 0.0080
Epoch  44 Batch  560/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9741, Loss: 0.0097
Epoch  44 Batch  580/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9787, Loss: 0.0096
Epoch  44 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9830, Loss: 0.0116
Epoch  44 Batch  620/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9790, Loss: 0.0120
Epoch  44 Batch  640/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9748, Loss: 0.0097
Epoch  44 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9645, Loss: 0.0067
Epoch  44 Batch  680/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9645, Loss: 0.0119
Epoch  44 Batch  700/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9688, Loss: 0.0100
Epoch  44 Batch  720/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9844, Loss: 0.0109
Epoch  44 Batch  740/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9826, Loss: 0.0103
Epoch  44 Batch  760/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9808, Loss: 0.0132
Epoch  44 Batch  780/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9794, Loss: 0.0164
Epoch  44 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9790, Loss: 0.0093
Epoch  44 Batch  820/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9844, Loss: 0.0105
Epoch  44 Batch  840/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9840, Loss: 0.0117
Epoch  44 Batch  860/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9663, Loss: 0.0134
Epoch  44 Batch  880/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9638, Loss: 0.0163
Epoch  44 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9844, Loss: 0.0120
Epoch  44 Batch  920/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9737, Loss: 0.0099
Epoch  44 Batch  940/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9744, Loss: 0.0093
Epoch  44 Batch  960/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9631, Loss: 0.0090
Epoch  44 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9723, Loss: 0.0131
Epoch  44 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9759, Loss: 0.0128
Epoch  44 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9755, Loss: 0.0069
Epoch  44 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9595, Loss: 0.0105
Epoch  44 Batch 1060/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9645, Loss: 0.0088
Epoch  45 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9748, Loss: 0.0083
Epoch  45 Batch   40/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9766, Loss: 0.0085
Epoch  45 Batch   60/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9620, Loss: 0.0087
Epoch  45 Batch   80/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9620, Loss: 0.0115
Epoch  45 Batch  100/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9666, Loss: 0.0091
Epoch  45 Batch  120/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9812, Loss: 0.0112
Epoch  45 Batch  140/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9748, Loss: 0.0123
Epoch  45 Batch  160/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9773, Loss: 0.0103
Epoch  45 Batch  180/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9698, Loss: 0.0083
Epoch  45 Batch  200/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9712, Loss: 0.0094
Epoch  45 Batch  220/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9790, Loss: 0.0116
Epoch  45 Batch  240/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9815, Loss: 0.0081
Epoch  45 Batch  260/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9751, Loss: 0.0080
Epoch  45 Batch  280/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9819, Loss: 0.0133
Epoch  45 Batch  300/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9688, Loss: 0.0128
Epoch  45 Batch  320/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9776, Loss: 0.0197
Epoch  45 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9719, Loss: 0.0063
Epoch  45 Batch  360/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9705, Loss: 0.0099
Epoch  45 Batch  380/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9705, Loss: 0.0077
Epoch  45 Batch  400/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9780, Loss: 0.0116
Epoch  45 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9805, Loss: 0.0094
Epoch  45 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9680, Loss: 0.0107
Epoch  45 Batch  460/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9659, Loss: 0.0115
Epoch  45 Batch  480/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9609, Loss: 0.0096
Epoch  45 Batch  500/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9751, Loss: 0.0080
Epoch  45 Batch  520/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9680, Loss: 0.0069
Epoch  45 Batch  540/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9748, Loss: 0.0077
Epoch  45 Batch  560/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9727, Loss: 0.0089
Epoch  45 Batch  580/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9783, Loss: 0.0092
Epoch  45 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9748, Loss: 0.0118
Epoch  45 Batch  620/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9751, Loss: 0.0119
Epoch  45 Batch  640/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9684, Loss: 0.0079
Epoch  45 Batch  660/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9688, Loss: 0.0070
Epoch  45 Batch  680/1077 - Train Accuracy: 0.9706, Validation Accuracy: 0.9645, Loss: 0.0115
Epoch  45 Batch  700/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9783, Loss: 0.0111
Epoch  45 Batch  720/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9794, Loss: 0.0101
Epoch  45 Batch  740/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9822, Loss: 0.0123
Epoch  45 Batch  760/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9769, Loss: 0.0102
Epoch  45 Batch  780/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9805, Loss: 0.0167
Epoch  45 Batch  800/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9840, Loss: 0.0107
Epoch  45 Batch  820/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9901, Loss: 0.0099
Epoch  45 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9801, Loss: 0.0112
Epoch  45 Batch  860/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9592, Loss: 0.0117
Epoch  45 Batch  880/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9748, Loss: 0.0153
Epoch  45 Batch  900/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9798, Loss: 0.0105
Epoch  45 Batch  920/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9790, Loss: 0.0080
Epoch  45 Batch  940/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9723, Loss: 0.0079
Epoch  45 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9716, Loss: 0.0088
Epoch  45 Batch  980/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9723, Loss: 0.0121
Epoch  45 Batch 1000/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9783, Loss: 0.0112
Epoch  45 Batch 1020/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9766, Loss: 0.0073
Epoch  45 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9673, Loss: 0.0094
Epoch  45 Batch 1060/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9741, Loss: 0.0171
Epoch  46 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9805, Loss: 0.0093
Epoch  46 Batch   40/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9691, Loss: 0.0094
Epoch  46 Batch   60/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9645, Loss: 0.0080
Epoch  46 Batch   80/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9759, Loss: 0.0124
Epoch  46 Batch  100/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9730, Loss: 0.0119
Epoch  46 Batch  120/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9723, Loss: 0.0095
Epoch  46 Batch  140/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9840, Loss: 0.0110
Epoch  46 Batch  160/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9766, Loss: 0.0109
Epoch  46 Batch  180/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9666, Loss: 0.0080
Epoch  46 Batch  200/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9801, Loss: 0.0089
Epoch  46 Batch  220/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9734, Loss: 0.0110
Epoch  46 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9798, Loss: 0.0069
Epoch  46 Batch  260/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9744, Loss: 0.0083
Epoch  46 Batch  280/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9776, Loss: 0.0139
Epoch  46 Batch  300/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9712, Loss: 0.0125
Epoch  46 Batch  320/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9773, Loss: 0.0184
Epoch  46 Batch  340/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9783, Loss: 0.0068
Epoch  46 Batch  360/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9620, Loss: 0.0087
Epoch  46 Batch  380/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9759, Loss: 0.0074
Epoch  46 Batch  400/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9798, Loss: 0.0107
Epoch  46 Batch  420/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9780, Loss: 0.0102
Epoch  46 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9563, Loss: 0.0098
Epoch  46 Batch  460/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9783, Loss: 0.0109
Epoch  46 Batch  480/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9673, Loss: 0.0075
Epoch  46 Batch  500/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9812, Loss: 0.0080
Epoch  46 Batch  520/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9741, Loss: 0.0080
Epoch  46 Batch  540/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9776, Loss: 0.0072
Epoch  46 Batch  560/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9762, Loss: 0.0092
Epoch  46 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9790, Loss: 0.0091
Epoch  46 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9815, Loss: 0.0116
Epoch  46 Batch  620/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9730, Loss: 0.0107
Epoch  46 Batch  640/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9744, Loss: 0.0076
Epoch  46 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9702, Loss: 0.0057
Epoch  46 Batch  680/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9648, Loss: 0.0106
Epoch  46 Batch  700/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9759, Loss: 0.0094
Epoch  46 Batch  720/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9759, Loss: 0.0099
Epoch  46 Batch  740/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9801, Loss: 0.0104
Epoch  46 Batch  760/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9716, Loss: 0.0118
Epoch  46 Batch  780/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9773, Loss: 0.0156
Epoch  46 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9798, Loss: 0.0093
Epoch  46 Batch  820/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9759, Loss: 0.0092
Epoch  46 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9762, Loss: 0.0106
Epoch  46 Batch  860/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9609, Loss: 0.0122
Epoch  46 Batch  880/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9744, Loss: 0.0174
Epoch  46 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9748, Loss: 0.0116
Epoch  46 Batch  920/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9730, Loss: 0.0078
Epoch  46 Batch  940/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9727, Loss: 0.0087
Epoch  46 Batch  960/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9737, Loss: 0.0098
Epoch  46 Batch  980/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9727, Loss: 0.0116
Epoch  46 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9833, Loss: 0.0133
Epoch  46 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9737, Loss: 0.0088
Epoch  46 Batch 1040/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9702, Loss: 0.0118
Epoch  46 Batch 1060/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9776, Loss: 0.0087
Epoch  47 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9790, Loss: 0.0074
Epoch  47 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9695, Loss: 0.0076
Epoch  47 Batch   60/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9496, Loss: 0.0095
Epoch  47 Batch   80/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9691, Loss: 0.0101
Epoch  47 Batch  100/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9663, Loss: 0.0095
Epoch  47 Batch  120/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9730, Loss: 0.0097
Epoch  47 Batch  140/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9741, Loss: 0.0096
Epoch  47 Batch  160/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9798, Loss: 0.0094
Epoch  47 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9723, Loss: 0.0072
Epoch  47 Batch  200/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9769, Loss: 0.0082
Epoch  47 Batch  220/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9815, Loss: 0.0118
Epoch  47 Batch  240/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9840, Loss: 0.0075
Epoch  47 Batch  260/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9776, Loss: 0.0090
Epoch  47 Batch  280/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9712, Loss: 0.0136
Epoch  47 Batch  300/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9712, Loss: 0.0133
Epoch  47 Batch  320/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9652, Loss: 0.0169
Epoch  47 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9798, Loss: 0.0074
Epoch  47 Batch  360/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9783, Loss: 0.0079
Epoch  47 Batch  380/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9737, Loss: 0.0081
Epoch  47 Batch  400/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9876, Loss: 0.0098
Epoch  47 Batch  420/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9812, Loss: 0.0088
Epoch  47 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9730, Loss: 0.0102
Epoch  47 Batch  460/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9727, Loss: 0.0102
Epoch  47 Batch  480/1077 - Train Accuracy: 0.9815, Validation Accuracy: 0.9698, Loss: 0.0086
Epoch  47 Batch  500/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9762, Loss: 0.0072
Epoch  47 Batch  520/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9798, Loss: 0.0065
Epoch  47 Batch  540/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9776, Loss: 0.0072
Epoch  47 Batch  560/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9737, Loss: 0.0091
Epoch  47 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9769, Loss: 0.0092
Epoch  47 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9833, Loss: 0.0107
Epoch  47 Batch  620/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9783, Loss: 0.0108
Epoch  47 Batch  640/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9748, Loss: 0.0076
Epoch  47 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9677, Loss: 0.0071
Epoch  47 Batch  680/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9688, Loss: 0.0128
Epoch  47 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9688, Loss: 0.0093
Epoch  47 Batch  720/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9776, Loss: 0.0094
Epoch  47 Batch  740/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9762, Loss: 0.0098
Epoch  47 Batch  760/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9830, Loss: 0.0103
Epoch  47 Batch  780/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9833, Loss: 0.0164
Epoch  47 Batch  800/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9794, Loss: 0.0093
Epoch  47 Batch  820/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9776, Loss: 0.0097
Epoch  47 Batch  840/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9766, Loss: 0.0114
Epoch  47 Batch  860/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9592, Loss: 0.0127
Epoch  47 Batch  880/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9677, Loss: 0.0151
Epoch  47 Batch  900/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9847, Loss: 0.0117
Epoch  47 Batch  920/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9762, Loss: 0.0084
Epoch  47 Batch  940/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9794, Loss: 0.0074
Epoch  47 Batch  960/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9688, Loss: 0.0091
Epoch  47 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9727, Loss: 0.0122
Epoch  47 Batch 1000/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9798, Loss: 0.0116
Epoch  47 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9716, Loss: 0.0067
Epoch  47 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9677, Loss: 0.0109
Epoch  47 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9911, Loss: 0.0079
Epoch  48 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9837, Loss: 0.0069
Epoch  48 Batch   40/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9783, Loss: 0.0081
Epoch  48 Batch   60/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9567, Loss: 0.0084
Epoch  48 Batch   80/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9826, Loss: 0.0105
Epoch  48 Batch  100/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9744, Loss: 0.0092
Epoch  48 Batch  120/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9751, Loss: 0.0097
Epoch  48 Batch  140/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9769, Loss: 0.0100
Epoch  48 Batch  160/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9801, Loss: 0.0085
Epoch  48 Batch  180/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9719, Loss: 0.0069
Epoch  48 Batch  200/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9790, Loss: 0.0090
Epoch  48 Batch  220/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9755, Loss: 0.0109
Epoch  48 Batch  240/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9879, Loss: 0.0078
Epoch  48 Batch  260/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9737, Loss: 0.0083
Epoch  48 Batch  280/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9638, Loss: 0.0124
Epoch  48 Batch  300/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9759, Loss: 0.0116
Epoch  48 Batch  320/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9698, Loss: 0.0185
Epoch  48 Batch  340/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9751, Loss: 0.0083
Epoch  48 Batch  360/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9734, Loss: 0.0074
Epoch  48 Batch  380/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9709, Loss: 0.0073
Epoch  48 Batch  400/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9830, Loss: 0.0097
Epoch  48 Batch  420/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9812, Loss: 0.0099
Epoch  48 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9613, Loss: 0.0099
Epoch  48 Batch  460/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9652, Loss: 0.0106
Epoch  48 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9691, Loss: 0.0076
Epoch  48 Batch  500/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9734, Loss: 0.0063
Epoch  48 Batch  520/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9755, Loss: 0.0077
Epoch  48 Batch  540/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9705, Loss: 0.0076
Epoch  48 Batch  560/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9709, Loss: 0.0085
Epoch  48 Batch  580/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9862, Loss: 0.0090
Epoch  48 Batch  600/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9830, Loss: 0.0098
Epoch  48 Batch  620/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9794, Loss: 0.0112
Epoch  48 Batch  640/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9759, Loss: 0.0081
Epoch  48 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9577, Loss: 0.0052
Epoch  48 Batch  680/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9705, Loss: 0.0111
Epoch  48 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9787, Loss: 0.0090
Epoch  48 Batch  720/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9787, Loss: 0.0091
Epoch  48 Batch  740/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9819, Loss: 0.0106
Epoch  48 Batch  760/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9769, Loss: 0.0105
Epoch  48 Batch  780/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9751, Loss: 0.0163
Epoch  48 Batch  800/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9631, Loss: 0.0105
Epoch  48 Batch  820/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9741, Loss: 0.0096
Epoch  48 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9776, Loss: 0.0113
Epoch  48 Batch  860/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9592, Loss: 0.0106
Epoch  48 Batch  880/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9730, Loss: 0.0155
Epoch  48 Batch  900/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9815, Loss: 0.0114
Epoch  48 Batch  920/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9688, Loss: 0.0076
Epoch  48 Batch  940/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9826, Loss: 0.0078
Epoch  48 Batch  960/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9698, Loss: 0.0092
Epoch  48 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9659, Loss: 0.0118
Epoch  48 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9812, Loss: 0.0095
Epoch  48 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9712, Loss: 0.0061
Epoch  48 Batch 1040/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9762, Loss: 0.0101
Epoch  48 Batch 1060/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9830, Loss: 0.0077
Epoch  49 Batch   20/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9730, Loss: 0.0076
Epoch  49 Batch   40/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9663, Loss: 0.0074
Epoch  49 Batch   60/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9602, Loss: 0.0092
Epoch  49 Batch   80/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9677, Loss: 0.0101
Epoch  49 Batch  100/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9670, Loss: 0.0092
Epoch  49 Batch  120/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9755, Loss: 0.0080
Epoch  49 Batch  140/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9819, Loss: 0.0111
Epoch  49 Batch  160/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9822, Loss: 0.0075
Epoch  49 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9670, Loss: 0.0060
Epoch  49 Batch  200/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9830, Loss: 0.0074
Epoch  49 Batch  220/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9691, Loss: 0.0102
Epoch  49 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9872, Loss: 0.0073
Epoch  49 Batch  260/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9755, Loss: 0.0088
Epoch  49 Batch  280/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9737, Loss: 0.0126
Epoch  49 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9716, Loss: 0.0129
Epoch  49 Batch  320/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9776, Loss: 0.0168
Epoch  49 Batch  340/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9659, Loss: 0.0087
Epoch  49 Batch  360/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9741, Loss: 0.0079
Epoch  49 Batch  380/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9787, Loss: 0.0077
Epoch  49 Batch  400/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9830, Loss: 0.0105
Epoch  49 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9759, Loss: 0.0092
Epoch  49 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9553, Loss: 0.0093
Epoch  49 Batch  460/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9680, Loss: 0.0100
Epoch  49 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9645, Loss: 0.0067
Epoch  49 Batch  500/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9748, Loss: 0.0063
Epoch  49 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9751, Loss: 0.0066
Epoch  49 Batch  540/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9723, Loss: 0.0068
Epoch  49 Batch  560/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9712, Loss: 0.0077
Epoch  49 Batch  580/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9631, Loss: 0.0092
Epoch  49 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9798, Loss: 0.0105
Epoch  49 Batch  620/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9783, Loss: 0.0102
Epoch  49 Batch  640/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9670, Loss: 0.0066
Epoch  49 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9631, Loss: 0.0050
Epoch  49 Batch  680/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9616, Loss: 0.0107
Epoch  49 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9695, Loss: 0.0088
Epoch  49 Batch  720/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9776, Loss: 0.0107
Epoch  49 Batch  740/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9766, Loss: 0.0099
Epoch  49 Batch  760/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9812, Loss: 0.0087
Epoch  49 Batch  780/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9730, Loss: 0.0124
Epoch  49 Batch  800/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9677, Loss: 0.0095
Epoch  49 Batch  820/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9698, Loss: 0.0108
Epoch  49 Batch  840/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9783, Loss: 0.0112
Epoch  49 Batch  860/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9666, Loss: 0.0101
Epoch  49 Batch  880/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9727, Loss: 0.0158
Epoch  49 Batch  900/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9698, Loss: 0.0101
Epoch  49 Batch  920/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9666, Loss: 0.0072
Epoch  49 Batch  940/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9819, Loss: 0.0065
Epoch  49 Batch  960/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9730, Loss: 0.0086
Epoch  49 Batch  980/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9673, Loss: 0.0124
Epoch  49 Batch 1000/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9787, Loss: 0.0087
Epoch  49 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9719, Loss: 0.0066
Epoch  49 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9688, Loss: 0.0099
Epoch  49 Batch 1060/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9773, Loss: 0.0064
Epoch  50 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9787, Loss: 0.0074
Epoch  50 Batch   40/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9773, Loss: 0.0078
Epoch  50 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9595, Loss: 0.0085
Epoch  50 Batch   80/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9691, Loss: 0.0112
Epoch  50 Batch  100/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9719, Loss: 0.0100
Epoch  50 Batch  120/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9759, Loss: 0.0083
Epoch  50 Batch  140/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9837, Loss: 0.0112
Epoch  50 Batch  160/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9815, Loss: 0.0089
Epoch  50 Batch  180/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9730, Loss: 0.0079
Epoch  50 Batch  200/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9830, Loss: 0.0086
Epoch  50 Batch  220/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9691, Loss: 0.0095
Epoch  50 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9925, Loss: 0.0066
Epoch  50 Batch  260/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9776, Loss: 0.0081
Epoch  50 Batch  280/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9755, Loss: 0.0131
Epoch  50 Batch  300/1077 - Train Accuracy: 0.9675, Validation Accuracy: 0.9663, Loss: 0.0111
Epoch  50 Batch  320/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9808, Loss: 0.0143
Epoch  50 Batch  340/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9787, Loss: 0.0063
Epoch  50 Batch  360/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9709, Loss: 0.0080
Epoch  50 Batch  380/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9755, Loss: 0.0066
Epoch  50 Batch  400/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9879, Loss: 0.0107
Epoch  50 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9776, Loss: 0.0096
Epoch  50 Batch  440/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9577, Loss: 0.0099
Epoch  50 Batch  460/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9741, Loss: 0.0096
Epoch  50 Batch  480/1077 - Train Accuracy: 0.9815, Validation Accuracy: 0.9688, Loss: 0.0075
Epoch  50 Batch  500/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9766, Loss: 0.0066
Epoch  50 Batch  520/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9730, Loss: 0.0064
Epoch  50 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9727, Loss: 0.0080
Epoch  50 Batch  560/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9794, Loss: 0.0070
Epoch  50 Batch  580/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9670, Loss: 0.0105
Epoch  50 Batch  600/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9719, Loss: 0.0088
Epoch  50 Batch  620/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9833, Loss: 0.0125
Epoch  50 Batch  640/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9751, Loss: 0.0064
Epoch  50 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9712, Loss: 0.0054
Epoch  50 Batch  680/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9748, Loss: 0.0094
Epoch  50 Batch  700/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9751, Loss: 0.0098
Epoch  50 Batch  720/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9790, Loss: 0.0102
Epoch  50 Batch  740/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9808, Loss: 0.0098
Epoch  50 Batch  760/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9815, Loss: 0.0096
Epoch  50 Batch  780/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9712, Loss: 0.0129
Epoch  50 Batch  800/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9837, Loss: 0.0088
Epoch  50 Batch  820/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9730, Loss: 0.0088
Epoch  50 Batch  840/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9776, Loss: 0.0120
Epoch  50 Batch  860/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9595, Loss: 0.0101
Epoch  50 Batch  880/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9634, Loss: 0.0171
Epoch  50 Batch  900/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9695, Loss: 0.0097
Epoch  50 Batch  920/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9737, Loss: 0.0071
Epoch  50 Batch  940/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9751, Loss: 0.0072
Epoch  50 Batch  960/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9702, Loss: 0.0085
Epoch  50 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9670, Loss: 0.0107
Epoch  50 Batch 1000/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9858, Loss: 0.0087
Epoch  50 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9723, Loss: 0.0057
Epoch  50 Batch 1040/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9716, Loss: 0.0098
Epoch  50 Batch 1060/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9776, Loss: 0.0083
Epoch  51 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9790, Loss: 0.0078
Epoch  51 Batch   40/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9709, Loss: 0.0099
Epoch  51 Batch   60/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9542, Loss: 0.0077
Epoch  51 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9741, Loss: 0.0094
Epoch  51 Batch  100/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9712, Loss: 0.0087
Epoch  51 Batch  120/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9826, Loss: 0.0085
Epoch  51 Batch  140/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9840, Loss: 0.0092
Epoch  51 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9815, Loss: 0.0060
Epoch  51 Batch  180/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9794, Loss: 0.0059
Epoch  51 Batch  200/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9826, Loss: 0.0071
Epoch  51 Batch  220/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9787, Loss: 0.0116
Epoch  51 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9925, Loss: 0.0079
Epoch  51 Batch  260/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9723, Loss: 0.0084
Epoch  51 Batch  280/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9680, Loss: 0.0124
Epoch  51 Batch  300/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9734, Loss: 0.0114
Epoch  51 Batch  320/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9634, Loss: 0.0157
Epoch  51 Batch  340/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9744, Loss: 0.0073
Epoch  51 Batch  360/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9737, Loss: 0.0072
Epoch  51 Batch  380/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9808, Loss: 0.0060
Epoch  51 Batch  400/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9837, Loss: 0.0082
Epoch  51 Batch  420/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9812, Loss: 0.0079
Epoch  51 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9663, Loss: 0.0078
Epoch  51 Batch  460/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9680, Loss: 0.0101
Epoch  51 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9751, Loss: 0.0062
Epoch  51 Batch  500/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9815, Loss: 0.0078
Epoch  51 Batch  520/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9801, Loss: 0.0068
Epoch  51 Batch  540/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9698, Loss: 0.0067
Epoch  51 Batch  560/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9798, Loss: 0.0067
Epoch  51 Batch  580/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9698, Loss: 0.0087
Epoch  51 Batch  600/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9798, Loss: 0.0106
Epoch  51 Batch  620/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9801, Loss: 0.0110
Epoch  51 Batch  640/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9744, Loss: 0.0050
Epoch  51 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9659, Loss: 0.0035
Epoch  51 Batch  680/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9702, Loss: 0.0093
Epoch  51 Batch  700/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9773, Loss: 0.0112
Epoch  51 Batch  720/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9822, Loss: 0.0073
Epoch  51 Batch  740/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9759, Loss: 0.0089
Epoch  51 Batch  760/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9812, Loss: 0.0119
Epoch  51 Batch  780/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9730, Loss: 0.0136
Epoch  51 Batch  800/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9634, Loss: 0.0082
Epoch  51 Batch  820/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9819, Loss: 0.0073
Epoch  51 Batch  840/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9798, Loss: 0.0092
Epoch  51 Batch  860/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9631, Loss: 0.0084
Epoch  51 Batch  880/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9762, Loss: 0.0165
Epoch  51 Batch  900/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9730, Loss: 0.0096
Epoch  51 Batch  920/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9766, Loss: 0.0067
Epoch  51 Batch  940/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9705, Loss: 0.0055
Epoch  51 Batch  960/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9680, Loss: 0.0089
Epoch  51 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9702, Loss: 0.0103
Epoch  51 Batch 1000/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9769, Loss: 0.0090
Epoch  51 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9723, Loss: 0.0058
Epoch  51 Batch 1040/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9727, Loss: 0.0102
Epoch  51 Batch 1060/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9723, Loss: 0.0062
Epoch  52 Batch   20/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9783, Loss: 0.0076
Epoch  52 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9691, Loss: 0.0065
Epoch  52 Batch   60/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9542, Loss: 0.0082
Epoch  52 Batch   80/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9790, Loss: 0.0105
Epoch  52 Batch  100/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9698, Loss: 0.0094
Epoch  52 Batch  120/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9798, Loss: 0.0089
Epoch  52 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9783, Loss: 0.0099
Epoch  52 Batch  160/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9815, Loss: 0.0087
Epoch  52 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9759, Loss: 0.0064
Epoch  52 Batch  200/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9819, Loss: 0.0066
Epoch  52 Batch  220/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9680, Loss: 0.0091
Epoch  52 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9744, Loss: 0.0068
Epoch  52 Batch  260/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9755, Loss: 0.0073
Epoch  52 Batch  280/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9666, Loss: 0.0115
Epoch  52 Batch  300/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9666, Loss: 0.0101
Epoch  52 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9755, Loss: 0.0135
Epoch  52 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9830, Loss: 0.0068
Epoch  52 Batch  360/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9737, Loss: 0.0070
Epoch  52 Batch  380/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9762, Loss: 0.0077
Epoch  52 Batch  400/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9819, Loss: 0.0085
Epoch  52 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9702, Loss: 0.0092
Epoch  52 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9663, Loss: 0.0078
Epoch  52 Batch  460/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9716, Loss: 0.0106
Epoch  52 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9712, Loss: 0.0072
Epoch  52 Batch  500/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9787, Loss: 0.0059
Epoch  52 Batch  520/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9755, Loss: 0.0074
Epoch  52 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9727, Loss: 0.0059
Epoch  52 Batch  560/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9822, Loss: 0.0070
Epoch  52 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9769, Loss: 0.0083
Epoch  52 Batch  600/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9801, Loss: 0.0088
Epoch  52 Batch  620/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9787, Loss: 0.0095
Epoch  52 Batch  640/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9744, Loss: 0.0080
Epoch  52 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9641, Loss: 0.0040
Epoch  52 Batch  680/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9716, Loss: 0.0084
Epoch  52 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9688, Loss: 0.0092
Epoch  52 Batch  720/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9833, Loss: 0.0085
Epoch  52 Batch  740/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9815, Loss: 0.0086
Epoch  52 Batch  760/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9826, Loss: 0.0092
Epoch  52 Batch  780/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9780, Loss: 0.0115
Epoch  52 Batch  800/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9744, Loss: 0.0075
Epoch  52 Batch  820/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9741, Loss: 0.0065
Epoch  52 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9712, Loss: 0.0087
Epoch  52 Batch  860/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9666, Loss: 0.0076
Epoch  52 Batch  880/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9709, Loss: 0.0151
Epoch  52 Batch  900/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9801, Loss: 0.0102
Epoch  52 Batch  920/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9741, Loss: 0.0070
Epoch  52 Batch  940/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9702, Loss: 0.0060
Epoch  52 Batch  960/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9755, Loss: 0.0084
Epoch  52 Batch  980/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9748, Loss: 0.0103
Epoch  52 Batch 1000/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9805, Loss: 0.0101
Epoch  52 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9680, Loss: 0.0053
Epoch  52 Batch 1040/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9712, Loss: 0.0096
Epoch  52 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9876, Loss: 0.0064
Epoch  53 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9837, Loss: 0.0072
Epoch  53 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9769, Loss: 0.0074
Epoch  53 Batch   60/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9396, Loss: 0.0079
Epoch  53 Batch   80/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9695, Loss: 0.0094
Epoch  53 Batch  100/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9723, Loss: 0.0090
Epoch  53 Batch  120/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9798, Loss: 0.0075
Epoch  53 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9798, Loss: 0.0101
Epoch  53 Batch  160/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9769, Loss: 0.0058
Epoch  53 Batch  180/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9709, Loss: 0.0061
Epoch  53 Batch  200/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9854, Loss: 0.0088
Epoch  53 Batch  220/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9691, Loss: 0.0089
Epoch  53 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9808, Loss: 0.0073
Epoch  53 Batch  260/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9780, Loss: 0.0071
Epoch  53 Batch  280/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9677, Loss: 0.0112
Epoch  53 Batch  300/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9766, Loss: 0.0094
Epoch  53 Batch  320/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9755, Loss: 0.0139
Epoch  53 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9723, Loss: 0.0060
Epoch  53 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9595, Loss: 0.0065
Epoch  53 Batch  380/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9759, Loss: 0.0079
Epoch  53 Batch  400/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9833, Loss: 0.0085
Epoch  53 Batch  420/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9712, Loss: 0.0079
Epoch  53 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9691, Loss: 0.0100
Epoch  53 Batch  460/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9712, Loss: 0.0088
Epoch  53 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9709, Loss: 0.0078
Epoch  53 Batch  500/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9716, Loss: 0.0064
Epoch  53 Batch  520/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9744, Loss: 0.0062
Epoch  53 Batch  540/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9620, Loss: 0.0061
Epoch  53 Batch  560/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9794, Loss: 0.0069
Epoch  53 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9790, Loss: 0.0085
Epoch  53 Batch  600/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9766, Loss: 0.0099
Epoch  53 Batch  620/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9783, Loss: 0.0089
Epoch  53 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9744, Loss: 0.0058
Epoch  53 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9659, Loss: 0.0038
Epoch  53 Batch  680/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9780, Loss: 0.0083
Epoch  53 Batch  700/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9684, Loss: 0.0089
Epoch  53 Batch  720/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9620, Loss: 0.0109
Epoch  53 Batch  740/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9734, Loss: 0.0089
Epoch  53 Batch  760/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9812, Loss: 0.0084
Epoch  53 Batch  780/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9851, Loss: 0.0107
Epoch  53 Batch  800/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9695, Loss: 0.0068
Epoch  53 Batch  820/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9854, Loss: 0.0079
Epoch  53 Batch  840/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9716, Loss: 0.0088
Epoch  53 Batch  860/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9631, Loss: 0.0087
Epoch  53 Batch  880/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9822, Loss: 0.0167
Epoch  53 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9762, Loss: 0.0094
Epoch  53 Batch  920/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9769, Loss: 0.0072
Epoch  53 Batch  940/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9773, Loss: 0.0072
Epoch  53 Batch  960/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9783, Loss: 0.0078
Epoch  53 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9798, Loss: 0.0098
Epoch  53 Batch 1000/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9805, Loss: 0.0078
Epoch  53 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9780, Loss: 0.0053
Epoch  53 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9741, Loss: 0.0083
Epoch  53 Batch 1060/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9755, Loss: 0.0065
Epoch  54 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9826, Loss: 0.0071
Epoch  54 Batch   40/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9783, Loss: 0.0069
Epoch  54 Batch   60/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9627, Loss: 0.0075
Epoch  54 Batch   80/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9695, Loss: 0.0092
Epoch  54 Batch  100/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9716, Loss: 0.0082
Epoch  54 Batch  120/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9737, Loss: 0.0082
Epoch  54 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9890, Loss: 0.0088
Epoch  54 Batch  160/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9815, Loss: 0.0062
Epoch  54 Batch  180/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9723, Loss: 0.0056
Epoch  54 Batch  200/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9854, Loss: 0.0061
Epoch  54 Batch  220/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9691, Loss: 0.0112
Epoch  54 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9812, Loss: 0.0060
Epoch  54 Batch  260/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9766, Loss: 0.0077
Epoch  54 Batch  280/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9755, Loss: 0.0107
Epoch  54 Batch  300/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9808, Loss: 0.0098
Epoch  54 Batch  320/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9730, Loss: 0.0121
Epoch  54 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9876, Loss: 0.0068
Epoch  54 Batch  360/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9744, Loss: 0.0066
Epoch  54 Batch  380/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9812, Loss: 0.0047
Epoch  54 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9787, Loss: 0.0075
Epoch  54 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9812, Loss: 0.0079
Epoch  54 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9741, Loss: 0.0081
Epoch  54 Batch  460/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9716, Loss: 0.0089
Epoch  54 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9709, Loss: 0.0061
Epoch  54 Batch  500/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9837, Loss: 0.0066
Epoch  54 Batch  520/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9794, Loss: 0.0066
Epoch  54 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9709, Loss: 0.0064
Epoch  54 Batch  560/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9854, Loss: 0.0071
Epoch  54 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9762, Loss: 0.0086
Epoch  54 Batch  600/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9819, Loss: 0.0095
Epoch  54 Batch  620/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9833, Loss: 0.0086
Epoch  54 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9759, Loss: 0.0053
Epoch  54 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9716, Loss: 0.0046
Epoch  54 Batch  680/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9581, Loss: 0.0079
Epoch  54 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9794, Loss: 0.0083
Epoch  54 Batch  720/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9830, Loss: 0.0080
Epoch  54 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9812, Loss: 0.0062
Epoch  54 Batch  760/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9837, Loss: 0.0100
Epoch  54 Batch  780/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9826, Loss: 0.0110
Epoch  54 Batch  800/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9691, Loss: 0.0067
Epoch  54 Batch  820/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9773, Loss: 0.0067
Epoch  54 Batch  840/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9780, Loss: 0.0098
Epoch  54 Batch  860/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9798, Loss: 0.0088
Epoch  54 Batch  880/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9730, Loss: 0.0136
Epoch  54 Batch  900/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9872, Loss: 0.0093
Epoch  54 Batch  920/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9769, Loss: 0.0074
Epoch  54 Batch  940/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9844, Loss: 0.0061
Epoch  54 Batch  960/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9645, Loss: 0.0082
Epoch  54 Batch  980/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9684, Loss: 0.0090
Epoch  54 Batch 1000/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9762, Loss: 0.0097
Epoch  54 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9751, Loss: 0.0061
Epoch  54 Batch 1040/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9680, Loss: 0.0099
Epoch  54 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9705, Loss: 0.0049
Epoch  55 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9819, Loss: 0.0079
Epoch  55 Batch   40/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9751, Loss: 0.0060
Epoch  55 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9691, Loss: 0.0081
Epoch  55 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9790, Loss: 0.0094
Epoch  55 Batch  100/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9723, Loss: 0.0087
Epoch  55 Batch  120/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9759, Loss: 0.0073
Epoch  55 Batch  140/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9886, Loss: 0.0077
Epoch  55 Batch  160/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9794, Loss: 0.0062
Epoch  55 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9776, Loss: 0.0065
Epoch  55 Batch  200/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9776, Loss: 0.0077
Epoch  55 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9783, Loss: 0.0088
Epoch  55 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0077
Epoch  55 Batch  260/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9773, Loss: 0.0070
Epoch  55 Batch  280/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9751, Loss: 0.0102
Epoch  55 Batch  300/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9751, Loss: 0.0089
Epoch  55 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9741, Loss: 0.0125
Epoch  55 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9698, Loss: 0.0068
Epoch  55 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9751, Loss: 0.0070
Epoch  55 Batch  380/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0049
Epoch  55 Batch  400/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9847, Loss: 0.0094
Epoch  55 Batch  420/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9730, Loss: 0.0100
Epoch  55 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9698, Loss: 0.0081
Epoch  55 Batch  460/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9666, Loss: 0.0098
Epoch  55 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9705, Loss: 0.0085
Epoch  55 Batch  500/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9751, Loss: 0.0088
Epoch  55 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9755, Loss: 0.0072
Epoch  55 Batch  540/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9822, Loss: 0.0072
Epoch  55 Batch  560/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9858, Loss: 0.0068
Epoch  55 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9769, Loss: 0.0090
Epoch  55 Batch  600/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9862, Loss: 0.0092
Epoch  55 Batch  620/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9847, Loss: 0.0095
Epoch  55 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9744, Loss: 0.0056
Epoch  55 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9716, Loss: 0.0038
Epoch  55 Batch  680/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9783, Loss: 0.0083
Epoch  55 Batch  700/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9656, Loss: 0.0115
Epoch  55 Batch  720/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9840, Loss: 0.0079
Epoch  55 Batch  740/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9666, Loss: 0.0071
Epoch  55 Batch  760/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9812, Loss: 0.0111
Epoch  55 Batch  780/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9826, Loss: 0.0126
Epoch  55 Batch  800/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9624, Loss: 0.0064
Epoch  55 Batch  820/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9812, Loss: 0.0076
Epoch  55 Batch  840/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9744, Loss: 0.0098
Epoch  55 Batch  860/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9805, Loss: 0.0064
Epoch  55 Batch  880/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9645, Loss: 0.0134
Epoch  55 Batch  900/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9762, Loss: 0.0100
Epoch  55 Batch  920/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9776, Loss: 0.0067
Epoch  55 Batch  940/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9783, Loss: 0.0048
Epoch  55 Batch  960/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9645, Loss: 0.0083
Epoch  55 Batch  980/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9780, Loss: 0.0093
Epoch  55 Batch 1000/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9776, Loss: 0.0089
Epoch  55 Batch 1020/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9780, Loss: 0.0063
Epoch  55 Batch 1040/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9695, Loss: 0.0103
Epoch  55 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9808, Loss: 0.0067
Epoch  56 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9790, Loss: 0.0067
Epoch  56 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9769, Loss: 0.0056
Epoch  56 Batch   60/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9698, Loss: 0.0096
Epoch  56 Batch   80/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9698, Loss: 0.0088
Epoch  56 Batch  100/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9755, Loss: 0.0072
Epoch  56 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9762, Loss: 0.0064
Epoch  56 Batch  140/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9869, Loss: 0.0074
Epoch  56 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9688, Loss: 0.0050
Epoch  56 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9822, Loss: 0.0054
Epoch  56 Batch  200/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9865, Loss: 0.0072
Epoch  56 Batch  220/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9741, Loss: 0.0094
Epoch  56 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9812, Loss: 0.0056
Epoch  56 Batch  260/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9787, Loss: 0.0055
Epoch  56 Batch  280/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9698, Loss: 0.0085
Epoch  56 Batch  300/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9712, Loss: 0.0091
Epoch  56 Batch  320/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9673, Loss: 0.0149
Epoch  56 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9822, Loss: 0.0058
Epoch  56 Batch  360/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9755, Loss: 0.0062
Epoch  56 Batch  380/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9826, Loss: 0.0057
Epoch  56 Batch  400/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9830, Loss: 0.0078
Epoch  56 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9773, Loss: 0.0071
Epoch  56 Batch  440/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9691, Loss: 0.0078
Epoch  56 Batch  460/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9695, Loss: 0.0121
Epoch  56 Batch  480/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9670, Loss: 0.0076
Epoch  56 Batch  500/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9805, Loss: 0.0093
Epoch  56 Batch  520/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9716, Loss: 0.0065
Epoch  56 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9805, Loss: 0.0055
Epoch  56 Batch  560/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9844, Loss: 0.0063
Epoch  56 Batch  580/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9766, Loss: 0.0079
Epoch  56 Batch  600/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9762, Loss: 0.0077
Epoch  56 Batch  620/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9851, Loss: 0.0092
Epoch  56 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9744, Loss: 0.0069
Epoch  56 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9716, Loss: 0.0049
Epoch  56 Batch  680/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9794, Loss: 0.0086
Epoch  56 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9723, Loss: 0.0084
Epoch  56 Batch  720/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9780, Loss: 0.0092
Epoch  56 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9783, Loss: 0.0070
Epoch  56 Batch  760/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9837, Loss: 0.0075
Epoch  56 Batch  780/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9872, Loss: 0.0094
Epoch  56 Batch  800/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9702, Loss: 0.0057
Epoch  56 Batch  820/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9826, Loss: 0.0060
Epoch  56 Batch  840/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9755, Loss: 0.0092
Epoch  56 Batch  860/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9698, Loss: 0.0067
Epoch  56 Batch  880/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9670, Loss: 0.0129
Epoch  56 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9794, Loss: 0.0100
Epoch  56 Batch  920/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9776, Loss: 0.0070
Epoch  56 Batch  940/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9783, Loss: 0.0047
Epoch  56 Batch  960/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9879, Loss: 0.0081
Epoch  56 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9854, Loss: 0.0086
Epoch  56 Batch 1000/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9815, Loss: 0.0085
Epoch  56 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9755, Loss: 0.0049
Epoch  56 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9826, Loss: 0.0095
Epoch  56 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9773, Loss: 0.0051
Epoch  57 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9794, Loss: 0.0057
Epoch  57 Batch   40/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9819, Loss: 0.0065
Epoch  57 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9620, Loss: 0.0076
Epoch  57 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9744, Loss: 0.0075
Epoch  57 Batch  100/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9734, Loss: 0.0078
Epoch  57 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9709, Loss: 0.0058
Epoch  57 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9865, Loss: 0.0092
Epoch  57 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0042
Epoch  57 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9755, Loss: 0.0051
Epoch  57 Batch  200/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9801, Loss: 0.0061
Epoch  57 Batch  220/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9780, Loss: 0.0081
Epoch  57 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9801, Loss: 0.0057
Epoch  57 Batch  260/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9719, Loss: 0.0064
Epoch  57 Batch  280/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9695, Loss: 0.0090
Epoch  57 Batch  300/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9837, Loss: 0.0077
Epoch  57 Batch  320/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9751, Loss: 0.0109
Epoch  57 Batch  340/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9815, Loss: 0.0081
Epoch  57 Batch  360/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9737, Loss: 0.0070
Epoch  57 Batch  380/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9805, Loss: 0.0052
Epoch  57 Batch  400/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9830, Loss: 0.0086
Epoch  57 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9812, Loss: 0.0067
Epoch  57 Batch  440/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9659, Loss: 0.0077
Epoch  57 Batch  460/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9680, Loss: 0.0093
Epoch  57 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9737, Loss: 0.0058
Epoch  57 Batch  500/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9833, Loss: 0.0082
Epoch  57 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9776, Loss: 0.0057
Epoch  57 Batch  540/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9727, Loss: 0.0053
Epoch  57 Batch  560/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9844, Loss: 0.0070
Epoch  57 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9780, Loss: 0.0069
Epoch  57 Batch  600/1077 - Train Accuracy: 0.9978, Validation Accuracy: 0.9837, Loss: 0.0075
Epoch  57 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0081
Epoch  57 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9790, Loss: 0.0049
Epoch  57 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9723, Loss: 0.0052
Epoch  57 Batch  680/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9815, Loss: 0.0073
Epoch  57 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9723, Loss: 0.0078
Epoch  57 Batch  720/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9851, Loss: 0.0069
Epoch  57 Batch  740/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9812, Loss: 0.0068
Epoch  57 Batch  760/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9812, Loss: 0.0071
Epoch  57 Batch  780/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9769, Loss: 0.0087
Epoch  57 Batch  800/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9702, Loss: 0.0057
Epoch  57 Batch  820/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9844, Loss: 0.0076
Epoch  57 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9854, Loss: 0.0081
Epoch  57 Batch  860/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9904, Loss: 0.0061
Epoch  57 Batch  880/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9730, Loss: 0.0135
Epoch  57 Batch  900/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9776, Loss: 0.0083
Epoch  57 Batch  920/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9727, Loss: 0.0067
Epoch  57 Batch  940/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9776, Loss: 0.0045
Epoch  57 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9641, Loss: 0.0076
Epoch  57 Batch  980/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9801, Loss: 0.0085
Epoch  57 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9691, Loss: 0.0085
Epoch  57 Batch 1020/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9780, Loss: 0.0067
Epoch  57 Batch 1040/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9776, Loss: 0.0096
Epoch  57 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9808, Loss: 0.0082
Epoch  58 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9854, Loss: 0.0064
Epoch  58 Batch   40/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9805, Loss: 0.0074
Epoch  58 Batch   60/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9609, Loss: 0.0082
Epoch  58 Batch   80/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9737, Loss: 0.0085
Epoch  58 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9787, Loss: 0.0081
Epoch  58 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9734, Loss: 0.0062
Epoch  58 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9822, Loss: 0.0073
Epoch  58 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0043
Epoch  58 Batch  180/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9819, Loss: 0.0058
Epoch  58 Batch  200/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9872, Loss: 0.0065
Epoch  58 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9759, Loss: 0.0086
Epoch  58 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9815, Loss: 0.0059
Epoch  58 Batch  260/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9830, Loss: 0.0059
Epoch  58 Batch  280/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9734, Loss: 0.0103
Epoch  58 Batch  300/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9790, Loss: 0.0081
Epoch  58 Batch  320/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9602, Loss: 0.0119
Epoch  58 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9748, Loss: 0.0061
Epoch  58 Batch  360/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9798, Loss: 0.0069
Epoch  58 Batch  380/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9812, Loss: 0.0050
Epoch  58 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9833, Loss: 0.0074
Epoch  58 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9808, Loss: 0.0064
Epoch  58 Batch  440/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9727, Loss: 0.0087
Epoch  58 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9645, Loss: 0.0078
Epoch  58 Batch  480/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9712, Loss: 0.0081
Epoch  58 Batch  500/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9755, Loss: 0.0050
Epoch  58 Batch  520/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9684, Loss: 0.0062
Epoch  58 Batch  540/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9794, Loss: 0.0058
Epoch  58 Batch  560/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9776, Loss: 0.0076
Epoch  58 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9833, Loss: 0.0085
Epoch  58 Batch  600/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9748, Loss: 0.0080
Epoch  58 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9808, Loss: 0.0080
Epoch  58 Batch  640/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9826, Loss: 0.0059
Epoch  58 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9776, Loss: 0.0043
Epoch  58 Batch  680/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9808, Loss: 0.0069
Epoch  58 Batch  700/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9766, Loss: 0.0079
Epoch  58 Batch  720/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9808, Loss: 0.0072
Epoch  58 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9741, Loss: 0.0055
Epoch  58 Batch  760/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9808, Loss: 0.0076
Epoch  58 Batch  780/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9837, Loss: 0.0086
Epoch  58 Batch  800/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9645, Loss: 0.0054
Epoch  58 Batch  820/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9833, Loss: 0.0078
Epoch  58 Batch  840/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9759, Loss: 0.0140
Epoch  58 Batch  860/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9822, Loss: 0.0062
Epoch  58 Batch  880/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9805, Loss: 0.0118
Epoch  58 Batch  900/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9762, Loss: 0.0097
Epoch  58 Batch  920/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9776, Loss: 0.0073
Epoch  58 Batch  940/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9762, Loss: 0.0057
Epoch  58 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9776, Loss: 0.0080
Epoch  58 Batch  980/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9901, Loss: 0.0081
Epoch  58 Batch 1000/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9712, Loss: 0.0082
Epoch  58 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9798, Loss: 0.0046
Epoch  58 Batch 1040/1077 - Train Accuracy: 0.9811, Validation Accuracy: 0.9776, Loss: 0.0100
Epoch  58 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9822, Loss: 0.0052
Epoch  59 Batch   20/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9766, Loss: 0.0075
Epoch  59 Batch   40/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9705, Loss: 0.0071
Epoch  59 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9627, Loss: 0.0075
Epoch  59 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9766, Loss: 0.0081
Epoch  59 Batch  100/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9719, Loss: 0.0063
Epoch  59 Batch  120/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9695, Loss: 0.0074
Epoch  59 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9890, Loss: 0.0084
Epoch  59 Batch  160/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9751, Loss: 0.0044
Epoch  59 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9851, Loss: 0.0048
Epoch  59 Batch  200/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9805, Loss: 0.0058
Epoch  59 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9858, Loss: 0.0110
Epoch  59 Batch  240/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9812, Loss: 0.0068
Epoch  59 Batch  260/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9833, Loss: 0.0061
Epoch  59 Batch  280/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9748, Loss: 0.0087
Epoch  59 Batch  300/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9737, Loss: 0.0089
Epoch  59 Batch  320/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9695, Loss: 0.0105
Epoch  59 Batch  340/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9822, Loss: 0.0070
Epoch  59 Batch  360/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9805, Loss: 0.0080
Epoch  59 Batch  380/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  59 Batch  400/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9879, Loss: 0.0078
Epoch  59 Batch  420/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9815, Loss: 0.0081
Epoch  59 Batch  440/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9609, Loss: 0.0058
Epoch  59 Batch  460/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9695, Loss: 0.0085
Epoch  59 Batch  480/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9716, Loss: 0.0053
Epoch  59 Batch  500/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9826, Loss: 0.0059
Epoch  59 Batch  520/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9773, Loss: 0.0052
Epoch  59 Batch  540/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9748, Loss: 0.0063
Epoch  59 Batch  560/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9801, Loss: 0.0063
Epoch  59 Batch  580/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9840, Loss: 0.0076
Epoch  59 Batch  600/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9854, Loss: 0.0078
Epoch  59 Batch  620/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9837, Loss: 0.0087
Epoch  59 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9844, Loss: 0.0046
Epoch  59 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9719, Loss: 0.0042
Epoch  59 Batch  680/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9787, Loss: 0.0069
Epoch  59 Batch  700/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9709, Loss: 0.0095
Epoch  59 Batch  720/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9833, Loss: 0.0068
Epoch  59 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9712, Loss: 0.0062
Epoch  59 Batch  760/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9833, Loss: 0.0072
Epoch  59 Batch  780/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9759, Loss: 0.0097
Epoch  59 Batch  800/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9737, Loss: 0.0052
Epoch  59 Batch  820/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9798, Loss: 0.0076
Epoch  59 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9737, Loss: 0.0090
Epoch  59 Batch  860/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9862, Loss: 0.0060
Epoch  59 Batch  880/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9759, Loss: 0.0125
Epoch  59 Batch  900/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9847, Loss: 0.0114
Epoch  59 Batch  920/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9790, Loss: 0.0056
Epoch  59 Batch  940/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9730, Loss: 0.0055
Epoch  59 Batch  960/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9769, Loss: 0.0073
Epoch  59 Batch  980/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9879, Loss: 0.0074
Epoch  59 Batch 1000/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9755, Loss: 0.0076
Epoch  59 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9755, Loss: 0.0043
Epoch  59 Batch 1040/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9780, Loss: 0.0081
Epoch  59 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9826, Loss: 0.0049
Epoch  60 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9808, Loss: 0.0053
Epoch  60 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9815, Loss: 0.0073
Epoch  60 Batch   60/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9826, Loss: 0.0077
Epoch  60 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9673, Loss: 0.0076
Epoch  60 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9776, Loss: 0.0059
Epoch  60 Batch  120/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9702, Loss: 0.0053
Epoch  60 Batch  140/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9876, Loss: 0.0085
Epoch  60 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9815, Loss: 0.0044
Epoch  60 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9872, Loss: 0.0051
Epoch  60 Batch  200/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9869, Loss: 0.0053
Epoch  60 Batch  220/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9840, Loss: 0.0090
Epoch  60 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9822, Loss: 0.0061
Epoch  60 Batch  260/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9769, Loss: 0.0064
Epoch  60 Batch  280/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9709, Loss: 0.0085
Epoch  60 Batch  300/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9808, Loss: 0.0079
Epoch  60 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9663, Loss: 0.0097
Epoch  60 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9790, Loss: 0.0054
Epoch  60 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9805, Loss: 0.0072
Epoch  60 Batch  380/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9798, Loss: 0.0056
Epoch  60 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9847, Loss: 0.0068
Epoch  60 Batch  420/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9826, Loss: 0.0070
Epoch  60 Batch  440/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9737, Loss: 0.0067
Epoch  60 Batch  460/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9680, Loss: 0.0090
Epoch  60 Batch  480/1077 - Train Accuracy: 0.9893, Validation Accuracy: 0.9769, Loss: 0.0084
Epoch  60 Batch  500/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9851, Loss: 0.0065
Epoch  60 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9748, Loss: 0.0054
Epoch  60 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9751, Loss: 0.0064
Epoch  60 Batch  560/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9826, Loss: 0.0057
Epoch  60 Batch  580/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9876, Loss: 0.0079
Epoch  60 Batch  600/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9854, Loss: 0.0077
Epoch  60 Batch  620/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9837, Loss: 0.0090
Epoch  60 Batch  640/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9879, Loss: 0.0082
Epoch  60 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9673, Loss: 0.0043
Epoch  60 Batch  680/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9751, Loss: 0.0065
Epoch  60 Batch  700/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9794, Loss: 0.0080
Epoch  60 Batch  720/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9833, Loss: 0.0080
Epoch  60 Batch  740/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9744, Loss: 0.0052
Epoch  60 Batch  760/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9830, Loss: 0.0060
Epoch  60 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9783, Loss: 0.0088
Epoch  60 Batch  800/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9684, Loss: 0.0069
Epoch  60 Batch  820/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9858, Loss: 0.0079
Epoch  60 Batch  840/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9787, Loss: 0.0110
Epoch  60 Batch  860/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9869, Loss: 0.0065
Epoch  60 Batch  880/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9755, Loss: 0.0136
Epoch  60 Batch  900/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9869, Loss: 0.0107
Epoch  60 Batch  920/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9826, Loss: 0.0078
Epoch  60 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9879, Loss: 0.0052
Epoch  60 Batch  960/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9769, Loss: 0.0072
Epoch  60 Batch  980/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9822, Loss: 0.0078
Epoch  60 Batch 1000/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9680, Loss: 0.0070
Epoch  60 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9780, Loss: 0.0042
Epoch  60 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9812, Loss: 0.0090
Epoch  60 Batch 1060/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9869, Loss: 0.0084
Epoch  61 Batch   20/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9851, Loss: 0.0061
Epoch  61 Batch   40/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9815, Loss: 0.0070
Epoch  61 Batch   60/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9659, Loss: 0.0074
Epoch  61 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9851, Loss: 0.0068
Epoch  61 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9730, Loss: 0.0095
Epoch  61 Batch  120/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9723, Loss: 0.0062
Epoch  61 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9833, Loss: 0.0089
Epoch  61 Batch  160/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9805, Loss: 0.0049
Epoch  61 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9759, Loss: 0.0062
Epoch  61 Batch  200/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9851, Loss: 0.0078
Epoch  61 Batch  220/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9808, Loss: 0.0082
Epoch  61 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9759, Loss: 0.0060
Epoch  61 Batch  260/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9780, Loss: 0.0050
Epoch  61 Batch  280/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9854, Loss: 0.0089
Epoch  61 Batch  300/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9893, Loss: 0.0067
Epoch  61 Batch  320/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9705, Loss: 0.0088
Epoch  61 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9755, Loss: 0.0055
Epoch  61 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9787, Loss: 0.0072
Epoch  61 Batch  380/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9769, Loss: 0.0040
Epoch  61 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9830, Loss: 0.0067
Epoch  61 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9815, Loss: 0.0059
Epoch  61 Batch  440/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9727, Loss: 0.0061
Epoch  61 Batch  460/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9602, Loss: 0.0084
Epoch  61 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9762, Loss: 0.0059
Epoch  61 Batch  500/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9748, Loss: 0.0057
Epoch  61 Batch  520/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9794, Loss: 0.0056
Epoch  61 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9748, Loss: 0.0055
Epoch  61 Batch  560/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9876, Loss: 0.0061
Epoch  61 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9844, Loss: 0.0077
Epoch  61 Batch  600/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9833, Loss: 0.0065
Epoch  61 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0084
Epoch  61 Batch  640/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9883, Loss: 0.0048
Epoch  61 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9712, Loss: 0.0044
Epoch  61 Batch  680/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9819, Loss: 0.0070
Epoch  61 Batch  700/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9663, Loss: 0.0081
Epoch  61 Batch  720/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9893, Loss: 0.0068
Epoch  61 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9744, Loss: 0.0053
Epoch  61 Batch  760/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9801, Loss: 0.0072
Epoch  61 Batch  780/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9684, Loss: 0.0081
Epoch  61 Batch  800/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9801, Loss: 0.0055
Epoch  61 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9787, Loss: 0.0049
Epoch  61 Batch  840/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9780, Loss: 0.0075
Epoch  61 Batch  860/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9773, Loss: 0.0060
Epoch  61 Batch  880/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9762, Loss: 0.0126
Epoch  61 Batch  900/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9748, Loss: 0.0122
Epoch  61 Batch  920/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9819, Loss: 0.0065
Epoch  61 Batch  940/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9730, Loss: 0.0071
Epoch  61 Batch  960/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9805, Loss: 0.0079
Epoch  61 Batch  980/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9847, Loss: 0.0077
Epoch  61 Batch 1000/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9762, Loss: 0.0081
Epoch  61 Batch 1020/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9833, Loss: 0.0051
Epoch  61 Batch 1040/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9805, Loss: 0.0096
Epoch  61 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9723, Loss: 0.0069
Epoch  62 Batch   20/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9773, Loss: 0.0088
Epoch  62 Batch   40/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9776, Loss: 0.0069
Epoch  62 Batch   60/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9709, Loss: 0.0073
Epoch  62 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9847, Loss: 0.0072
Epoch  62 Batch  100/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9787, Loss: 0.0061
Epoch  62 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9773, Loss: 0.0051
Epoch  62 Batch  140/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9869, Loss: 0.0064
Epoch  62 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9833, Loss: 0.0045
Epoch  62 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9833, Loss: 0.0055
Epoch  62 Batch  200/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9833, Loss: 0.0060
Epoch  62 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9769, Loss: 0.0083
Epoch  62 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9776, Loss: 0.0046
Epoch  62 Batch  260/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9798, Loss: 0.0073
Epoch  62 Batch  280/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9709, Loss: 0.0074
Epoch  62 Batch  300/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9901, Loss: 0.0071
Epoch  62 Batch  320/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9695, Loss: 0.0099
Epoch  62 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9854, Loss: 0.0044
Epoch  62 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9790, Loss: 0.0060
Epoch  62 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0044
Epoch  62 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9833, Loss: 0.0065
Epoch  62 Batch  420/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9837, Loss: 0.0059
Epoch  62 Batch  440/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9737, Loss: 0.0056
Epoch  62 Batch  460/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9737, Loss: 0.0085
Epoch  62 Batch  480/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9684, Loss: 0.0087
Epoch  62 Batch  500/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9780, Loss: 0.0066
Epoch  62 Batch  520/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9798, Loss: 0.0054
Epoch  62 Batch  540/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9798, Loss: 0.0053
Epoch  62 Batch  560/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9851, Loss: 0.0054
Epoch  62 Batch  580/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9862, Loss: 0.0080
Epoch  62 Batch  600/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9869, Loss: 0.0063
Epoch  62 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0081
Epoch  62 Batch  640/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9883, Loss: 0.0049
Epoch  62 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9705, Loss: 0.0045
Epoch  62 Batch  680/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9886, Loss: 0.0062
Epoch  62 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9730, Loss: 0.0071
Epoch  62 Batch  720/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9808, Loss: 0.0061
Epoch  62 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9762, Loss: 0.0056
Epoch  62 Batch  760/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9808, Loss: 0.0077
Epoch  62 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9712, Loss: 0.0098
Epoch  62 Batch  800/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9783, Loss: 0.0057
Epoch  62 Batch  820/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9716, Loss: 0.0062
Epoch  62 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9755, Loss: 0.0066
Epoch  62 Batch  860/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9858, Loss: 0.0057
Epoch  62 Batch  880/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9798, Loss: 0.0116
Epoch  62 Batch  900/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9865, Loss: 0.0105
Epoch  62 Batch  920/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9787, Loss: 0.0054
Epoch  62 Batch  940/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9812, Loss: 0.0048
Epoch  62 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9751, Loss: 0.0069
Epoch  62 Batch  980/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9766, Loss: 0.0080
Epoch  62 Batch 1000/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9783, Loss: 0.0070
Epoch  62 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9716, Loss: 0.0036
Epoch  62 Batch 1040/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9773, Loss: 0.0123
Epoch  62 Batch 1060/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9638, Loss: 0.0079
Epoch  63 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9734, Loss: 0.0078
Epoch  63 Batch   40/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9712, Loss: 0.0060
Epoch  63 Batch   60/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9677, Loss: 0.0089
Epoch  63 Batch   80/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9790, Loss: 0.0095
Epoch  63 Batch  100/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9790, Loss: 0.0072
Epoch  63 Batch  120/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9776, Loss: 0.0080
Epoch  63 Batch  140/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9808, Loss: 0.0083
Epoch  63 Batch  160/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9741, Loss: 0.0041
Epoch  63 Batch  180/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9688, Loss: 0.0055
Epoch  63 Batch  200/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9879, Loss: 0.0051
Epoch  63 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9712, Loss: 0.0092
Epoch  63 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9801, Loss: 0.0044
Epoch  63 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9755, Loss: 0.0062
Epoch  63 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9787, Loss: 0.0091
Epoch  63 Batch  300/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9844, Loss: 0.0082
Epoch  63 Batch  320/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9712, Loss: 0.0117
Epoch  63 Batch  340/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9680, Loss: 0.0064
Epoch  63 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9751, Loss: 0.0060
Epoch  63 Batch  380/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9769, Loss: 0.0044
Epoch  63 Batch  400/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9897, Loss: 0.0091
Epoch  63 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9801, Loss: 0.0067
Epoch  63 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9826, Loss: 0.0050
Epoch  63 Batch  460/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9773, Loss: 0.0087
Epoch  63 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9805, Loss: 0.0063
Epoch  63 Batch  500/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9805, Loss: 0.0043
Epoch  63 Batch  520/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9794, Loss: 0.0055
Epoch  63 Batch  540/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9666, Loss: 0.0061
Epoch  63 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9727, Loss: 0.0049
Epoch  63 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9876, Loss: 0.0071
Epoch  63 Batch  600/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9865, Loss: 0.0065
Epoch  63 Batch  620/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9847, Loss: 0.0077
Epoch  63 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9844, Loss: 0.0054
Epoch  63 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9776, Loss: 0.0041
Epoch  63 Batch  680/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9837, Loss: 0.0069
Epoch  63 Batch  700/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9723, Loss: 0.0078
Epoch  63 Batch  720/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9837, Loss: 0.0068
Epoch  63 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9716, Loss: 0.0056
Epoch  63 Batch  760/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9801, Loss: 0.0060
Epoch  63 Batch  780/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9773, Loss: 0.0088
Epoch  63 Batch  800/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9783, Loss: 0.0055
Epoch  63 Batch  820/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9790, Loss: 0.0057
Epoch  63 Batch  840/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9805, Loss: 0.0092
Epoch  63 Batch  860/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9822, Loss: 0.0073
Epoch  63 Batch  880/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9858, Loss: 0.0121
Epoch  63 Batch  900/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9826, Loss: 0.0104
Epoch  63 Batch  920/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9783, Loss: 0.0072
Epoch  63 Batch  940/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9808, Loss: 0.0050
Epoch  63 Batch  960/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9709, Loss: 0.0076
Epoch  63 Batch  980/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9847, Loss: 0.0077
Epoch  63 Batch 1000/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9808, Loss: 0.0062
Epoch  63 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9819, Loss: 0.0042
Epoch  63 Batch 1040/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9794, Loss: 0.0074
Epoch  63 Batch 1060/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9822, Loss: 0.0047
Epoch  64 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9744, Loss: 0.0065
Epoch  64 Batch   40/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9744, Loss: 0.0063
Epoch  64 Batch   60/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9769, Loss: 0.0064
Epoch  64 Batch   80/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9794, Loss: 0.0073
Epoch  64 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9780, Loss: 0.0061
Epoch  64 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9751, Loss: 0.0065
Epoch  64 Batch  140/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9822, Loss: 0.0063
Epoch  64 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9769, Loss: 0.0036
Epoch  64 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9712, Loss: 0.0044
Epoch  64 Batch  200/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9872, Loss: 0.0050
Epoch  64 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9844, Loss: 0.0095
Epoch  64 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9801, Loss: 0.0058
Epoch  64 Batch  260/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9737, Loss: 0.0051
Epoch  64 Batch  280/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9801, Loss: 0.0080
Epoch  64 Batch  300/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9844, Loss: 0.0062
Epoch  64 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9648, Loss: 0.0094
Epoch  64 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9755, Loss: 0.0042
Epoch  64 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9801, Loss: 0.0066
Epoch  64 Batch  380/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9808, Loss: 0.0057
Epoch  64 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9883, Loss: 0.0065
Epoch  64 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9826, Loss: 0.0074
Epoch  64 Batch  440/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9759, Loss: 0.0059
Epoch  64 Batch  460/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9730, Loss: 0.0083
Epoch  64 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9716, Loss: 0.0080
Epoch  64 Batch  500/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9776, Loss: 0.0062
Epoch  64 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9773, Loss: 0.0055
Epoch  64 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9851, Loss: 0.0064
Epoch  64 Batch  560/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9901, Loss: 0.0064
Epoch  64 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9886, Loss: 0.0077
Epoch  64 Batch  600/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9869, Loss: 0.0060
Epoch  64 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0069
Epoch  64 Batch  640/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9805, Loss: 0.0043
Epoch  64 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9766, Loss: 0.0045
Epoch  64 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9815, Loss: 0.0065
Epoch  64 Batch  700/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9741, Loss: 0.0073
Epoch  64 Batch  720/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9783, Loss: 0.0076
Epoch  64 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9876, Loss: 0.0056
Epoch  64 Batch  760/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0062
Epoch  64 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9734, Loss: 0.0080
Epoch  64 Batch  800/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9766, Loss: 0.0078
Epoch  64 Batch  820/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9798, Loss: 0.0049
Epoch  64 Batch  840/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9790, Loss: 0.0075
Epoch  64 Batch  860/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9897, Loss: 0.0072
Epoch  64 Batch  880/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9751, Loss: 0.0104
Epoch  64 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9822, Loss: 0.0098
Epoch  64 Batch  920/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9776, Loss: 0.0064
Epoch  64 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0048
Epoch  64 Batch  960/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9695, Loss: 0.0075
Epoch  64 Batch  980/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9780, Loss: 0.0078
Epoch  64 Batch 1000/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9673, Loss: 0.0070
Epoch  64 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9790, Loss: 0.0041
Epoch  64 Batch 1040/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9830, Loss: 0.0087
Epoch  64 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9830, Loss: 0.0057
Epoch  65 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9840, Loss: 0.0062
Epoch  65 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9822, Loss: 0.0056
Epoch  65 Batch   60/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9773, Loss: 0.0075
Epoch  65 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9751, Loss: 0.0073
Epoch  65 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9776, Loss: 0.0065
Epoch  65 Batch  120/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9773, Loss: 0.0061
Epoch  65 Batch  140/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9822, Loss: 0.0069
Epoch  65 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0044
Epoch  65 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9773, Loss: 0.0046
Epoch  65 Batch  200/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9872, Loss: 0.0049
Epoch  65 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9833, Loss: 0.0092
Epoch  65 Batch  240/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9872, Loss: 0.0062
Epoch  65 Batch  260/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9805, Loss: 0.0058
Epoch  65 Batch  280/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9805, Loss: 0.0077
Epoch  65 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9872, Loss: 0.0066
Epoch  65 Batch  320/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9663, Loss: 0.0112
Epoch  65 Batch  340/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9695, Loss: 0.0068
Epoch  65 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9801, Loss: 0.0065
Epoch  65 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9830, Loss: 0.0041
Epoch  65 Batch  400/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9883, Loss: 0.0081
Epoch  65 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9815, Loss: 0.0061
Epoch  65 Batch  440/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9620, Loss: 0.0057
Epoch  65 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9702, Loss: 0.0082
Epoch  65 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9780, Loss: 0.0054
Epoch  65 Batch  500/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9808, Loss: 0.0050
Epoch  65 Batch  520/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9783, Loss: 0.0050
Epoch  65 Batch  540/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9830, Loss: 0.0056
Epoch  65 Batch  560/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9851, Loss: 0.0055
Epoch  65 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9837, Loss: 0.0064
Epoch  65 Batch  600/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9837, Loss: 0.0064
Epoch  65 Batch  620/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9822, Loss: 0.0076
Epoch  65 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9805, Loss: 0.0051
Epoch  65 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9822, Loss: 0.0042
Epoch  65 Batch  680/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9833, Loss: 0.0073
Epoch  65 Batch  700/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9680, Loss: 0.0072
Epoch  65 Batch  720/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9904, Loss: 0.0062
Epoch  65 Batch  740/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9737, Loss: 0.0053
Epoch  65 Batch  760/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9826, Loss: 0.0069
Epoch  65 Batch  780/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0079
Epoch  65 Batch  800/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9730, Loss: 0.0054
Epoch  65 Batch  820/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9847, Loss: 0.0064
Epoch  65 Batch  840/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9794, Loss: 0.0067
Epoch  65 Batch  860/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9837, Loss: 0.0060
Epoch  65 Batch  880/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9709, Loss: 0.0118
Epoch  65 Batch  900/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9847, Loss: 0.0093
Epoch  65 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9815, Loss: 0.0047
Epoch  65 Batch  940/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9734, Loss: 0.0053
Epoch  65 Batch  960/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9783, Loss: 0.0086
Epoch  65 Batch  980/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9790, Loss: 0.0092
Epoch  65 Batch 1000/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9737, Loss: 0.0074
Epoch  65 Batch 1020/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9826, Loss: 0.0077
Epoch  65 Batch 1040/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9794, Loss: 0.0104
Epoch  65 Batch 1060/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9769, Loss: 0.0047
Epoch  66 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9794, Loss: 0.0056
Epoch  66 Batch   40/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9822, Loss: 0.0075
Epoch  66 Batch   60/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9631, Loss: 0.0073
Epoch  66 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9851, Loss: 0.0067
Epoch  66 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9787, Loss: 0.0063
Epoch  66 Batch  120/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9776, Loss: 0.0055
Epoch  66 Batch  140/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9833, Loss: 0.0078
Epoch  66 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0041
Epoch  66 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9869, Loss: 0.0047
Epoch  66 Batch  200/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9872, Loss: 0.0056
Epoch  66 Batch  220/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9790, Loss: 0.0079
Epoch  66 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  66 Batch  260/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9673, Loss: 0.0060
Epoch  66 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9798, Loss: 0.0077
Epoch  66 Batch  300/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9840, Loss: 0.0057
Epoch  66 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9734, Loss: 0.0079
Epoch  66 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9805, Loss: 0.0049
Epoch  66 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9790, Loss: 0.0061
Epoch  66 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9780, Loss: 0.0035
Epoch  66 Batch  400/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9883, Loss: 0.0090
Epoch  66 Batch  420/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9830, Loss: 0.0061
Epoch  66 Batch  440/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9812, Loss: 0.0046
Epoch  66 Batch  460/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9634, Loss: 0.0094
Epoch  66 Batch  480/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9719, Loss: 0.0085
Epoch  66 Batch  500/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9773, Loss: 0.0059
Epoch  66 Batch  520/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9798, Loss: 0.0046
Epoch  66 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9723, Loss: 0.0054
Epoch  66 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9815, Loss: 0.0040
Epoch  66 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9769, Loss: 0.0067
Epoch  66 Batch  600/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9847, Loss: 0.0057
Epoch  66 Batch  620/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9854, Loss: 0.0088
Epoch  66 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9847, Loss: 0.0044
Epoch  66 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9808, Loss: 0.0036
Epoch  66 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9879, Loss: 0.0071
Epoch  66 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9773, Loss: 0.0073
Epoch  66 Batch  720/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9837, Loss: 0.0058
Epoch  66 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9783, Loss: 0.0047
Epoch  66 Batch  760/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9837, Loss: 0.0070
Epoch  66 Batch  780/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9869, Loss: 0.0104
Epoch  66 Batch  800/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9719, Loss: 0.0054
Epoch  66 Batch  820/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9869, Loss: 0.0054
Epoch  66 Batch  840/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9815, Loss: 0.0063
Epoch  66 Batch  860/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9897, Loss: 0.0062
Epoch  66 Batch  880/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9751, Loss: 0.0118
Epoch  66 Batch  900/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9830, Loss: 0.0095
Epoch  66 Batch  920/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9851, Loss: 0.0051
Epoch  66 Batch  940/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9787, Loss: 0.0053
Epoch  66 Batch  960/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9801, Loss: 0.0071
Epoch  66 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9840, Loss: 0.0066
Epoch  66 Batch 1000/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9719, Loss: 0.0067
Epoch  66 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9844, Loss: 0.0039
Epoch  66 Batch 1040/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9830, Loss: 0.0092
Epoch  66 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0043
Epoch  67 Batch   20/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9840, Loss: 0.0058
Epoch  67 Batch   40/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9759, Loss: 0.0068
Epoch  67 Batch   60/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9769, Loss: 0.0069
Epoch  67 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9663, Loss: 0.0070
Epoch  67 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9730, Loss: 0.0063
Epoch  67 Batch  120/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9705, Loss: 0.0069
Epoch  67 Batch  140/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9837, Loss: 0.0055
Epoch  67 Batch  160/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9773, Loss: 0.0033
Epoch  67 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9769, Loss: 0.0048
Epoch  67 Batch  200/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9840, Loss: 0.0050
Epoch  67 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9794, Loss: 0.0076
Epoch  67 Batch  240/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9759, Loss: 0.0049
Epoch  67 Batch  260/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9744, Loss: 0.0053
Epoch  67 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9751, Loss: 0.0068
Epoch  67 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9790, Loss: 0.0063
Epoch  67 Batch  320/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9737, Loss: 0.0092
Epoch  67 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9773, Loss: 0.0045
Epoch  67 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9783, Loss: 0.0067
Epoch  67 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0045
Epoch  67 Batch  400/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9833, Loss: 0.0072
Epoch  67 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9830, Loss: 0.0050
Epoch  67 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9762, Loss: 0.0049
Epoch  67 Batch  460/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9734, Loss: 0.0079
Epoch  67 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9659, Loss: 0.0074
Epoch  67 Batch  500/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9783, Loss: 0.0043
Epoch  67 Batch  520/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9762, Loss: 0.0046
Epoch  67 Batch  540/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9734, Loss: 0.0050
Epoch  67 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0054
Epoch  67 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9876, Loss: 0.0061
Epoch  67 Batch  600/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9854, Loss: 0.0067
Epoch  67 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9776, Loss: 0.0084
Epoch  67 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9847, Loss: 0.0045
Epoch  67 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9808, Loss: 0.0042
Epoch  67 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9858, Loss: 0.0059
Epoch  67 Batch  700/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9787, Loss: 0.0075
Epoch  67 Batch  720/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9833, Loss: 0.0050
Epoch  67 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9787, Loss: 0.0050
Epoch  67 Batch  760/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9837, Loss: 0.0059
Epoch  67 Batch  780/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9826, Loss: 0.0076
Epoch  67 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9705, Loss: 0.0070
Epoch  67 Batch  820/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9787, Loss: 0.0058
Epoch  67 Batch  840/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9769, Loss: 0.0081
Epoch  67 Batch  860/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9869, Loss: 0.0068
Epoch  67 Batch  880/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9709, Loss: 0.0113
Epoch  67 Batch  900/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9798, Loss: 0.0082
Epoch  67 Batch  920/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9844, Loss: 0.0042
Epoch  67 Batch  940/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9801, Loss: 0.0068
Epoch  67 Batch  960/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9698, Loss: 0.0078
Epoch  67 Batch  980/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9688, Loss: 0.0079
Epoch  67 Batch 1000/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9780, Loss: 0.0061
Epoch  67 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9815, Loss: 0.0036
Epoch  67 Batch 1040/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9723, Loss: 0.0106
Epoch  67 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9698, Loss: 0.0064
Epoch  68 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9872, Loss: 0.0074
Epoch  68 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9794, Loss: 0.0074
Epoch  68 Batch   60/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9723, Loss: 0.0069
Epoch  68 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9748, Loss: 0.0064
Epoch  68 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9730, Loss: 0.0059
Epoch  68 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9727, Loss: 0.0057
Epoch  68 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9822, Loss: 0.0048
Epoch  68 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9727, Loss: 0.0042
Epoch  68 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9794, Loss: 0.0051
Epoch  68 Batch  200/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9865, Loss: 0.0060
Epoch  68 Batch  220/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9805, Loss: 0.0087
Epoch  68 Batch  240/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9776, Loss: 0.0053
Epoch  68 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0050
Epoch  68 Batch  280/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9737, Loss: 0.0067
Epoch  68 Batch  300/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9830, Loss: 0.0055
Epoch  68 Batch  320/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9595, Loss: 0.0085
Epoch  68 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9755, Loss: 0.0054
Epoch  68 Batch  360/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9705, Loss: 0.0066
Epoch  68 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9783, Loss: 0.0033
Epoch  68 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9815, Loss: 0.0064
Epoch  68 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9751, Loss: 0.0043
Epoch  68 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9766, Loss: 0.0040
Epoch  68 Batch  460/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9631, Loss: 0.0090
Epoch  68 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9766, Loss: 0.0068
Epoch  68 Batch  500/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9801, Loss: 0.0045
Epoch  68 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9801, Loss: 0.0037
Epoch  68 Batch  540/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9712, Loss: 0.0045
Epoch  68 Batch  560/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9780, Loss: 0.0056
Epoch  68 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9851, Loss: 0.0063
Epoch  68 Batch  600/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9890, Loss: 0.0055
Epoch  68 Batch  620/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9862, Loss: 0.0075
Epoch  68 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9844, Loss: 0.0050
Epoch  68 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9737, Loss: 0.0065
Epoch  68 Batch  680/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9759, Loss: 0.0074
Epoch  68 Batch  700/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9762, Loss: 0.0073
Epoch  68 Batch  720/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9837, Loss: 0.0065
Epoch  68 Batch  740/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9762, Loss: 0.0077
Epoch  68 Batch  760/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9822, Loss: 0.0064
Epoch  68 Batch  780/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9805, Loss: 0.0090
Epoch  68 Batch  800/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9755, Loss: 0.0053
Epoch  68 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9819, Loss: 0.0052
Epoch  68 Batch  840/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9830, Loss: 0.0083
Epoch  68 Batch  860/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9844, Loss: 0.0056
Epoch  68 Batch  880/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9759, Loss: 0.0107
Epoch  68 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9869, Loss: 0.0095
Epoch  68 Batch  920/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9652, Loss: 0.0047
Epoch  68 Batch  940/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9698, Loss: 0.0055
Epoch  68 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9737, Loss: 0.0069
Epoch  68 Batch  980/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9851, Loss: 0.0055
Epoch  68 Batch 1000/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9730, Loss: 0.0068
Epoch  68 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9812, Loss: 0.0045
Epoch  68 Batch 1040/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9830, Loss: 0.0074
Epoch  68 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9709, Loss: 0.0044
Epoch  69 Batch   20/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9844, Loss: 0.0052
Epoch  69 Batch   40/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9808, Loss: 0.0066
Epoch  69 Batch   60/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9656, Loss: 0.0065
Epoch  69 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9727, Loss: 0.0074
Epoch  69 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9798, Loss: 0.0058
Epoch  69 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9783, Loss: 0.0061
Epoch  69 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9766, Loss: 0.0051
Epoch  69 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0036
Epoch  69 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9727, Loss: 0.0042
Epoch  69 Batch  200/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9847, Loss: 0.0045
Epoch  69 Batch  220/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9787, Loss: 0.0085
Epoch  69 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9822, Loss: 0.0056
Epoch  69 Batch  260/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9893, Loss: 0.0062
Epoch  69 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9822, Loss: 0.0069
Epoch  69 Batch  300/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9904, Loss: 0.0073
Epoch  69 Batch  320/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9670, Loss: 0.0081
Epoch  69 Batch  340/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9805, Loss: 0.0057
Epoch  69 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9709, Loss: 0.0065
Epoch  69 Batch  380/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9918, Loss: 0.0044
Epoch  69 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9883, Loss: 0.0058
Epoch  69 Batch  420/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9826, Loss: 0.0062
Epoch  69 Batch  440/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9798, Loss: 0.0044
Epoch  69 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9677, Loss: 0.0077
Epoch  69 Batch  480/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9620, Loss: 0.0051
Epoch  69 Batch  500/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9794, Loss: 0.0045
Epoch  69 Batch  520/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9798, Loss: 0.0060
Epoch  69 Batch  540/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9783, Loss: 0.0070
Epoch  69 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9801, Loss: 0.0045
Epoch  69 Batch  580/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9876, Loss: 0.0076
Epoch  69 Batch  600/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9869, Loss: 0.0068
Epoch  69 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9847, Loss: 0.0085
Epoch  69 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9844, Loss: 0.0056
Epoch  69 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9808, Loss: 0.0033
Epoch  69 Batch  680/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9851, Loss: 0.0060
Epoch  69 Batch  700/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9741, Loss: 0.0065
Epoch  69 Batch  720/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9879, Loss: 0.0048
Epoch  69 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9808, Loss: 0.0053
Epoch  69 Batch  760/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9833, Loss: 0.0062
Epoch  69 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9794, Loss: 0.0068
Epoch  69 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9794, Loss: 0.0045
Epoch  69 Batch  820/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9815, Loss: 0.0059
Epoch  69 Batch  840/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9830, Loss: 0.0104
Epoch  69 Batch  860/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9925, Loss: 0.0054
Epoch  69 Batch  880/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9851, Loss: 0.0107
Epoch  69 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9854, Loss: 0.0086
Epoch  69 Batch  920/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9840, Loss: 0.0046
Epoch  69 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9812, Loss: 0.0044
Epoch  69 Batch  960/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9670, Loss: 0.0063
Epoch  69 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9837, Loss: 0.0062
Epoch  69 Batch 1000/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9798, Loss: 0.0076
Epoch  69 Batch 1020/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9833, Loss: 0.0035
Epoch  69 Batch 1040/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9830, Loss: 0.0094
Epoch  69 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9822, Loss: 0.0039
Epoch  70 Batch   20/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9908, Loss: 0.0052
Epoch  70 Batch   40/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9844, Loss: 0.0059
Epoch  70 Batch   60/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9716, Loss: 0.0066
Epoch  70 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9805, Loss: 0.0068
Epoch  70 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9723, Loss: 0.0049
Epoch  70 Batch  120/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9773, Loss: 0.0052
Epoch  70 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9798, Loss: 0.0049
Epoch  70 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9822, Loss: 0.0041
Epoch  70 Batch  180/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9773, Loss: 0.0044
Epoch  70 Batch  200/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9854, Loss: 0.0046
Epoch  70 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9815, Loss: 0.0084
Epoch  70 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9822, Loss: 0.0044
Epoch  70 Batch  260/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9808, Loss: 0.0062
Epoch  70 Batch  280/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9712, Loss: 0.0052
Epoch  70 Batch  300/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9922, Loss: 0.0054
Epoch  70 Batch  320/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9790, Loss: 0.0082
Epoch  70 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9830, Loss: 0.0051
Epoch  70 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9744, Loss: 0.0063
Epoch  70 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9858, Loss: 0.0041
Epoch  70 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9883, Loss: 0.0052
Epoch  70 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9830, Loss: 0.0054
Epoch  70 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9783, Loss: 0.0040
Epoch  70 Batch  460/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9734, Loss: 0.0079
Epoch  70 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9680, Loss: 0.0052
Epoch  70 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9790, Loss: 0.0038
Epoch  70 Batch  520/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9769, Loss: 0.0039
Epoch  70 Batch  540/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9787, Loss: 0.0051
Epoch  70 Batch  560/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9751, Loss: 0.0050
Epoch  70 Batch  580/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9862, Loss: 0.0067
Epoch  70 Batch  600/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9808, Loss: 0.0064
Epoch  70 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9723, Loss: 0.0075
Epoch  70 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9840, Loss: 0.0040
Epoch  70 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9794, Loss: 0.0039
Epoch  70 Batch  680/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9830, Loss: 0.0047
Epoch  70 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9787, Loss: 0.0070
Epoch  70 Batch  720/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9830, Loss: 0.0051
Epoch  70 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9755, Loss: 0.0059
Epoch  70 Batch  760/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9805, Loss: 0.0060
Epoch  70 Batch  780/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9812, Loss: 0.0059
Epoch  70 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9766, Loss: 0.0049
Epoch  70 Batch  820/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9869, Loss: 0.0056
Epoch  70 Batch  840/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9808, Loss: 0.0067
Epoch  70 Batch  860/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9876, Loss: 0.0052
Epoch  70 Batch  880/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9734, Loss: 0.0090
Epoch  70 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9801, Loss: 0.0082
Epoch  70 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9851, Loss: 0.0048
Epoch  70 Batch  940/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9766, Loss: 0.0041
Epoch  70 Batch  960/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9730, Loss: 0.0066
Epoch  70 Batch  980/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9794, Loss: 0.0057
Epoch  70 Batch 1000/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9670, Loss: 0.0065
Epoch  70 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0029
Epoch  70 Batch 1040/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9805, Loss: 0.0083
Epoch  70 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9702, Loss: 0.0040
Epoch  71 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9851, Loss: 0.0068
Epoch  71 Batch   40/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9837, Loss: 0.0076
Epoch  71 Batch   60/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9723, Loss: 0.0072
Epoch  71 Batch   80/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9798, Loss: 0.0078
Epoch  71 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9709, Loss: 0.0054
Epoch  71 Batch  120/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9744, Loss: 0.0074
Epoch  71 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9808, Loss: 0.0055
Epoch  71 Batch  160/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9805, Loss: 0.0038
Epoch  71 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9819, Loss: 0.0068
Epoch  71 Batch  200/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9794, Loss: 0.0063
Epoch  71 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9854, Loss: 0.0072
Epoch  71 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9805, Loss: 0.0048
Epoch  71 Batch  260/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9830, Loss: 0.0061
Epoch  71 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9801, Loss: 0.0064
Epoch  71 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9922, Loss: 0.0069
Epoch  71 Batch  320/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9691, Loss: 0.0063
Epoch  71 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9801, Loss: 0.0045
Epoch  71 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9734, Loss: 0.0049
Epoch  71 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9808, Loss: 0.0040
Epoch  71 Batch  400/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9826, Loss: 0.0122
Epoch  71 Batch  420/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9751, Loss: 0.0073
Epoch  71 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9734, Loss: 0.0056
Epoch  71 Batch  460/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9819, Loss: 0.0112
Epoch  71 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9719, Loss: 0.0051
Epoch  71 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9780, Loss: 0.0039
Epoch  71 Batch  520/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9748, Loss: 0.0040
Epoch  71 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9787, Loss: 0.0046
Epoch  71 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9815, Loss: 0.0037
Epoch  71 Batch  580/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9869, Loss: 0.0071
Epoch  71 Batch  600/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9780, Loss: 0.0086
Epoch  71 Batch  620/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9794, Loss: 0.0088
Epoch  71 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9879, Loss: 0.0062
Epoch  71 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9787, Loss: 0.0044
Epoch  71 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9837, Loss: 0.0064
Epoch  71 Batch  700/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9783, Loss: 0.0072
Epoch  71 Batch  720/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0065
Epoch  71 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9759, Loss: 0.0046
Epoch  71 Batch  760/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9837, Loss: 0.0067
Epoch  71 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9716, Loss: 0.0059
Epoch  71 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9780, Loss: 0.0041
Epoch  71 Batch  820/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9819, Loss: 0.0046
Epoch  71 Batch  840/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9830, Loss: 0.0062
Epoch  71 Batch  860/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9876, Loss: 0.0049
Epoch  71 Batch  880/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9656, Loss: 0.0098
Epoch  71 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9776, Loss: 0.0087
Epoch  71 Batch  920/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9808, Loss: 0.0051
Epoch  71 Batch  940/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9787, Loss: 0.0047
Epoch  71 Batch  960/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9801, Loss: 0.0071
Epoch  71 Batch  980/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9819, Loss: 0.0066
Epoch  71 Batch 1000/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9748, Loss: 0.0067
Epoch  71 Batch 1020/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9787, Loss: 0.0037
Epoch  71 Batch 1040/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9815, Loss: 0.0063
Epoch  71 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9751, Loss: 0.0041
Epoch  72 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9886, Loss: 0.0047
Epoch  72 Batch   40/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9886, Loss: 0.0063
Epoch  72 Batch   60/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9730, Loss: 0.0058
Epoch  72 Batch   80/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9851, Loss: 0.0091
Epoch  72 Batch  100/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9801, Loss: 0.0067
Epoch  72 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9808, Loss: 0.0049
Epoch  72 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9869, Loss: 0.0040
Epoch  72 Batch  160/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9755, Loss: 0.0036
Epoch  72 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9744, Loss: 0.0044
Epoch  72 Batch  200/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9840, Loss: 0.0045
Epoch  72 Batch  220/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9808, Loss: 0.0062
Epoch  72 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9751, Loss: 0.0048
Epoch  72 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0040
Epoch  72 Batch  280/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9769, Loss: 0.0073
Epoch  72 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9851, Loss: 0.0048
Epoch  72 Batch  320/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9734, Loss: 0.0084
Epoch  72 Batch  340/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9901, Loss: 0.0047
Epoch  72 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9744, Loss: 0.0059
Epoch  72 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9851, Loss: 0.0034
Epoch  72 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9847, Loss: 0.0053
Epoch  72 Batch  420/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9819, Loss: 0.0053
Epoch  72 Batch  440/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9851, Loss: 0.0042
Epoch  72 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9659, Loss: 0.0065
Epoch  72 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9712, Loss: 0.0061
Epoch  72 Batch  500/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9812, Loss: 0.0036
Epoch  72 Batch  520/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9737, Loss: 0.0052
Epoch  72 Batch  540/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9744, Loss: 0.0045
Epoch  72 Batch  560/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9755, Loss: 0.0044
Epoch  72 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9769, Loss: 0.0076
Epoch  72 Batch  600/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9869, Loss: 0.0062
Epoch  72 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9869, Loss: 0.0071
Epoch  72 Batch  640/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9893, Loss: 0.0058
Epoch  72 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9741, Loss: 0.0030
Epoch  72 Batch  680/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9879, Loss: 0.0063
Epoch  72 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9773, Loss: 0.0057
Epoch  72 Batch  720/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9897, Loss: 0.0058
Epoch  72 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9808, Loss: 0.0048
Epoch  72 Batch  760/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9851, Loss: 0.0067
Epoch  72 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9890, Loss: 0.0057
Epoch  72 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9805, Loss: 0.0043
Epoch  72 Batch  820/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9851, Loss: 0.0045
Epoch  72 Batch  840/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9787, Loss: 0.0064
Epoch  72 Batch  860/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9826, Loss: 0.0061
Epoch  72 Batch  880/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9702, Loss: 0.0079
Epoch  72 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9822, Loss: 0.0079
Epoch  72 Batch  920/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9819, Loss: 0.0058
Epoch  72 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0043
Epoch  72 Batch  960/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9751, Loss: 0.0077
Epoch  72 Batch  980/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9837, Loss: 0.0070
Epoch  72 Batch 1000/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9709, Loss: 0.0069
Epoch  72 Batch 1020/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9840, Loss: 0.0037
Epoch  72 Batch 1040/1077 - Train Accuracy: 0.9811, Validation Accuracy: 0.9826, Loss: 0.0080
Epoch  72 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9727, Loss: 0.0048
Epoch  73 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9854, Loss: 0.0049
Epoch  73 Batch   40/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9869, Loss: 0.0054
Epoch  73 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9680, Loss: 0.0064
Epoch  73 Batch   80/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9851, Loss: 0.0068
Epoch  73 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9762, Loss: 0.0052
Epoch  73 Batch  120/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9730, Loss: 0.0075
Epoch  73 Batch  140/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9851, Loss: 0.0042
Epoch  73 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9741, Loss: 0.0030
Epoch  73 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9822, Loss: 0.0039
Epoch  73 Batch  200/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9822, Loss: 0.0044
Epoch  73 Batch  220/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9886, Loss: 0.0064
Epoch  73 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9801, Loss: 0.0043
Epoch  73 Batch  260/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9815, Loss: 0.0050
Epoch  73 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9844, Loss: 0.0068
Epoch  73 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9847, Loss: 0.0042
Epoch  73 Batch  320/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9734, Loss: 0.0072
Epoch  73 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9787, Loss: 0.0041
Epoch  73 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9627, Loss: 0.0053
Epoch  73 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9759, Loss: 0.0035
Epoch  73 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9783, Loss: 0.0044
Epoch  73 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9826, Loss: 0.0045
Epoch  73 Batch  440/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9776, Loss: 0.0046
Epoch  73 Batch  460/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9691, Loss: 0.0084
Epoch  73 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9716, Loss: 0.0059
Epoch  73 Batch  500/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9830, Loss: 0.0041
Epoch  73 Batch  520/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9798, Loss: 0.0036
Epoch  73 Batch  540/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9762, Loss: 0.0050
Epoch  73 Batch  560/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9826, Loss: 0.0048
Epoch  73 Batch  580/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9890, Loss: 0.0070
Epoch  73 Batch  600/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9837, Loss: 0.0077
Epoch  73 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9741, Loss: 0.0068
Epoch  73 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9830, Loss: 0.0052
Epoch  73 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9787, Loss: 0.0030
Epoch  73 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9876, Loss: 0.0057
Epoch  73 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9751, Loss: 0.0063
Epoch  73 Batch  720/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9805, Loss: 0.0054
Epoch  73 Batch  740/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9702, Loss: 0.0051
Epoch  73 Batch  760/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9854, Loss: 0.0054
Epoch  73 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9794, Loss: 0.0060
Epoch  73 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9780, Loss: 0.0035
Epoch  73 Batch  820/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9822, Loss: 0.0062
Epoch  73 Batch  840/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9830, Loss: 0.0058
Epoch  73 Batch  860/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9879, Loss: 0.0062
Epoch  73 Batch  880/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9755, Loss: 0.0094
Epoch  73 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9869, Loss: 0.0075
Epoch  73 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9925, Loss: 0.0050
Epoch  73 Batch  940/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9734, Loss: 0.0045
Epoch  73 Batch  960/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9847, Loss: 0.0069
Epoch  73 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9840, Loss: 0.0061
Epoch  73 Batch 1000/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9734, Loss: 0.0057
Epoch  73 Batch 1020/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9869, Loss: 0.0041
Epoch  73 Batch 1040/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9837, Loss: 0.0075
Epoch  73 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9822, Loss: 0.0055
Epoch  74 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9915, Loss: 0.0060
Epoch  74 Batch   40/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9872, Loss: 0.0068
Epoch  74 Batch   60/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9766, Loss: 0.0061
Epoch  74 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9872, Loss: 0.0064
Epoch  74 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9801, Loss: 0.0054
Epoch  74 Batch  120/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9805, Loss: 0.0088
Epoch  74 Batch  140/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9751, Loss: 0.0083
Epoch  74 Batch  160/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9709, Loss: 0.0037
Epoch  74 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9748, Loss: 0.0048
Epoch  74 Batch  200/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  74 Batch  220/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9819, Loss: 0.0079
Epoch  74 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9851, Loss: 0.0051
Epoch  74 Batch  260/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9751, Loss: 0.0050
Epoch  74 Batch  280/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9705, Loss: 0.0085
Epoch  74 Batch  300/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9812, Loss: 0.0086
Epoch  74 Batch  320/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9691, Loss: 0.0105
Epoch  74 Batch  340/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9847, Loss: 0.0057
Epoch  74 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9712, Loss: 0.0054
Epoch  74 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9812, Loss: 0.0048
Epoch  74 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9879, Loss: 0.0076
Epoch  74 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9798, Loss: 0.0054
Epoch  74 Batch  440/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9805, Loss: 0.0037
Epoch  74 Batch  460/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9776, Loss: 0.0074
Epoch  74 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9794, Loss: 0.0052
Epoch  74 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0041
Epoch  74 Batch  520/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9780, Loss: 0.0047
Epoch  74 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9819, Loss: 0.0045
Epoch  74 Batch  560/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9876, Loss: 0.0031
Epoch  74 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9830, Loss: 0.0067
Epoch  74 Batch  600/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9766, Loss: 0.0054
Epoch  74 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9766, Loss: 0.0064
Epoch  74 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9847, Loss: 0.0042
Epoch  74 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9780, Loss: 0.0036
Epoch  74 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9876, Loss: 0.0049
Epoch  74 Batch  700/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9805, Loss: 0.0080
Epoch  74 Batch  720/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9833, Loss: 0.0040
Epoch  74 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9759, Loss: 0.0042
Epoch  74 Batch  760/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9858, Loss: 0.0056
Epoch  74 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9862, Loss: 0.0077
Epoch  74 Batch  800/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9826, Loss: 0.0051
Epoch  74 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9783, Loss: 0.0060
Epoch  74 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9780, Loss: 0.0057
Epoch  74 Batch  860/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  74 Batch  880/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9652, Loss: 0.0072
Epoch  74 Batch  900/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9915, Loss: 0.0095
Epoch  74 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9709, Loss: 0.0043
Epoch  74 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9691, Loss: 0.0035
Epoch  74 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9730, Loss: 0.0074
Epoch  74 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9879, Loss: 0.0051
Epoch  74 Batch 1000/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9759, Loss: 0.0080
Epoch  74 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9879, Loss: 0.0035
Epoch  74 Batch 1040/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9826, Loss: 0.0063
Epoch  74 Batch 1060/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9780, Loss: 0.0042
Epoch  75 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9904, Loss: 0.0043
Epoch  75 Batch   40/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9901, Loss: 0.0058
Epoch  75 Batch   60/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9805, Loss: 0.0056
Epoch  75 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9755, Loss: 0.0073
Epoch  75 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9790, Loss: 0.0051
Epoch  75 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9780, Loss: 0.0053
Epoch  75 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9847, Loss: 0.0060
Epoch  75 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9748, Loss: 0.0032
Epoch  75 Batch  180/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9719, Loss: 0.0042
Epoch  75 Batch  200/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9883, Loss: 0.0058
Epoch  75 Batch  220/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9854, Loss: 0.0077
Epoch  75 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9766, Loss: 0.0035
Epoch  75 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9773, Loss: 0.0041
Epoch  75 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9780, Loss: 0.0051
Epoch  75 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9833, Loss: 0.0046
Epoch  75 Batch  320/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9741, Loss: 0.0099
Epoch  75 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9755, Loss: 0.0038
Epoch  75 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9801, Loss: 0.0050
Epoch  75 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9911, Loss: 0.0033
Epoch  75 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9883, Loss: 0.0053
Epoch  75 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9751, Loss: 0.0065
Epoch  75 Batch  440/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9741, Loss: 0.0035
Epoch  75 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9730, Loss: 0.0070
Epoch  75 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9677, Loss: 0.0105
Epoch  75 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9762, Loss: 0.0040
Epoch  75 Batch  520/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9659, Loss: 0.0047
Epoch  75 Batch  540/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9698, Loss: 0.0030
Epoch  75 Batch  560/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9702, Loss: 0.0041
Epoch  75 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9833, Loss: 0.0064
Epoch  75 Batch  600/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9830, Loss: 0.0060
Epoch  75 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9869, Loss: 0.0056
Epoch  75 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9751, Loss: 0.0045
Epoch  75 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0026
Epoch  75 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9858, Loss: 0.0050
Epoch  75 Batch  700/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9815, Loss: 0.0094
Epoch  75 Batch  720/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9783, Loss: 0.0061
Epoch  75 Batch  740/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9716, Loss: 0.0071
Epoch  75 Batch  760/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9826, Loss: 0.0073
Epoch  75 Batch  780/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9922, Loss: 0.0084
Epoch  75 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0037
Epoch  75 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0045
Epoch  75 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9794, Loss: 0.0061
Epoch  75 Batch  860/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9805, Loss: 0.0049
Epoch  75 Batch  880/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9719, Loss: 0.0077
Epoch  75 Batch  900/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9826, Loss: 0.0072
Epoch  75 Batch  920/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9822, Loss: 0.0051
Epoch  75 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9734, Loss: 0.0042
Epoch  75 Batch  960/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9716, Loss: 0.0060
Epoch  75 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9876, Loss: 0.0053
Epoch  75 Batch 1000/1077 - Train Accuracy: 0.9970, Validation Accuracy: 0.9766, Loss: 0.0047
Epoch  75 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9837, Loss: 0.0030
Epoch  75 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9830, Loss: 0.0074
Epoch  75 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0040
Epoch  76 Batch   20/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9925, Loss: 0.0046
Epoch  76 Batch   40/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9879, Loss: 0.0074
Epoch  76 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9702, Loss: 0.0066
Epoch  76 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9751, Loss: 0.0070
Epoch  76 Batch  100/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9794, Loss: 0.0063
Epoch  76 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9769, Loss: 0.0047
Epoch  76 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9819, Loss: 0.0040
Epoch  76 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9702, Loss: 0.0031
Epoch  76 Batch  180/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9748, Loss: 0.0046
Epoch  76 Batch  200/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9798, Loss: 0.0037
Epoch  76 Batch  220/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9858, Loss: 0.0069
Epoch  76 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9798, Loss: 0.0041
Epoch  76 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0050
Epoch  76 Batch  280/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9801, Loss: 0.0058
Epoch  76 Batch  300/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9925, Loss: 0.0045
Epoch  76 Batch  320/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9719, Loss: 0.0063
Epoch  76 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9755, Loss: 0.0037
Epoch  76 Batch  360/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9755, Loss: 0.0043
Epoch  76 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9826, Loss: 0.0041
Epoch  76 Batch  400/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9854, Loss: 0.0068
Epoch  76 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9879, Loss: 0.0050
Epoch  76 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9787, Loss: 0.0033
Epoch  76 Batch  460/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9680, Loss: 0.0063
Epoch  76 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9691, Loss: 0.0063
Epoch  76 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0032
Epoch  76 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9748, Loss: 0.0042
Epoch  76 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9744, Loss: 0.0041
Epoch  76 Batch  560/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9776, Loss: 0.0043
Epoch  76 Batch  580/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9719, Loss: 0.0066
Epoch  76 Batch  600/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9826, Loss: 0.0051
Epoch  76 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9869, Loss: 0.0061
Epoch  76 Batch  640/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9727, Loss: 0.0052
Epoch  76 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9712, Loss: 0.0041
Epoch  76 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9883, Loss: 0.0047
Epoch  76 Batch  700/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9766, Loss: 0.0063
Epoch  76 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0040
Epoch  76 Batch  740/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9783, Loss: 0.0064
Epoch  76 Batch  760/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9858, Loss: 0.0061
Epoch  76 Batch  780/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9808, Loss: 0.0066
Epoch  76 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9737, Loss: 0.0054
Epoch  76 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0040
Epoch  76 Batch  840/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9830, Loss: 0.0075
Epoch  76 Batch  860/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9876, Loss: 0.0059
Epoch  76 Batch  880/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9680, Loss: 0.0071
Epoch  76 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9727, Loss: 0.0086
Epoch  76 Batch  920/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9759, Loss: 0.0052
Epoch  76 Batch  940/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9691, Loss: 0.0035
Epoch  76 Batch  960/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9684, Loss: 0.0069
Epoch  76 Batch  980/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9808, Loss: 0.0080
Epoch  76 Batch 1000/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9851, Loss: 0.0070
Epoch  76 Batch 1020/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9730, Loss: 0.0052
Epoch  76 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9883, Loss: 0.0088
Epoch  76 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9670, Loss: 0.0053
Epoch  77 Batch   20/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9783, Loss: 0.0069
Epoch  77 Batch   40/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9865, Loss: 0.0077
Epoch  77 Batch   60/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9656, Loss: 0.0065
Epoch  77 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9805, Loss: 0.0062
Epoch  77 Batch  100/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9812, Loss: 0.0053
Epoch  77 Batch  120/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9822, Loss: 0.0062
Epoch  77 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9780, Loss: 0.0040
Epoch  77 Batch  160/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9705, Loss: 0.0045
Epoch  77 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9751, Loss: 0.0044
Epoch  77 Batch  200/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9748, Loss: 0.0031
Epoch  77 Batch  220/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9766, Loss: 0.0077
Epoch  77 Batch  240/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9890, Loss: 0.0047
Epoch  77 Batch  260/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9844, Loss: 0.0050
Epoch  77 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9780, Loss: 0.0052
Epoch  77 Batch  300/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9876, Loss: 0.0052
Epoch  77 Batch  320/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9744, Loss: 0.0060
Epoch  77 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9798, Loss: 0.0038
Epoch  77 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9716, Loss: 0.0036
Epoch  77 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9730, Loss: 0.0029
Epoch  77 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9897, Loss: 0.0057
Epoch  77 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9862, Loss: 0.0050
Epoch  77 Batch  440/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9787, Loss: 0.0029
Epoch  77 Batch  460/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9737, Loss: 0.0057
Epoch  77 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9769, Loss: 0.0042
Epoch  77 Batch  500/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9826, Loss: 0.0036
Epoch  77 Batch  520/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9652, Loss: 0.0031
Epoch  77 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9695, Loss: 0.0042
Epoch  77 Batch  560/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9677, Loss: 0.0047
Epoch  77 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9769, Loss: 0.0060
Epoch  77 Batch  600/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9808, Loss: 0.0078
Epoch  77 Batch  620/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9893, Loss: 0.0069
Epoch  77 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9847, Loss: 0.0047
Epoch  77 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9677, Loss: 0.0040
Epoch  77 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9890, Loss: 0.0056
Epoch  77 Batch  700/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9780, Loss: 0.0072
Epoch  77 Batch  720/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9805, Loss: 0.0048
Epoch  77 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9759, Loss: 0.0047
Epoch  77 Batch  760/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9858, Loss: 0.0068
Epoch  77 Batch  780/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9925, Loss: 0.0074
Epoch  77 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9801, Loss: 0.0030
Epoch  77 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9812, Loss: 0.0047
Epoch  77 Batch  840/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9815, Loss: 0.0076
Epoch  77 Batch  860/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9805, Loss: 0.0055
Epoch  77 Batch  880/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9719, Loss: 0.0075
Epoch  77 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9869, Loss: 0.0071
Epoch  77 Batch  920/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9780, Loss: 0.0053
Epoch  77 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0048
Epoch  77 Batch  960/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9670, Loss: 0.0068
Epoch  77 Batch  980/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9822, Loss: 0.0066
Epoch  77 Batch 1000/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9741, Loss: 0.0065
Epoch  77 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9851, Loss: 0.0030
Epoch  77 Batch 1040/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9776, Loss: 0.0056
Epoch  77 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9801, Loss: 0.0033
Epoch  78 Batch   20/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9851, Loss: 0.0062
Epoch  78 Batch   40/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9901, Loss: 0.0080
Epoch  78 Batch   60/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9741, Loss: 0.0058
Epoch  78 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9815, Loss: 0.0070
Epoch  78 Batch  100/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9847, Loss: 0.0062
Epoch  78 Batch  120/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9801, Loss: 0.0067
Epoch  78 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9730, Loss: 0.0048
Epoch  78 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0022
Epoch  78 Batch  180/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9727, Loss: 0.0038
Epoch  78 Batch  200/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9819, Loss: 0.0062
Epoch  78 Batch  220/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9780, Loss: 0.0070
Epoch  78 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9808, Loss: 0.0039
Epoch  78 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9776, Loss: 0.0046
Epoch  78 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9830, Loss: 0.0054
Epoch  78 Batch  300/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9883, Loss: 0.0047
Epoch  78 Batch  320/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9734, Loss: 0.0073
Epoch  78 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9801, Loss: 0.0036
Epoch  78 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9751, Loss: 0.0051
Epoch  78 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9808, Loss: 0.0030
Epoch  78 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9851, Loss: 0.0045
Epoch  78 Batch  420/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9822, Loss: 0.0057
Epoch  78 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9830, Loss: 0.0033
Epoch  78 Batch  460/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9830, Loss: 0.0066
Epoch  78 Batch  480/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9627, Loss: 0.0051
Epoch  78 Batch  500/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9780, Loss: 0.0038
Epoch  78 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9684, Loss: 0.0045
Epoch  78 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9787, Loss: 0.0042
Epoch  78 Batch  560/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9780, Loss: 0.0047
Epoch  78 Batch  580/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9822, Loss: 0.0060
Epoch  78 Batch  600/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9819, Loss: 0.0046
Epoch  78 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9869, Loss: 0.0062
Epoch  78 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9847, Loss: 0.0041
Epoch  78 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9847, Loss: 0.0029
Epoch  78 Batch  680/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9826, Loss: 0.0053
Epoch  78 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9808, Loss: 0.0057
Epoch  78 Batch  720/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9897, Loss: 0.0045
Epoch  78 Batch  740/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9759, Loss: 0.0041
Epoch  78 Batch  760/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9794, Loss: 0.0058
Epoch  78 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9837, Loss: 0.0056
Epoch  78 Batch  800/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9808, Loss: 0.0040
Epoch  78 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9879, Loss: 0.0035
Epoch  78 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9830, Loss: 0.0053
Epoch  78 Batch  860/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9879, Loss: 0.0058
Epoch  78 Batch  880/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9673, Loss: 0.0060
Epoch  78 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9897, Loss: 0.0073
Epoch  78 Batch  920/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9776, Loss: 0.0101
Epoch  78 Batch  940/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9844, Loss: 0.0044
Epoch  78 Batch  960/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9773, Loss: 0.0096
Epoch  78 Batch  980/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9865, Loss: 0.0062
Epoch  78 Batch 1000/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9741, Loss: 0.0091
Epoch  78 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9794, Loss: 0.0029
Epoch  78 Batch 1040/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9837, Loss: 0.0056
Epoch  78 Batch 1060/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9805, Loss: 0.0040
Epoch  79 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9922, Loss: 0.0043
Epoch  79 Batch   40/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9805, Loss: 0.0045
Epoch  79 Batch   60/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9691, Loss: 0.0076
Epoch  79 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9702, Loss: 0.0058
Epoch  79 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9741, Loss: 0.0053
Epoch  79 Batch  120/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9730, Loss: 0.0071
Epoch  79 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9826, Loss: 0.0043
Epoch  79 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9769, Loss: 0.0029
Epoch  79 Batch  180/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9776, Loss: 0.0039
Epoch  79 Batch  200/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9837, Loss: 0.0040
Epoch  79 Batch  220/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9822, Loss: 0.0080
Epoch  79 Batch  240/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9862, Loss: 0.0057
Epoch  79 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9879, Loss: 0.0047
Epoch  79 Batch  280/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9776, Loss: 0.0057
Epoch  79 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9890, Loss: 0.0054
Epoch  79 Batch  320/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9670, Loss: 0.0053
Epoch  79 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9837, Loss: 0.0030
Epoch  79 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9716, Loss: 0.0042
Epoch  79 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9663, Loss: 0.0030
Epoch  79 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9876, Loss: 0.0059
Epoch  79 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9862, Loss: 0.0051
Epoch  79 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9801, Loss: 0.0030
Epoch  79 Batch  460/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9688, Loss: 0.0062
Epoch  79 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9673, Loss: 0.0043
Epoch  79 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9730, Loss: 0.0033
Epoch  79 Batch  520/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9673, Loss: 0.0047
Epoch  79 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9723, Loss: 0.0047
Epoch  79 Batch  560/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9709, Loss: 0.0035
Epoch  79 Batch  580/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9744, Loss: 0.0076
Epoch  79 Batch  600/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9755, Loss: 0.0054
Epoch  79 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9790, Loss: 0.0058
Epoch  79 Batch  640/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9790, Loss: 0.0057
Epoch  79 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0021
Epoch  79 Batch  680/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9854, Loss: 0.0048
Epoch  79 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9755, Loss: 0.0070
Epoch  79 Batch  720/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9830, Loss: 0.0042
Epoch  79 Batch  740/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9776, Loss: 0.0055
Epoch  79 Batch  760/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9862, Loss: 0.0053
Epoch  79 Batch  780/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9865, Loss: 0.0058
Epoch  79 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9716, Loss: 0.0032
Epoch  79 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9755, Loss: 0.0038
Epoch  79 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9766, Loss: 0.0054
Epoch  79 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9876, Loss: 0.0048
Epoch  79 Batch  880/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9759, Loss: 0.0062
Epoch  79 Batch  900/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9815, Loss: 0.0078
Epoch  79 Batch  920/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9808, Loss: 0.0089
Epoch  79 Batch  940/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9709, Loss: 0.0044
Epoch  79 Batch  960/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9773, Loss: 0.0065
Epoch  79 Batch  980/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9815, Loss: 0.0069
Epoch  79 Batch 1000/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9684, Loss: 0.0046
Epoch  79 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9819, Loss: 0.0034
Epoch  79 Batch 1040/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9826, Loss: 0.0058
Epoch  79 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9798, Loss: 0.0033
Epoch  80 Batch   20/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9854, Loss: 0.0047
Epoch  80 Batch   40/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9940, Loss: 0.0043
Epoch  80 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9730, Loss: 0.0051
Epoch  80 Batch   80/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9759, Loss: 0.0053
Epoch  80 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9876, Loss: 0.0054
Epoch  80 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9830, Loss: 0.0060
Epoch  80 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9854, Loss: 0.0035
Epoch  80 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9769, Loss: 0.0032
Epoch  80 Batch  180/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9748, Loss: 0.0042
Epoch  80 Batch  200/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9794, Loss: 0.0035
Epoch  80 Batch  220/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9812, Loss: 0.0070
Epoch  80 Batch  240/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9805, Loss: 0.0042
Epoch  80 Batch  260/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9769, Loss: 0.0055
Epoch  80 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9819, Loss: 0.0057
Epoch  80 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9847, Loss: 0.0050
Epoch  80 Batch  320/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9737, Loss: 0.0085
Epoch  80 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9762, Loss: 0.0035
Epoch  80 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9698, Loss: 0.0044
Epoch  80 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9695, Loss: 0.0029
Epoch  80 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9794, Loss: 0.0044
Epoch  80 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9851, Loss: 0.0043
Epoch  80 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9904, Loss: 0.0032
Epoch  80 Batch  460/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9705, Loss: 0.0074
Epoch  80 Batch  480/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9670, Loss: 0.0047
Epoch  80 Batch  500/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9822, Loss: 0.0033
Epoch  80 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9624, Loss: 0.0042
Epoch  80 Batch  540/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9837, Loss: 0.0043
Epoch  80 Batch  560/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9773, Loss: 0.0056
Epoch  80 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9680, Loss: 0.0061
Epoch  80 Batch  600/1077 - Train Accuracy: 0.9985, Validation Accuracy: 0.9751, Loss: 0.0047
Epoch  80 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9901, Loss: 0.0056
Epoch  80 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9897, Loss: 0.0048
Epoch  80 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9712, Loss: 0.0037
Epoch  80 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9854, Loss: 0.0049
Epoch  80 Batch  700/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9783, Loss: 0.0096
Epoch  80 Batch  720/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9815, Loss: 0.0123
Epoch  80 Batch  740/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9759, Loss: 0.0061
Epoch  80 Batch  760/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9876, Loss: 0.0062
Epoch  80 Batch  780/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9925, Loss: 0.0081
Epoch  80 Batch  800/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9830, Loss: 0.0043
Epoch  80 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9911, Loss: 0.0057
Epoch  80 Batch  840/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9808, Loss: 0.0058
Epoch  80 Batch  860/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9922, Loss: 0.0051
Epoch  80 Batch  880/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9719, Loss: 0.0090
Epoch  80 Batch  900/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9840, Loss: 0.0104
Epoch  80 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9723, Loss: 0.0040
Epoch  80 Batch  940/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9805, Loss: 0.0035
Epoch  80 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9698, Loss: 0.0066
Epoch  80 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9798, Loss: 0.0046
Epoch  80 Batch 1000/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9769, Loss: 0.0049
Epoch  80 Batch 1020/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9840, Loss: 0.0033
Epoch  80 Batch 1040/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9830, Loss: 0.0083
Epoch  80 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9815, Loss: 0.0038
Epoch  81 Batch   20/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9872, Loss: 0.0059
Epoch  81 Batch   40/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9847, Loss: 0.0037
Epoch  81 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9801, Loss: 0.0052
Epoch  81 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9851, Loss: 0.0051
Epoch  81 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9925, Loss: 0.0043
Epoch  81 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9801, Loss: 0.0048
Epoch  81 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9822, Loss: 0.0036
Epoch  81 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9734, Loss: 0.0034
Epoch  81 Batch  180/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9776, Loss: 0.0047
Epoch  81 Batch  200/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9815, Loss: 0.0034
Epoch  81 Batch  220/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9794, Loss: 0.0067
Epoch  81 Batch  240/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9830, Loss: 0.0040
Epoch  81 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9737, Loss: 0.0036
Epoch  81 Batch  280/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9737, Loss: 0.0052
Epoch  81 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9872, Loss: 0.0044
Epoch  81 Batch  320/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9673, Loss: 0.0068
Epoch  81 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9787, Loss: 0.0030
Epoch  81 Batch  360/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9766, Loss: 0.0042
Epoch  81 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9702, Loss: 0.0039
Epoch  81 Batch  400/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9812, Loss: 0.0047
Epoch  81 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9876, Loss: 0.0047
Epoch  81 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9741, Loss: 0.0030
Epoch  81 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9808, Loss: 0.0055
Epoch  81 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9716, Loss: 0.0046
Epoch  81 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9744, Loss: 0.0035
Epoch  81 Batch  520/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9712, Loss: 0.0040
Epoch  81 Batch  540/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9822, Loss: 0.0057
Epoch  81 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9808, Loss: 0.0043
Epoch  81 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9727, Loss: 0.0056
Epoch  81 Batch  600/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9719, Loss: 0.0062
Epoch  81 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9847, Loss: 0.0063
Epoch  81 Batch  640/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9847, Loss: 0.0063
Epoch  81 Batch  660/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9737, Loss: 0.0045
Epoch  81 Batch  680/1077 - Train Accuracy: 0.9732, Validation Accuracy: 0.9773, Loss: 0.0079
Epoch  81 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9751, Loss: 0.0081
Epoch  81 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9798, Loss: 0.0050
Epoch  81 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9794, Loss: 0.0052
Epoch  81 Batch  760/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9805, Loss: 0.0077
Epoch  81 Batch  780/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9862, Loss: 0.0086
Epoch  81 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9876, Loss: 0.0032
Epoch  81 Batch  820/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9826, Loss: 0.0044
Epoch  81 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9805, Loss: 0.0056
Epoch  81 Batch  860/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9826, Loss: 0.0062
Epoch  81 Batch  880/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9794, Loss: 0.0057
Epoch  81 Batch  900/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9812, Loss: 0.0095
Epoch  81 Batch  920/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9805, Loss: 0.0051
Epoch  81 Batch  940/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9755, Loss: 0.0052
Epoch  81 Batch  960/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9737, Loss: 0.0059
Epoch  81 Batch  980/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9837, Loss: 0.0058
Epoch  81 Batch 1000/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9787, Loss: 0.0055
Epoch  81 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9833, Loss: 0.0030
Epoch  81 Batch 1040/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9783, Loss: 0.0083
Epoch  81 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9915, Loss: 0.0031
Epoch  82 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9897, Loss: 0.0041
Epoch  82 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9844, Loss: 0.0045
Epoch  82 Batch   60/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9876, Loss: 0.0059
Epoch  82 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9897, Loss: 0.0056
Epoch  82 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9808, Loss: 0.0048
Epoch  82 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9822, Loss: 0.0043
Epoch  82 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9819, Loss: 0.0044
Epoch  82 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9801, Loss: 0.0026
Epoch  82 Batch  180/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9794, Loss: 0.0044
Epoch  82 Batch  200/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9872, Loss: 0.0033
Epoch  82 Batch  220/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9837, Loss: 0.0057
Epoch  82 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9830, Loss: 0.0037
Epoch  82 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9815, Loss: 0.0046
Epoch  82 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9702, Loss: 0.0042
Epoch  82 Batch  300/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9901, Loss: 0.0046
Epoch  82 Batch  320/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9688, Loss: 0.0065
Epoch  82 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9762, Loss: 0.0036
Epoch  82 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9783, Loss: 0.0038
Epoch  82 Batch  380/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9716, Loss: 0.0033
Epoch  82 Batch  400/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9847, Loss: 0.0049
Epoch  82 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9844, Loss: 0.0047
Epoch  82 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9712, Loss: 0.0033
Epoch  82 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9808, Loss: 0.0056
Epoch  82 Batch  480/1077 - Train Accuracy: 0.9893, Validation Accuracy: 0.9723, Loss: 0.0056
Epoch  82 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9727, Loss: 0.0030
Epoch  82 Batch  520/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9666, Loss: 0.0027
Epoch  82 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9759, Loss: 0.0040
Epoch  82 Batch  560/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9712, Loss: 0.0032
Epoch  82 Batch  580/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9759, Loss: 0.0055
Epoch  82 Batch  600/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9851, Loss: 0.0051
Epoch  82 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9826, Loss: 0.0062
Epoch  82 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9762, Loss: 0.0058
Epoch  82 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9762, Loss: 0.0031
Epoch  82 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9851, Loss: 0.0042
Epoch  82 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9769, Loss: 0.0066
Epoch  82 Batch  720/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9787, Loss: 0.0040
Epoch  82 Batch  740/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9780, Loss: 0.0079
Epoch  82 Batch  760/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9766, Loss: 0.0049
Epoch  82 Batch  780/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9851, Loss: 0.0084
Epoch  82 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9805, Loss: 0.0030
Epoch  82 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9876, Loss: 0.0032
Epoch  82 Batch  840/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9826, Loss: 0.0051
Epoch  82 Batch  860/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9862, Loss: 0.0039
Epoch  82 Batch  880/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9762, Loss: 0.0060
Epoch  82 Batch  900/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9872, Loss: 0.0074
Epoch  82 Batch  920/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9847, Loss: 0.0054
Epoch  82 Batch  940/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9815, Loss: 0.0051
Epoch  82 Batch  960/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9766, Loss: 0.0063
Epoch  82 Batch  980/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9840, Loss: 0.0060
Epoch  82 Batch 1000/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9759, Loss: 0.0048
Epoch  82 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9812, Loss: 0.0025
Epoch  82 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9815, Loss: 0.0050
Epoch  82 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9780, Loss: 0.0034
Epoch  83 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9922, Loss: 0.0047
Epoch  83 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9925, Loss: 0.0051
Epoch  83 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9847, Loss: 0.0056
Epoch  83 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9897, Loss: 0.0046
Epoch  83 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9883, Loss: 0.0054
Epoch  83 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9783, Loss: 0.0059
Epoch  83 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9847, Loss: 0.0045
Epoch  83 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0027
Epoch  83 Batch  180/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9826, Loss: 0.0043
Epoch  83 Batch  200/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9869, Loss: 0.0029
Epoch  83 Batch  220/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9790, Loss: 0.0077
Epoch  83 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9854, Loss: 0.0032
Epoch  83 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9773, Loss: 0.0033
Epoch  83 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9897, Loss: 0.0057
Epoch  83 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9883, Loss: 0.0042
Epoch  83 Batch  320/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9741, Loss: 0.0047
Epoch  83 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9734, Loss: 0.0032
Epoch  83 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9759, Loss: 0.0047
Epoch  83 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9741, Loss: 0.0034
Epoch  83 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9830, Loss: 0.0049
Epoch  83 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9783, Loss: 0.0038
Epoch  83 Batch  440/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9762, Loss: 0.0035
Epoch  83 Batch  460/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9744, Loss: 0.0072
Epoch  83 Batch  480/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9641, Loss: 0.0059
Epoch  83 Batch  500/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9826, Loss: 0.0062
Epoch  83 Batch  520/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9730, Loss: 0.0030
Epoch  83 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9837, Loss: 0.0040
Epoch  83 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9737, Loss: 0.0056
Epoch  83 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9808, Loss: 0.0059
Epoch  83 Batch  600/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9780, Loss: 0.0050
Epoch  83 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9893, Loss: 0.0061
Epoch  83 Batch  640/1077 - Train Accuracy: 0.9888, Validation Accuracy: 0.9773, Loss: 0.0046
Epoch  83 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9762, Loss: 0.0033
Epoch  83 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9897, Loss: 0.0044
Epoch  83 Batch  700/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9794, Loss: 0.0065
Epoch  83 Batch  720/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9790, Loss: 0.0048
Epoch  83 Batch  740/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9801, Loss: 0.0049
Epoch  83 Batch  760/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9883, Loss: 0.0071
Epoch  83 Batch  780/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9872, Loss: 0.0069
Epoch  83 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9922, Loss: 0.0032
Epoch  83 Batch  820/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9876, Loss: 0.0056
Epoch  83 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9826, Loss: 0.0054
Epoch  83 Batch  860/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9872, Loss: 0.0069
Epoch  83 Batch  880/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9748, Loss: 0.0059
Epoch  83 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9798, Loss: 0.0066
Epoch  83 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9830, Loss: 0.0042
Epoch  83 Batch  940/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9790, Loss: 0.0045
Epoch  83 Batch  960/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9822, Loss: 0.0071
Epoch  83 Batch  980/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9854, Loss: 0.0055
Epoch  83 Batch 1000/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9698, Loss: 0.0046
Epoch  83 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9883, Loss: 0.0031
Epoch  83 Batch 1040/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9847, Loss: 0.0079
Epoch  83 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9822, Loss: 0.0037
Epoch  84 Batch   20/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9872, Loss: 0.0059
Epoch  84 Batch   40/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9925, Loss: 0.0034
Epoch  84 Batch   60/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9798, Loss: 0.0046
Epoch  84 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9830, Loss: 0.0049
Epoch  84 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9776, Loss: 0.0037
Epoch  84 Batch  120/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9794, Loss: 0.0060
Epoch  84 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9883, Loss: 0.0044
Epoch  84 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9798, Loss: 0.0040
Epoch  84 Batch  180/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9780, Loss: 0.0039
Epoch  84 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9854, Loss: 0.0030
Epoch  84 Batch  220/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9815, Loss: 0.0068
Epoch  84 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9812, Loss: 0.0033
Epoch  84 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9833, Loss: 0.0036
Epoch  84 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9826, Loss: 0.0038
Epoch  84 Batch  300/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9872, Loss: 0.0050
Epoch  84 Batch  320/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9656, Loss: 0.0079
Epoch  84 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9656, Loss: 0.0036
Epoch  84 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9751, Loss: 0.0055
Epoch  84 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9783, Loss: 0.0028
Epoch  84 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9918, Loss: 0.0040
Epoch  84 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9719, Loss: 0.0031
Epoch  84 Batch  440/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9851, Loss: 0.0035
Epoch  84 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9737, Loss: 0.0057
Epoch  84 Batch  480/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9677, Loss: 0.0059
Epoch  84 Batch  500/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9751, Loss: 0.0029
Epoch  84 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9737, Loss: 0.0037
Epoch  84 Batch  540/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9837, Loss: 0.0042
Epoch  84 Batch  560/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9869, Loss: 0.0051
Epoch  84 Batch  580/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9780, Loss: 0.0056
Epoch  84 Batch  600/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9851, Loss: 0.0053
Epoch  84 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9826, Loss: 0.0052
Epoch  84 Batch  640/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9805, Loss: 0.0049
Epoch  84 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9759, Loss: 0.0028
Epoch  84 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9876, Loss: 0.0050
Epoch  84 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9805, Loss: 0.0056
Epoch  84 Batch  720/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9805, Loss: 0.0054
Epoch  84 Batch  740/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9751, Loss: 0.0046
Epoch  84 Batch  760/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9840, Loss: 0.0063
Epoch  84 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9862, Loss: 0.0060
Epoch  84 Batch  800/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9780, Loss: 0.0035
Epoch  84 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0047
Epoch  84 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0059
Epoch  84 Batch  860/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9876, Loss: 0.0058
Epoch  84 Batch  880/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9744, Loss: 0.0062
Epoch  84 Batch  900/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9762, Loss: 0.0079
Epoch  84 Batch  920/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9748, Loss: 0.0056
Epoch  84 Batch  940/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9805, Loss: 0.0046
Epoch  84 Batch  960/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9808, Loss: 0.0075
Epoch  84 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9815, Loss: 0.0056
Epoch  84 Batch 1000/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9766, Loss: 0.0047
Epoch  84 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9879, Loss: 0.0032
Epoch  84 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9862, Loss: 0.0045
Epoch  84 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9780, Loss: 0.0051
Epoch  85 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9947, Loss: 0.0042
Epoch  85 Batch   40/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9901, Loss: 0.0039
Epoch  85 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9751, Loss: 0.0052
Epoch  85 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9780, Loss: 0.0051
Epoch  85 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9808, Loss: 0.0053
Epoch  85 Batch  120/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9790, Loss: 0.0062
Epoch  85 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9819, Loss: 0.0058
Epoch  85 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9759, Loss: 0.0030
Epoch  85 Batch  180/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9776, Loss: 0.0035
Epoch  85 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9787, Loss: 0.0033
Epoch  85 Batch  220/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9776, Loss: 0.0063
Epoch  85 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9762, Loss: 0.0033
Epoch  85 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9798, Loss: 0.0039
Epoch  85 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9833, Loss: 0.0061
Epoch  85 Batch  300/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9872, Loss: 0.0050
Epoch  85 Batch  320/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9712, Loss: 0.0072
Epoch  85 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9780, Loss: 0.0032
Epoch  85 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9801, Loss: 0.0034
Epoch  85 Batch  380/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9702, Loss: 0.0032
Epoch  85 Batch  400/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9808, Loss: 0.0032
Epoch  85 Batch  420/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9790, Loss: 0.0041
Epoch  85 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9837, Loss: 0.0029
Epoch  85 Batch  460/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9723, Loss: 0.0052
Epoch  85 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9677, Loss: 0.0039
Epoch  85 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9730, Loss: 0.0027
Epoch  85 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9730, Loss: 0.0037
Epoch  85 Batch  540/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9787, Loss: 0.0034
Epoch  85 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9794, Loss: 0.0035
Epoch  85 Batch  580/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9798, Loss: 0.0059
Epoch  85 Batch  600/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9854, Loss: 0.0061
Epoch  85 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9798, Loss: 0.0059
Epoch  85 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9876, Loss: 0.0038
Epoch  85 Batch  660/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9776, Loss: 0.0049
Epoch  85 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9808, Loss: 0.0056
Epoch  85 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9801, Loss: 0.0048
Epoch  85 Batch  720/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9826, Loss: 0.0036
Epoch  85 Batch  740/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9751, Loss: 0.0037
Epoch  85 Batch  760/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9819, Loss: 0.0048
Epoch  85 Batch  780/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9879, Loss: 0.0064
Epoch  85 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9872, Loss: 0.0029
Epoch  85 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9904, Loss: 0.0034
Epoch  85 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9830, Loss: 0.0042
Epoch  85 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9879, Loss: 0.0049
Epoch  85 Batch  880/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9755, Loss: 0.0074
Epoch  85 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9826, Loss: 0.0065
Epoch  85 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9822, Loss: 0.0040
Epoch  85 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9727, Loss: 0.0035
Epoch  85 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9858, Loss: 0.0068
Epoch  85 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9830, Loss: 0.0050
Epoch  85 Batch 1000/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9751, Loss: 0.0068
Epoch  85 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9862, Loss: 0.0036
Epoch  85 Batch 1040/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9854, Loss: 0.0050
Epoch  85 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9822, Loss: 0.0035
Epoch  86 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9950, Loss: 0.0053
Epoch  86 Batch   40/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9851, Loss: 0.0049
Epoch  86 Batch   60/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9787, Loss: 0.0051
Epoch  86 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9805, Loss: 0.0043
Epoch  86 Batch  100/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9744, Loss: 0.0055
Epoch  86 Batch  120/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9847, Loss: 0.0067
Epoch  86 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9780, Loss: 0.0031
Epoch  86 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9872, Loss: 0.0035
Epoch  86 Batch  180/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9783, Loss: 0.0038
Epoch  86 Batch  200/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9840, Loss: 0.0036
Epoch  86 Batch  220/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9759, Loss: 0.0068
Epoch  86 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9805, Loss: 0.0041
Epoch  86 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9858, Loss: 0.0043
Epoch  86 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9783, Loss: 0.0052
Epoch  86 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9826, Loss: 0.0042
Epoch  86 Batch  320/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9808, Loss: 0.0049
Epoch  86 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9762, Loss: 0.0041
Epoch  86 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9815, Loss: 0.0036
Epoch  86 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9766, Loss: 0.0034
Epoch  86 Batch  400/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9805, Loss: 0.0051
Epoch  86 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9783, Loss: 0.0047
Epoch  86 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9847, Loss: 0.0027
Epoch  86 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9769, Loss: 0.0044
Epoch  86 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9698, Loss: 0.0046
Epoch  86 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9730, Loss: 0.0022
Epoch  86 Batch  520/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9751, Loss: 0.0034
Epoch  86 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9688, Loss: 0.0046
Epoch  86 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9755, Loss: 0.0051
Epoch  86 Batch  580/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9858, Loss: 0.0043
Epoch  86 Batch  600/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9844, Loss: 0.0057
Epoch  86 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9812, Loss: 0.0065
Epoch  86 Batch  640/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9904, Loss: 0.0077
Epoch  86 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9805, Loss: 0.0046
Epoch  86 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9826, Loss: 0.0053
Epoch  86 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9833, Loss: 0.0071
Epoch  86 Batch  720/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9851, Loss: 0.0042
Epoch  86 Batch  740/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9744, Loss: 0.0056
Epoch  86 Batch  760/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9783, Loss: 0.0081
Epoch  86 Batch  780/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9908, Loss: 0.0061
Epoch  86 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9847, Loss: 0.0018
Epoch  86 Batch  820/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9897, Loss: 0.0046
Epoch  86 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  86 Batch  860/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9904, Loss: 0.0052
Epoch  86 Batch  880/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9776, Loss: 0.0056
Epoch  86 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9872, Loss: 0.0057
Epoch  86 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9783, Loss: 0.0039
Epoch  86 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0032
Epoch  86 Batch  960/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9744, Loss: 0.0062
Epoch  86 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9819, Loss: 0.0056
Epoch  86 Batch 1000/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9851, Loss: 0.0063
Epoch  86 Batch 1020/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9897, Loss: 0.0025
Epoch  86 Batch 1040/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9858, Loss: 0.0045
Epoch  86 Batch 1060/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9659, Loss: 0.0040
Epoch  87 Batch   20/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9925, Loss: 0.0072
Epoch  87 Batch   40/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9940, Loss: 0.0050
Epoch  87 Batch   60/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9808, Loss: 0.0053
Epoch  87 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9787, Loss: 0.0040
Epoch  87 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9869, Loss: 0.0042
Epoch  87 Batch  120/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9847, Loss: 0.0045
Epoch  87 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9716, Loss: 0.0036
Epoch  87 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0022
Epoch  87 Batch  180/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9759, Loss: 0.0043
Epoch  87 Batch  200/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9854, Loss: 0.0052
Epoch  87 Batch  220/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9751, Loss: 0.0070
Epoch  87 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9741, Loss: 0.0035
Epoch  87 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9688, Loss: 0.0030
Epoch  87 Batch  280/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9627, Loss: 0.0043
Epoch  87 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9826, Loss: 0.0059
Epoch  87 Batch  320/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9666, Loss: 0.0079
Epoch  87 Batch  340/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9790, Loss: 0.0054
Epoch  87 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9695, Loss: 0.0033
Epoch  87 Batch  380/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9648, Loss: 0.0034
Epoch  87 Batch  400/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9812, Loss: 0.0027
Epoch  87 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9748, Loss: 0.0040
Epoch  87 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9688, Loss: 0.0027
Epoch  87 Batch  460/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9688, Loss: 0.0066
Epoch  87 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9606, Loss: 0.0066
Epoch  87 Batch  500/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9776, Loss: 0.0032
Epoch  87 Batch  520/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9734, Loss: 0.0026
Epoch  87 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9805, Loss: 0.0044
Epoch  87 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9712, Loss: 0.0031
Epoch  87 Batch  580/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9723, Loss: 0.0048
Epoch  87 Batch  600/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9893, Loss: 0.0044
Epoch  87 Batch  620/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9798, Loss: 0.0063
Epoch  87 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9851, Loss: 0.0036
Epoch  87 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0018
Epoch  87 Batch  680/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9716, Loss: 0.0044
Epoch  87 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9801, Loss: 0.0076
Epoch  87 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9826, Loss: 0.0035
Epoch  87 Batch  740/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9769, Loss: 0.0041
Epoch  87 Batch  760/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9844, Loss: 0.0054
Epoch  87 Batch  780/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9862, Loss: 0.0061
Epoch  87 Batch  800/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9798, Loss: 0.0043
Epoch  87 Batch  820/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9869, Loss: 0.0040
Epoch  87 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9830, Loss: 0.0043
Epoch  87 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9879, Loss: 0.0037
Epoch  87 Batch  880/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9780, Loss: 0.0043
Epoch  87 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9819, Loss: 0.0070
Epoch  87 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9773, Loss: 0.0040
Epoch  87 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9741, Loss: 0.0033
Epoch  87 Batch  960/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9790, Loss: 0.0065
Epoch  87 Batch  980/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9840, Loss: 0.0053
Epoch  87 Batch 1000/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9680, Loss: 0.0056
Epoch  87 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9904, Loss: 0.0026
Epoch  87 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9840, Loss: 0.0046
Epoch  87 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9826, Loss: 0.0035
Epoch  88 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9879, Loss: 0.0055
Epoch  88 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9808, Loss: 0.0046
Epoch  88 Batch   60/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9751, Loss: 0.0056
Epoch  88 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9847, Loss: 0.0049
Epoch  88 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9826, Loss: 0.0037
Epoch  88 Batch  120/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9822, Loss: 0.0045
Epoch  88 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9865, Loss: 0.0059
Epoch  88 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9837, Loss: 0.0021
Epoch  88 Batch  180/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9808, Loss: 0.0036
Epoch  88 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9744, Loss: 0.0029
Epoch  88 Batch  220/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9798, Loss: 0.0062
Epoch  88 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9744, Loss: 0.0036
Epoch  88 Batch  260/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9808, Loss: 0.0043
Epoch  88 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9691, Loss: 0.0059
Epoch  88 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9826, Loss: 0.0054
Epoch  88 Batch  320/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9712, Loss: 0.0051
Epoch  88 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9762, Loss: 0.0043
Epoch  88 Batch  360/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9737, Loss: 0.0034
Epoch  88 Batch  380/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9684, Loss: 0.0038
Epoch  88 Batch  400/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9773, Loss: 0.0035
Epoch  88 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9773, Loss: 0.0030
Epoch  88 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9691, Loss: 0.0027
Epoch  88 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9709, Loss: 0.0053
Epoch  88 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9727, Loss: 0.0047
Epoch  88 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9744, Loss: 0.0025
Epoch  88 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9634, Loss: 0.0035
Epoch  88 Batch  540/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9851, Loss: 0.0048
Epoch  88 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9759, Loss: 0.0039
Epoch  88 Batch  580/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9684, Loss: 0.0043
Epoch  88 Batch  600/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9730, Loss: 0.0046
Epoch  88 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9840, Loss: 0.0053
Epoch  88 Batch  640/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9773, Loss: 0.0047
Epoch  88 Batch  660/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9794, Loss: 0.0034
Epoch  88 Batch  680/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9808, Loss: 0.0046
Epoch  88 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9723, Loss: 0.0061
Epoch  88 Batch  720/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9790, Loss: 0.0041
Epoch  88 Batch  740/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9801, Loss: 0.0041
Epoch  88 Batch  760/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9833, Loss: 0.0038
Epoch  88 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9854, Loss: 0.0070
Epoch  88 Batch  800/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9854, Loss: 0.0030
Epoch  88 Batch  820/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9879, Loss: 0.0034
Epoch  88 Batch  840/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9812, Loss: 0.0059
Epoch  88 Batch  860/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9865, Loss: 0.0054
Epoch  88 Batch  880/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9808, Loss: 0.0046
Epoch  88 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9805, Loss: 0.0076
Epoch  88 Batch  920/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9790, Loss: 0.0045
Epoch  88 Batch  940/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9794, Loss: 0.0051
Epoch  88 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9698, Loss: 0.0069
Epoch  88 Batch  980/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9833, Loss: 0.0053
Epoch  88 Batch 1000/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9716, Loss: 0.0055
Epoch  88 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0032
Epoch  88 Batch 1040/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9876, Loss: 0.0088
Epoch  88 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9869, Loss: 0.0047
Epoch  89 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9876, Loss: 0.0049
Epoch  89 Batch   40/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9787, Loss: 0.0058
Epoch  89 Batch   60/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9748, Loss: 0.0055
Epoch  89 Batch   80/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9783, Loss: 0.0057
Epoch  89 Batch  100/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9854, Loss: 0.0042
Epoch  89 Batch  120/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9790, Loss: 0.0046
Epoch  89 Batch  140/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9769, Loss: 0.0049
Epoch  89 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9751, Loss: 0.0020
Epoch  89 Batch  180/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9794, Loss: 0.0037
Epoch  89 Batch  200/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9847, Loss: 0.0031
Epoch  89 Batch  220/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9730, Loss: 0.0071
Epoch  89 Batch  240/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9844, Loss: 0.0033
Epoch  89 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9744, Loss: 0.0037
Epoch  89 Batch  280/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9790, Loss: 0.0048
Epoch  89 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9805, Loss: 0.0044
Epoch  89 Batch  320/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9613, Loss: 0.0075
Epoch  89 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9751, Loss: 0.0035
Epoch  89 Batch  360/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9755, Loss: 0.0070
Epoch  89 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9737, Loss: 0.0051
Epoch  89 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9766, Loss: 0.0049
Epoch  89 Batch  420/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9695, Loss: 0.0027
Epoch  89 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9780, Loss: 0.0036
Epoch  89 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9780, Loss: 0.0051
Epoch  89 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9748, Loss: 0.0054
Epoch  89 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0025
Epoch  89 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9723, Loss: 0.0048
Epoch  89 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9847, Loss: 0.0040
Epoch  89 Batch  560/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9865, Loss: 0.0024
Epoch  89 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9798, Loss: 0.0052
Epoch  89 Batch  600/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9826, Loss: 0.0053
Epoch  89 Batch  620/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9830, Loss: 0.0055
Epoch  89 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9780, Loss: 0.0043
Epoch  89 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9712, Loss: 0.0019
Epoch  89 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9805, Loss: 0.0048
Epoch  89 Batch  700/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9851, Loss: 0.0067
Epoch  89 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9783, Loss: 0.0034
Epoch  89 Batch  740/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9759, Loss: 0.0034
Epoch  89 Batch  760/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9769, Loss: 0.0040
Epoch  89 Batch  780/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9872, Loss: 0.0062
Epoch  89 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9872, Loss: 0.0027
Epoch  89 Batch  820/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9876, Loss: 0.0039
Epoch  89 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9815, Loss: 0.0036
Epoch  89 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9872, Loss: 0.0038
Epoch  89 Batch  880/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9805, Loss: 0.0050
Epoch  89 Batch  900/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9727, Loss: 0.0067
Epoch  89 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9794, Loss: 0.0034
Epoch  89 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9773, Loss: 0.0021
Epoch  89 Batch  960/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9748, Loss: 0.0058
Epoch  89 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9826, Loss: 0.0046
Epoch  89 Batch 1000/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9730, Loss: 0.0050
Epoch  89 Batch 1020/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9819, Loss: 0.0034
Epoch  89 Batch 1040/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9790, Loss: 0.0049
Epoch  89 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9744, Loss: 0.0034
Epoch  90 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9904, Loss: 0.0047
Epoch  90 Batch   40/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9922, Loss: 0.0037
Epoch  90 Batch   60/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9847, Loss: 0.0054
Epoch  90 Batch   80/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9762, Loss: 0.0054
Epoch  90 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9826, Loss: 0.0044
Epoch  90 Batch  120/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9776, Loss: 0.0102
Epoch  90 Batch  140/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9865, Loss: 0.0078
Epoch  90 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9751, Loss: 0.0032
Epoch  90 Batch  180/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9879, Loss: 0.0036
Epoch  90 Batch  200/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9847, Loss: 0.0064
Epoch  90 Batch  220/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9801, Loss: 0.0055
Epoch  90 Batch  240/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9790, Loss: 0.0037
Epoch  90 Batch  260/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9794, Loss: 0.0046
Epoch  90 Batch  280/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9798, Loss: 0.0051
Epoch  90 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9822, Loss: 0.0046
Epoch  90 Batch  320/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9819, Loss: 0.0063
Epoch  90 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9851, Loss: 0.0041
Epoch  90 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9734, Loss: 0.0037
Epoch  90 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9709, Loss: 0.0027
Epoch  90 Batch  400/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9801, Loss: 0.0055
Epoch  90 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9698, Loss: 0.0034
Epoch  90 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9819, Loss: 0.0033
Epoch  90 Batch  460/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9762, Loss: 0.0053
Epoch  90 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9748, Loss: 0.0064
Epoch  90 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0023
Epoch  90 Batch  520/1077 - Train Accuracy: 0.9978, Validation Accuracy: 0.9755, Loss: 0.0038
Epoch  90 Batch  540/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9833, Loss: 0.0029
Epoch  90 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9794, Loss: 0.0044
Epoch  90 Batch  580/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9712, Loss: 0.0038
Epoch  90 Batch  600/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9794, Loss: 0.0028
Epoch  90 Batch  620/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9790, Loss: 0.0051
Epoch  90 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9847, Loss: 0.0036
Epoch  90 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0021
Epoch  90 Batch  680/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9801, Loss: 0.0048
Epoch  90 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9851, Loss: 0.0047
Epoch  90 Batch  720/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9762, Loss: 0.0031
Epoch  90 Batch  740/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9798, Loss: 0.0045
Epoch  90 Batch  760/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9844, Loss: 0.0064
Epoch  90 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9769, Loss: 0.0066
Epoch  90 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9879, Loss: 0.0027
Epoch  90 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9922, Loss: 0.0043
Epoch  90 Batch  840/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9830, Loss: 0.0041
Epoch  90 Batch  860/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9872, Loss: 0.0050
Epoch  90 Batch  880/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9801, Loss: 0.0057
Epoch  90 Batch  900/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9798, Loss: 0.0053
Epoch  90 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0032
Epoch  90 Batch  940/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9904, Loss: 0.0025
Epoch  90 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9879, Loss: 0.0065
Epoch  90 Batch  980/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9851, Loss: 0.0047
Epoch  90 Batch 1000/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9783, Loss: 0.0061
Epoch  90 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9862, Loss: 0.0023
Epoch  90 Batch 1040/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9862, Loss: 0.0058
Epoch  90 Batch 1060/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9780, Loss: 0.0031
Epoch  91 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9911, Loss: 0.0043
Epoch  91 Batch   40/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9858, Loss: 0.0040
Epoch  91 Batch   60/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9783, Loss: 0.0054
Epoch  91 Batch   80/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9801, Loss: 0.0045
Epoch  91 Batch  100/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9815, Loss: 0.0039
Epoch  91 Batch  120/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9833, Loss: 0.0050
Epoch  91 Batch  140/1077 - Train Accuracy: 0.9975, Validation Accuracy: 0.9847, Loss: 0.0040
Epoch  91 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9787, Loss: 0.0028
Epoch  91 Batch  180/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9776, Loss: 0.0044
Epoch  91 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9730, Loss: 0.0026
Epoch  91 Batch  220/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9840, Loss: 0.0059
Epoch  91 Batch  240/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0045
Epoch  91 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9858, Loss: 0.0048
Epoch  91 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9762, Loss: 0.0044
Epoch  91 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9851, Loss: 0.0060
Epoch  91 Batch  320/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9698, Loss: 0.0077
Epoch  91 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9695, Loss: 0.0041
Epoch  91 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9741, Loss: 0.0034
Epoch  91 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9762, Loss: 0.0031
Epoch  91 Batch  400/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9798, Loss: 0.0031
Epoch  91 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9755, Loss: 0.0034
Epoch  91 Batch  440/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9833, Loss: 0.0039
Epoch  91 Batch  460/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9762, Loss: 0.0056
Epoch  91 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9702, Loss: 0.0069
Epoch  91 Batch  500/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9783, Loss: 0.0025
Epoch  91 Batch  520/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0027
Epoch  91 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9918, Loss: 0.0048
Epoch  91 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9922, Loss: 0.0027
Epoch  91 Batch  580/1077 - Train Accuracy: 0.9847, Validation Accuracy: 0.9794, Loss: 0.0041
Epoch  91 Batch  600/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9904, Loss: 0.0049
Epoch  91 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9780, Loss: 0.0048
Epoch  91 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9904, Loss: 0.0050
Epoch  91 Batch  660/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9886, Loss: 0.0035
Epoch  91 Batch  680/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9918, Loss: 0.0042
Epoch  91 Batch  700/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9862, Loss: 0.0081
Epoch  91 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9762, Loss: 0.0037
Epoch  91 Batch  740/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9826, Loss: 0.0039
Epoch  91 Batch  760/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9790, Loss: 0.0056
Epoch  91 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9812, Loss: 0.0075
Epoch  91 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9851, Loss: 0.0016
Epoch  91 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9925, Loss: 0.0029
Epoch  91 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0043
Epoch  91 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9862, Loss: 0.0036
Epoch  91 Batch  880/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9822, Loss: 0.0058
Epoch  91 Batch  900/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9893, Loss: 0.0059
Epoch  91 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9776, Loss: 0.0023
Epoch  91 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0048
Epoch  91 Batch  960/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9780, Loss: 0.0081
Epoch  91 Batch  980/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9815, Loss: 0.0048
Epoch  91 Batch 1000/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9769, Loss: 0.0056
Epoch  91 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9833, Loss: 0.0028
Epoch  91 Batch 1040/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9922, Loss: 0.0090
Epoch  91 Batch 1060/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9730, Loss: 0.0058
Epoch  92 Batch   20/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9883, Loss: 0.0050
Epoch  92 Batch   40/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9830, Loss: 0.0030
Epoch  92 Batch   60/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9815, Loss: 0.0038
Epoch  92 Batch   80/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9851, Loss: 0.0048
Epoch  92 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9776, Loss: 0.0038
Epoch  92 Batch  120/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9830, Loss: 0.0046
Epoch  92 Batch  140/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9826, Loss: 0.0051
Epoch  92 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0028
Epoch  92 Batch  180/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9780, Loss: 0.0026
Epoch  92 Batch  200/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9773, Loss: 0.0032
Epoch  92 Batch  220/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9844, Loss: 0.0081
Epoch  92 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9783, Loss: 0.0036
Epoch  92 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9805, Loss: 0.0033
Epoch  92 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9801, Loss: 0.0031
Epoch  92 Batch  300/1077 - Train Accuracy: 0.9942, Validation Accuracy: 0.9876, Loss: 0.0044
Epoch  92 Batch  320/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9716, Loss: 0.0043
Epoch  92 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9673, Loss: 0.0022
Epoch  92 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9812, Loss: 0.0026
Epoch  92 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9741, Loss: 0.0027
Epoch  92 Batch  400/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9748, Loss: 0.0026
Epoch  92 Batch  420/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9794, Loss: 0.0023
Epoch  92 Batch  440/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9730, Loss: 0.0034
Epoch  92 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9684, Loss: 0.0043
Epoch  92 Batch  480/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9624, Loss: 0.0036
Epoch  92 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9719, Loss: 0.0028
Epoch  92 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9702, Loss: 0.0037
Epoch  92 Batch  540/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9790, Loss: 0.0048
Epoch  92 Batch  560/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9872, Loss: 0.0039
Epoch  92 Batch  580/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9801, Loss: 0.0038
Epoch  92 Batch  600/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9776, Loss: 0.0050
Epoch  92 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9840, Loss: 0.0060
Epoch  92 Batch  640/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9844, Loss: 0.0026
Epoch  92 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9688, Loss: 0.0019
Epoch  92 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9805, Loss: 0.0040
Epoch  92 Batch  700/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9801, Loss: 0.0055
Epoch  92 Batch  720/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9815, Loss: 0.0035
Epoch  92 Batch  740/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9865, Loss: 0.0044
Epoch  92 Batch  760/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9869, Loss: 0.0043
Epoch  92 Batch  780/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9801, Loss: 0.0034
Epoch  92 Batch  800/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9812, Loss: 0.0016
Epoch  92 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9879, Loss: 0.0028
Epoch  92 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9830, Loss: 0.0041
Epoch  92 Batch  860/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9876, Loss: 0.0034
Epoch  92 Batch  880/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9815, Loss: 0.0055
Epoch  92 Batch  900/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9847, Loss: 0.0068
Epoch  92 Batch  920/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9869, Loss: 0.0072
Epoch  92 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9794, Loss: 0.0025
Epoch  92 Batch  960/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9833, Loss: 0.0054
Epoch  92 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9897, Loss: 0.0046
Epoch  92 Batch 1000/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9712, Loss: 0.0053
Epoch  92 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9787, Loss: 0.0029
Epoch  92 Batch 1040/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9854, Loss: 0.0046
Epoch  92 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9837, Loss: 0.0034
Epoch  93 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9925, Loss: 0.0038
Epoch  93 Batch   40/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0041
Epoch  93 Batch   60/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9787, Loss: 0.0051
Epoch  93 Batch   80/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9837, Loss: 0.0033
Epoch  93 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9862, Loss: 0.0046
Epoch  93 Batch  120/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9847, Loss: 0.0054
Epoch  93 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9762, Loss: 0.0040
Epoch  93 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9751, Loss: 0.0019
Epoch  93 Batch  180/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9780, Loss: 0.0042
Epoch  93 Batch  200/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9822, Loss: 0.0031
Epoch  93 Batch  220/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9851, Loss: 0.0065
Epoch  93 Batch  240/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9783, Loss: 0.0037
Epoch  93 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9716, Loss: 0.0034
Epoch  93 Batch  280/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0038
Epoch  93 Batch  300/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9783, Loss: 0.0061
Epoch  93 Batch  320/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9656, Loss: 0.0046
Epoch  93 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9680, Loss: 0.0031
Epoch  93 Batch  360/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9751, Loss: 0.0030
Epoch  93 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9769, Loss: 0.0026
Epoch  93 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9748, Loss: 0.0039
Epoch  93 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9705, Loss: 0.0027
Epoch  93 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9712, Loss: 0.0041
Epoch  93 Batch  460/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9805, Loss: 0.0046
Epoch  93 Batch  480/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9833, Loss: 0.0033
Epoch  93 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9801, Loss: 0.0023
Epoch  93 Batch  520/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9730, Loss: 0.0027
Epoch  93 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9833, Loss: 0.0055
Epoch  93 Batch  560/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9769, Loss: 0.0043
Epoch  93 Batch  580/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9830, Loss: 0.0042
Epoch  93 Batch  600/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9904, Loss: 0.0027
Epoch  93 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9830, Loss: 0.0044
Epoch  93 Batch  640/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9897, Loss: 0.0033
Epoch  93 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9748, Loss: 0.0018
Epoch  93 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9826, Loss: 0.0036
Epoch  93 Batch  700/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9790, Loss: 0.0058
Epoch  93 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9790, Loss: 0.0043
Epoch  93 Batch  740/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9737, Loss: 0.0047
Epoch  93 Batch  760/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9844, Loss: 0.0047
Epoch  93 Batch  780/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9847, Loss: 0.0057
Epoch  93 Batch  800/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9862, Loss: 0.0035
Epoch  93 Batch  820/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9812, Loss: 0.0042
Epoch  93 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9790, Loss: 0.0046
Epoch  93 Batch  860/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9918, Loss: 0.0048
Epoch  93 Batch  880/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9826, Loss: 0.0067
Epoch  93 Batch  900/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9822, Loss: 0.0096
Epoch  93 Batch  920/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9815, Loss: 0.0054
Epoch  93 Batch  940/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9925, Loss: 0.0050
Epoch  93 Batch  960/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9837, Loss: 0.0059
Epoch  93 Batch  980/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9897, Loss: 0.0067
Epoch  93 Batch 1000/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9851, Loss: 0.0056
Epoch  93 Batch 1020/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9883, Loss: 0.0046
Epoch  93 Batch 1040/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9862, Loss: 0.0046
Epoch  93 Batch 1060/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9862, Loss: 0.0041
Epoch  94 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9925, Loss: 0.0060
Epoch  94 Batch   40/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9897, Loss: 0.0032
Epoch  94 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9751, Loss: 0.0038
Epoch  94 Batch   80/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9847, Loss: 0.0041
Epoch  94 Batch  100/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9872, Loss: 0.0039
Epoch  94 Batch  120/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9830, Loss: 0.0051
Epoch  94 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9826, Loss: 0.0034
Epoch  94 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9755, Loss: 0.0023
Epoch  94 Batch  180/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0028
Epoch  94 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9830, Loss: 0.0037
Epoch  94 Batch  220/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9865, Loss: 0.0078
Epoch  94 Batch  240/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0029
Epoch  94 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9744, Loss: 0.0023
Epoch  94 Batch  280/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9716, Loss: 0.0040
Epoch  94 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9826, Loss: 0.0059
Epoch  94 Batch  320/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9723, Loss: 0.0054
Epoch  94 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9709, Loss: 0.0043
Epoch  94 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9783, Loss: 0.0050
Epoch  94 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9730, Loss: 0.0021
Epoch  94 Batch  400/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9901, Loss: 0.0027
Epoch  94 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9812, Loss: 0.0042
Epoch  94 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9837, Loss: 0.0030
Epoch  94 Batch  460/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9801, Loss: 0.0039
Epoch  94 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9723, Loss: 0.0056
Epoch  94 Batch  500/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9808, Loss: 0.0037
Epoch  94 Batch  520/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9705, Loss: 0.0024
Epoch  94 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9751, Loss: 0.0047
Epoch  94 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9762, Loss: 0.0043
Epoch  94 Batch  580/1077 - Train Accuracy: 0.9967, Validation Accuracy: 0.9769, Loss: 0.0036
Epoch  94 Batch  600/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9897, Loss: 0.0031
Epoch  94 Batch  620/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9815, Loss: 0.0052
Epoch  94 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9925, Loss: 0.0037
Epoch  94 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9727, Loss: 0.0047
Epoch  94 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9812, Loss: 0.0057
Epoch  94 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9883, Loss: 0.0063
Epoch  94 Batch  720/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0035
Epoch  94 Batch  740/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9790, Loss: 0.0036
Epoch  94 Batch  760/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9844, Loss: 0.0053
Epoch  94 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9790, Loss: 0.0066
Epoch  94 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9865, Loss: 0.0016
Epoch  94 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9876, Loss: 0.0036
Epoch  94 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9830, Loss: 0.0035
Epoch  94 Batch  860/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9879, Loss: 0.0050
Epoch  94 Batch  880/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9851, Loss: 0.0061
Epoch  94 Batch  900/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9851, Loss: 0.0074
Epoch  94 Batch  920/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9776, Loss: 0.0045
Epoch  94 Batch  940/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9886, Loss: 0.0038
Epoch  94 Batch  960/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9844, Loss: 0.0071
Epoch  94 Batch  980/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9865, Loss: 0.0047
Epoch  94 Batch 1000/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9712, Loss: 0.0042
Epoch  94 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9787, Loss: 0.0022
Epoch  94 Batch 1040/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9862, Loss: 0.0069
Epoch  94 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9805, Loss: 0.0025
Epoch  95 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9925, Loss: 0.0057
Epoch  95 Batch   40/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9869, Loss: 0.0042
Epoch  95 Batch   60/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9730, Loss: 0.0037
Epoch  95 Batch   80/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9805, Loss: 0.0046
Epoch  95 Batch  100/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9865, Loss: 0.0073
Epoch  95 Batch  120/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9822, Loss: 0.0049
Epoch  95 Batch  140/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9822, Loss: 0.0043
Epoch  95 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9801, Loss: 0.0025
Epoch  95 Batch  180/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9766, Loss: 0.0032
Epoch  95 Batch  200/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9751, Loss: 0.0028
Epoch  95 Batch  220/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9844, Loss: 0.0126
Epoch  95 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9762, Loss: 0.0044
Epoch  95 Batch  260/1077 - Train Accuracy: 0.9955, Validation Accuracy: 0.9812, Loss: 0.0071
Epoch  95 Batch  280/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9751, Loss: 0.0040
Epoch  95 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9840, Loss: 0.0039
Epoch  95 Batch  320/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9751, Loss: 0.0067
Epoch  95 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9805, Loss: 0.0032
Epoch  95 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9794, Loss: 0.0036
Epoch  95 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9798, Loss: 0.0031
Epoch  95 Batch  400/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9805, Loss: 0.0043
Epoch  95 Batch  420/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9727, Loss: 0.0025
Epoch  95 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9847, Loss: 0.0031
Epoch  95 Batch  460/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9744, Loss: 0.0055
Epoch  95 Batch  480/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9666, Loss: 0.0034
Epoch  95 Batch  500/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9759, Loss: 0.0033
Epoch  95 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9734, Loss: 0.0041
Epoch  95 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9830, Loss: 0.0045
Epoch  95 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9844, Loss: 0.0032
Epoch  95 Batch  580/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9762, Loss: 0.0041
Epoch  95 Batch  600/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9908, Loss: 0.0032
Epoch  95 Batch  620/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9727, Loss: 0.0097
Epoch  95 Batch  640/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9925, Loss: 0.0034
Epoch  95 Batch  660/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9670, Loss: 0.0030
Epoch  95 Batch  680/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9808, Loss: 0.0041
Epoch  95 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9851, Loss: 0.0054
Epoch  95 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9783, Loss: 0.0033
Epoch  95 Batch  740/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9826, Loss: 0.0040
Epoch  95 Batch  760/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0031
Epoch  95 Batch  780/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9805, Loss: 0.0054
Epoch  95 Batch  800/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9872, Loss: 0.0041
Epoch  95 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9858, Loss: 0.0042
Epoch  95 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9815, Loss: 0.0035
Epoch  95 Batch  860/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9851, Loss: 0.0032
Epoch  95 Batch  880/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9780, Loss: 0.0072
Epoch  95 Batch  900/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9780, Loss: 0.0088
Epoch  95 Batch  920/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9766, Loss: 0.0096
Epoch  95 Batch  940/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9734, Loss: 0.0045
Epoch  95 Batch  960/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9677, Loss: 0.0060
Epoch  95 Batch  980/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9822, Loss: 0.0074
Epoch  95 Batch 1000/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9702, Loss: 0.0047
Epoch  95 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9794, Loss: 0.0035
Epoch  95 Batch 1040/1077 - Train Accuracy: 0.9901, Validation Accuracy: 0.9869, Loss: 0.0044
Epoch  95 Batch 1060/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9780, Loss: 0.0029
Epoch  96 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9872, Loss: 0.0045
Epoch  96 Batch   40/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9869, Loss: 0.0044
Epoch  96 Batch   60/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9872, Loss: 0.0051
Epoch  96 Batch   80/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9819, Loss: 0.0034
Epoch  96 Batch  100/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9805, Loss: 0.0040
Epoch  96 Batch  120/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9801, Loss: 0.0053
Epoch  96 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9773, Loss: 0.0027
Epoch  96 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9865, Loss: 0.0043
Epoch  96 Batch  180/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9826, Loss: 0.0043
Epoch  96 Batch  200/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9748, Loss: 0.0036
Epoch  96 Batch  220/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9826, Loss: 0.0065
Epoch  96 Batch  240/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9812, Loss: 0.0029
Epoch  96 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0026
Epoch  96 Batch  280/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9812, Loss: 0.0026
Epoch  96 Batch  300/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9858, Loss: 0.0035
Epoch  96 Batch  320/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9766, Loss: 0.0049
Epoch  96 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9748, Loss: 0.0036
Epoch  96 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9794, Loss: 0.0035
Epoch  96 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9698, Loss: 0.0024
Epoch  96 Batch  400/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9798, Loss: 0.0025
Epoch  96 Batch  420/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9847, Loss: 0.0025
Epoch  96 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9798, Loss: 0.0027
Epoch  96 Batch  460/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9741, Loss: 0.0047
Epoch  96 Batch  480/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9723, Loss: 0.0051
Epoch  96 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9833, Loss: 0.0022
Epoch  96 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9780, Loss: 0.0035
Epoch  96 Batch  540/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9766, Loss: 0.0051
Epoch  96 Batch  560/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9918, Loss: 0.0033
Epoch  96 Batch  580/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9815, Loss: 0.0030
Epoch  96 Batch  600/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9858, Loss: 0.0045
Epoch  96 Batch  620/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9709, Loss: 0.0048
Epoch  96 Batch  640/1077 - Train Accuracy: 0.9993, Validation Accuracy: 0.9830, Loss: 0.0048
Epoch  96 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9751, Loss: 0.0025
Epoch  96 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9748, Loss: 0.0037
Epoch  96 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9876, Loss: 0.0054
Epoch  96 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0031
Epoch  96 Batch  740/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9822, Loss: 0.0045
Epoch  96 Batch  760/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9766, Loss: 0.0072
Epoch  96 Batch  780/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9769, Loss: 0.0102
Epoch  96 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9801, Loss: 0.0034
Epoch  96 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9815, Loss: 0.0032
Epoch  96 Batch  840/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9762, Loss: 0.0049
Epoch  96 Batch  860/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9872, Loss: 0.0060
Epoch  96 Batch  880/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9734, Loss: 0.0050
Epoch  96 Batch  900/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9840, Loss: 0.0073
Epoch  96 Batch  920/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9798, Loss: 0.0053
Epoch  96 Batch  940/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9812, Loss: 0.0030
Epoch  96 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9879, Loss: 0.0060
Epoch  96 Batch  980/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9876, Loss: 0.0059
Epoch  96 Batch 1000/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9808, Loss: 0.0048
Epoch  96 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9822, Loss: 0.0031
Epoch  96 Batch 1040/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9840, Loss: 0.0055
Epoch  96 Batch 1060/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9727, Loss: 0.0041
Epoch  97 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9925, Loss: 0.0039
Epoch  97 Batch   40/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9876, Loss: 0.0033
Epoch  97 Batch   60/1077 - Train Accuracy: 0.9907, Validation Accuracy: 0.9751, Loss: 0.0035
Epoch  97 Batch   80/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9847, Loss: 0.0033
Epoch  97 Batch  100/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9741, Loss: 0.0039
Epoch  97 Batch  120/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9830, Loss: 0.0039
Epoch  97 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9876, Loss: 0.0036
Epoch  97 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9769, Loss: 0.0042
Epoch  97 Batch  180/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9744, Loss: 0.0024
Epoch  97 Batch  200/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9865, Loss: 0.0025
Epoch  97 Batch  220/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9769, Loss: 0.0063
Epoch  97 Batch  240/1077 - Train Accuracy: 0.9977, Validation Accuracy: 0.9751, Loss: 0.0037
Epoch  97 Batch  260/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9819, Loss: 0.0025
Epoch  97 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9794, Loss: 0.0039
Epoch  97 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9858, Loss: 0.0039
Epoch  97 Batch  320/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9773, Loss: 0.0041
Epoch  97 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9819, Loss: 0.0026
Epoch  97 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9794, Loss: 0.0033
Epoch  97 Batch  380/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9790, Loss: 0.0035
Epoch  97 Batch  400/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9790, Loss: 0.0026
Epoch  97 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9759, Loss: 0.0033
Epoch  97 Batch  440/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9862, Loss: 0.0039
Epoch  97 Batch  460/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9790, Loss: 0.0053
Epoch  97 Batch  480/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9762, Loss: 0.0044
Epoch  97 Batch  500/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9719, Loss: 0.0031
Epoch  97 Batch  520/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9755, Loss: 0.0030
Epoch  97 Batch  540/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9741, Loss: 0.0055
Epoch  97 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9780, Loss: 0.0041
Epoch  97 Batch  580/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9808, Loss: 0.0053
Epoch  97 Batch  600/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9854, Loss: 0.0044
Epoch  97 Batch  620/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9830, Loss: 0.0061
Epoch  97 Batch  640/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9854, Loss: 0.0051
Epoch  97 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9712, Loss: 0.0036
Epoch  97 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9684, Loss: 0.0044
Epoch  97 Batch  700/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9808, Loss: 0.0046
Epoch  97 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9819, Loss: 0.0037
Epoch  97 Batch  740/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9759, Loss: 0.0034
Epoch  97 Batch  760/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9826, Loss: 0.0060
Epoch  97 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9872, Loss: 0.0045
Epoch  97 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9865, Loss: 0.0014
Epoch  97 Batch  820/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9925, Loss: 0.0052
Epoch  97 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9822, Loss: 0.0051
Epoch  97 Batch  860/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9869, Loss: 0.0052
Epoch  97 Batch  880/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9638, Loss: 0.0121
Epoch  97 Batch  900/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9869, Loss: 0.0077
Epoch  97 Batch  920/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9787, Loss: 0.0105
Epoch  97 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9833, Loss: 0.0032
Epoch  97 Batch  960/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9826, Loss: 0.0059
Epoch  97 Batch  980/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9815, Loss: 0.0084
Epoch  97 Batch 1000/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9766, Loss: 0.0061
Epoch  97 Batch 1020/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9869, Loss: 0.0033
Epoch  97 Batch 1040/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9925, Loss: 0.0075
Epoch  97 Batch 1060/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9751, Loss: 0.0051
Epoch  98 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9858, Loss: 0.0037
Epoch  98 Batch   40/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9865, Loss: 0.0033
Epoch  98 Batch   60/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9783, Loss: 0.0043
Epoch  98 Batch   80/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9830, Loss: 0.0036
Epoch  98 Batch  100/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9748, Loss: 0.0042
Epoch  98 Batch  120/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9830, Loss: 0.0071
Epoch  98 Batch  140/1077 - Train Accuracy: 0.9979, Validation Accuracy: 0.9787, Loss: 0.0032
Epoch  98 Batch  160/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9819, Loss: 0.0021
Epoch  98 Batch  180/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9759, Loss: 0.0027
Epoch  98 Batch  200/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9808, Loss: 0.0022
Epoch  98 Batch  220/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9883, Loss: 0.0055
Epoch  98 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9787, Loss: 0.0032
Epoch  98 Batch  260/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9769, Loss: 0.0027
Epoch  98 Batch  280/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9769, Loss: 0.0049
Epoch  98 Batch  300/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9876, Loss: 0.0031
Epoch  98 Batch  320/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9826, Loss: 0.0056
Epoch  98 Batch  340/1077 - Train Accuracy: 0.9971, Validation Accuracy: 0.9759, Loss: 0.0046
Epoch  98 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0021
Epoch  98 Batch  380/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9830, Loss: 0.0026
Epoch  98 Batch  400/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9830, Loss: 0.0042
Epoch  98 Batch  420/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0017
Epoch  98 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9858, Loss: 0.0030
Epoch  98 Batch  460/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9737, Loss: 0.0045
Epoch  98 Batch  480/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9751, Loss: 0.0038
Epoch  98 Batch  500/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9876, Loss: 0.0027
Epoch  98 Batch  520/1077 - Train Accuracy: 0.9981, Validation Accuracy: 0.9780, Loss: 0.0026
Epoch  98 Batch  540/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9744, Loss: 0.0034
Epoch  98 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9872, Loss: 0.0038
Epoch  98 Batch  580/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9787, Loss: 0.0032
Epoch  98 Batch  600/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9879, Loss: 0.0040
Epoch  98 Batch  620/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9766, Loss: 0.0045
Epoch  98 Batch  640/1077 - Train Accuracy: 0.9944, Validation Accuracy: 0.9876, Loss: 0.0027
Epoch  98 Batch  660/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9776, Loss: 0.0019
Epoch  98 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9819, Loss: 0.0030
Epoch  98 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9876, Loss: 0.0043
Epoch  98 Batch  720/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9876, Loss: 0.0045
Epoch  98 Batch  740/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9879, Loss: 0.0039
Epoch  98 Batch  760/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9840, Loss: 0.0053
Epoch  98 Batch  780/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9844, Loss: 0.0049
Epoch  98 Batch  800/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9918, Loss: 0.0030
Epoch  98 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9840, Loss: 0.0021
Epoch  98 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9830, Loss: 0.0036
Epoch  98 Batch  860/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9879, Loss: 0.0036
Epoch  98 Batch  880/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9847, Loss: 0.0051
Epoch  98 Batch  900/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9844, Loss: 0.0058
Epoch  98 Batch  920/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9869, Loss: 0.0030
Epoch  98 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9897, Loss: 0.0020
Epoch  98 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9851, Loss: 0.0059
Epoch  98 Batch  980/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9858, Loss: 0.0051
Epoch  98 Batch 1000/1077 - Train Accuracy: 0.9929, Validation Accuracy: 0.9833, Loss: 0.0072
Epoch  98 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9865, Loss: 0.0028
Epoch  98 Batch 1040/1077 - Train Accuracy: 0.9893, Validation Accuracy: 0.9858, Loss: 0.0068
Epoch  98 Batch 1060/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9922, Loss: 0.0038
Epoch  99 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9854, Loss: 0.0060
Epoch  99 Batch   40/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9854, Loss: 0.0041
Epoch  99 Batch   60/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9844, Loss: 0.0045
Epoch  99 Batch   80/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9876, Loss: 0.0038
Epoch  99 Batch  100/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9858, Loss: 0.0043
Epoch  99 Batch  120/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9830, Loss: 0.0038
Epoch  99 Batch  140/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9890, Loss: 0.0049
Epoch  99 Batch  160/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9766, Loss: 0.0021
Epoch  99 Batch  180/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0019
Epoch  99 Batch  200/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9780, Loss: 0.0024
Epoch  99 Batch  220/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9780, Loss: 0.0070
Epoch  99 Batch  240/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9744, Loss: 0.0035
Epoch  99 Batch  260/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9652, Loss: 0.0025
Epoch  99 Batch  280/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9790, Loss: 0.0025
Epoch  99 Batch  300/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9780, Loss: 0.0047
Epoch  99 Batch  320/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9737, Loss: 0.0068
Epoch  99 Batch  340/1077 - Train Accuracy: 0.9947, Validation Accuracy: 0.9790, Loss: 0.0063
Epoch  99 Batch  360/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9826, Loss: 0.0026
Epoch  99 Batch  380/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9766, Loss: 0.0022
Epoch  99 Batch  400/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9815, Loss: 0.0020
Epoch  99 Batch  420/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9709, Loss: 0.0022
Epoch  99 Batch  440/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9847, Loss: 0.0024
Epoch  99 Batch  460/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9787, Loss: 0.0047
Epoch  99 Batch  480/1077 - Train Accuracy: 0.9951, Validation Accuracy: 0.9680, Loss: 0.0032
Epoch  99 Batch  500/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9826, Loss: 0.0017
Epoch  99 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9730, Loss: 0.0037
Epoch  99 Batch  540/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9830, Loss: 0.0027
Epoch  99 Batch  560/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9862, Loss: 0.0042
Epoch  99 Batch  580/1077 - Train Accuracy: 0.9952, Validation Accuracy: 0.9798, Loss: 0.0026
Epoch  99 Batch  600/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9837, Loss: 0.0037
Epoch  99 Batch  620/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9826, Loss: 0.0042
Epoch  99 Batch  640/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9883, Loss: 0.0021
Epoch  99 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9734, Loss: 0.0035
Epoch  99 Batch  680/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9815, Loss: 0.0042
Epoch  99 Batch  700/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9787, Loss: 0.0050
Epoch  99 Batch  720/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9805, Loss: 0.0030
Epoch  99 Batch  740/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9808, Loss: 0.0038
Epoch  99 Batch  760/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9819, Loss: 0.0037
Epoch  99 Batch  780/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9776, Loss: 0.0047
Epoch  99 Batch  800/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9865, Loss: 0.0019
Epoch  99 Batch  820/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9865, Loss: 0.0025
Epoch  99 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9815, Loss: 0.0036
Epoch  99 Batch  860/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9854, Loss: 0.0034
Epoch  99 Batch  880/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9808, Loss: 0.0044
Epoch  99 Batch  900/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9854, Loss: 0.0047
Epoch  99 Batch  920/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9790, Loss: 0.0044
Epoch  99 Batch  940/1077 - Train Accuracy: 1.0000, Validation Accuracy: 0.9787, Loss: 0.0020
Epoch  99 Batch  960/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9830, Loss: 0.0063
Epoch  99 Batch  980/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9840, Loss: 0.0050
Epoch  99 Batch 1000/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9876, Loss: 0.0070
Epoch  99 Batch 1020/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9830, Loss: 0.0023
Epoch  99 Batch 1040/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9886, Loss: 0.0050
Epoch  99 Batch 1060/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9783, Loss: 0.0032
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="n">list_</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

    <span class="k">return</span> <span class="n">list_</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [104, 165, 16, 18, 124, 7]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [53, 84, 263, 292, 260, 1]
  French Words: n&#39;aime plus magnifique automobile . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
